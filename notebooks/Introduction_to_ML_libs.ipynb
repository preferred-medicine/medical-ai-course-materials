{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-9QSHa5gkqc"
   },
   "source": [
    "[![colab-logo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/preferred-medicine/medical-ai-course-materials/blob/master/notebooks/Introduction_to_ML_libs.ipynb)\n",
    "\n",
    "#  Basics of machine learning \n",
    "\n",
    "In this chapter, we introduce the representative machine learning algorithms and the points of how to use them, together with the mathematical background. Let's think about algorithms of **single regression analysis** and **multiple regression analysis** together with mathematical expressions as a practice to acquire the concept of machine learning . By learning these, you will see how to use differentiation, linear algebra, and statistics. There are many places in the neural network which will be introduced in the next chapter that will be based on the concept of multiple regression analysis.\n",
    "\n",
    "\n",
    "## Single regression analysis \n",
    "\n",
    "First, we will discuss single regression analysis, which is one of the most basic methods of machine learning algorithms. Machine learning algorithms are roughly divided into **supervised learning** and **unsupervised learning**, and simple regression analysis is a type of supervised learning. As a typical problem of supervised learning,10Or0.1There are **regressions** to predict numerical values (strictly continuous values) as in, and **classification** to predict category values like red wine or white wine . Simple regression analysis, as the name implies, is a method that handles regression, and is a machine learning algorithm that predicts one output variable from one input variable.\n",
    "\n",
    "\n",
    "### Problem setting (single regression analysis) \n",
    "In machine learning, learning is performed based on data, but it is necessary for humans to decide what to use and what to predict from the information contained in the data.\n",
    "\n",
    "Here, as an example, let us consider the problem of predicting rent. Therefore, rent is an **output variable** $y$ It becomes.\n",
    "\n",
    "Then, the **input variables** consider what should be adopted as. For rent forecasting, for example, the room size, the distance from the station, and the crime rate can be considered as input variables. Here we input the size of the room variable $x$ Let's adopt as. In practice, when there are multiple input variable candidates, modeling that can handle all of them is generally used, but this will be introduced later in the multiple regression analysis.\n",
    "\n",
    "In the machine learning algorithm, each method is roughly divided into the following three steps.\n",
    "\n",
    "- Step 1: Determine the model\n",
    "- Step 2: Determine the objective function\n",
    "- Step 3: Find the optimal parameters\n",
    "\n",
    "We will explain the above three steps in order.\n",
    "\n",
    "### Step 1. Determine the model (single regression analysis) \n",
    "\n",
    "First, decide the **model** in Step1 . Model is an output variable $y$ And input variables $x$ It is a **formulation** of the relationship of . How can we formulate the rent and predict it well? Currently, this model design is generally performed manually, and machines do not automatically determine this (in recent years, research has also progressed to automatically determine models such as AutoML).\n",
    "\n",
    "For example, in a given data set, suppose that the relationship between rent and room size is as follows.\n",
    "\n",
    "\n",
    "![ÂÆ∂Ë≥É„Å®ÈÉ®Â±ã„ÅÆÂ∫É„Åï„ÅÆÈñ¢‰øÇ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/01.png)\n",
    "\n",
    "In this case, the larger the room, the higher the rent, and it seems reasonable to use a straight line for prediction.\n",
    "\n",
    "\n",
    "![Áõ¥Á∑öÂºè„Å´„Çà„Çã„É¢„Éá„É´Âåñ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/02.png)\n",
    "\n",
    "In this case, the straight line is adopted as a model, and the model of Step 1 is formulated as follows.\n",
    "\n",
    "$$\n",
    "y = wx + b\n",
    "$$\n",
    "\n",
    "here $w$ Is inclined, $b$ Is a parameter called intercept (in machine learning, **weight** is the slope ) $w$, **Bias the segment (bias)** $b$ It is common to express with the symbol).\n",
    "\n",
    "In single regression analysis, the model is thus straight $y = wx + b$ Decide the weightùë§And bias $b$ Adjust the to fit the data well.\n",
    "\n",
    "The goal of many machine learning is to use a model characterized by such parameters and to find the optimal parameters to fit a given **data set** . Here, the data set is the size of the room, which is an input variable $x$ And the rent to be teacher data $t$ A set of data consisting of a set of $y$ , Give something as teacher data $t$ And I use it separately).\n",
    "\n",
    "The data set is $\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ It may also be represented as. Where subscriptùëõ ($n=1,2,\\ldots,N$) Is $n$ It means the second property,$N$ Is the total number of properties. this $N$ Is called the **number of samples** .\n",
    "\n",
    "Here, we will introduce a technique called **data centering** to facilitate the subsequent calculations . As shown in the figure below, the room size and the rent both have positive values, so it looks like the graph on the left. Centering means **averaging** $\\boldsymbol{0}$ It performs conversion processing such as placing it in the center. This centralization is generally performed as preprocessing in many algorithms. Strictly speaking, centralization scaling described in the previous chapter is often used.\n",
    "\n",
    "\n",
    "![‰∏≠ÂøÉÂåñÂá¶ÁêÜ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/03.png)\n",
    "\n",
    "As one of the reasons for this process, as shown in the figure below, bias is due to centralization of data $b$But $0$ And $y_{c} = wx_{c}$ It can be mentioned that the model can be expressed without bias components, as this can reduce the parameters to be adjusted.\n",
    "\n",
    "\n",
    "![‰∏≠ÂøÉÂåñÂæå„ÅÆÁõ¥Á∑öÂºè](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/04.png)\n",
    "\n",
    "Centralization of the data is achieved by subtracting the average of the input and output from the whole of the data. In other words,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{c} &= x - \\bar{x} \\\\\n",
    "t_{c} &= t - \\bar{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. For example, looking at specific numbers, it is as shown in the figure below.\n",
    "\n",
    "![‰∏≠ÂøÉÂåñÂâçÂæå„ÅÆÊï∞ÂÄ§ÊØîËºÉ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/05.png)\n",
    "\n",
    "Indexed to indicate after centering ùëêBecause the expression is redundant with respect to, it is assumed in the future that this subscript is omitted and data centralization is performed in advance. At this time, the model is\n",
    "\n",
    "$$\n",
    "y = wx\n",
    "$$\n",
    "\n",
    "And the goal of simple regression analysis is the data set $\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ Parameters based on ùë§The right will be adjusted.\n",
    "\n",
    "\n",
    "### Step 2. Determine the objective function (single regression analysis) \n",
    "\n",
    "As explained in Chapter 1, supervised learning often involves designing an objective function and learning the model by minimizing (or maximizing) the objective function.\n",
    "\n",
    "This time, the goal is to match the teacher data and the predicted value, and the squared error of the teacher data and the predicted value is used as an objective function to express it. The squared error is0And only when $t = y$ It can be said that we have achieved perfect prediction. $n$ Teacher data for the second property $t_{n}$ And predicted value $y_{n}$ The squared error of\n",
    "\n",
    "$$\n",
    "(t_{n} - y_{n})^{2}\n",
    "$$\n",
    "\n",
    "It becomes. Since it is necessary to consider this for all properties, the final objective function takes its sum\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + (t_{N}-y_{N})^{2} \\\\\n",
    "&=\\sum^{N}_{n=1}\\left( t_{n}-y_{n}\\right)^{2}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. Also, the model decided in Step 1\n",
    "\n",
    "$$\n",
    "y_{n} = wx_{n}\n",
    "$$\n",
    "\n",
    "The objective function is\n",
    "$$\n",
    "\\mathcal{L}=\\sum^{N}_{n=1}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "\n",
    "It can be expressed in a form that includes and parameters. Remember that such a function is called a loss function.\n",
    "\n",
    "\n",
    "### Step 3. Find the optimal parameter (single regression analysis) \n",
    "\n",
    "The last step is to find parameters that minimize the objective function. Here we have already learned that differentiation can be used as a way to find points to minimize a function. In the case of the square of the difference like this time, the point at which ‚ÄúSlope 0‚Äù is differentiated is the loss.0The point is The derivative of the objective function is as follows.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac{\\partial }{\\partial w} \\mathcal{L}  &= \\dfrac{\\partial}{\\partial w} { \\sum^{N}_{n=1} ( t_{n}-wx_{n})^{2} }\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here, the derivative has the property of **linearity**, and in particular, the derivative of the sum is obtained using the fact that it is the sum of derivatives.\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial}{\\partial w} \\mathcal{L}=\\sum^{N}_{n=1}\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "\n",
    "Where differentiation and summation $\\sum$ The symbol of is replaced. Next, looking at the terms of the sum,\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "\n",
    "Part of $t_n - wx_n$ You can see that it is a composite function of and its square .$u_{n} = t_{n} - wx_{n}$, $f(u_{n}) = u_{n}^{2}$ If you\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2} &=  \\dfrac {\\partial }{\\partial w} f(u_{n}) \\\\\n",
    "&= \\dfrac {\\partial u_{n}}{\\partial w} \\dfrac{\\partial f(u_{n})}{\\partial u_{n}} \\\\\n",
    "&=-x_{n} \\times 2 u_{n}  \\\\\n",
    "&= -2x_{n}( t_{n}-wx_{n} )\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "can be obtained. Than this,\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac{\\partial }{\\partial w} \\mathcal{L}\n",
    "&=\\sum^{N}_{n=1}\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "\\\\&=-\\sum^{N}_{n=1}2x_{n}\\left( t_{n}-wx_{n}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. So that the value of this derivative is 0 $w$ When you ask for\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial w} \\mathcal{L} &=0\\\\\n",
    "-2\\sum^{N}_{n=1}x_{n}\\left( t_{n}-wx_{n}\\right) &=0\\\\\n",
    "-2 \\sum^{N}_{n=1}x_{n}t_{n} + 2\\sum^{N}_{n=1}wx^{2}_{n}&=0\\\\\n",
    "-2\\sum^{N}_{n=1}x_{n}t_{n}+2w\\sum^{N}_{n=1}x^{2}_{n}&=0\\\\\n",
    "w\\sum^{N}_{n=1}x^{2}_{n}&=\\sum^{N}_{n=1}x_{n}t_{n}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Than,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w&=\\dfrac {\\displaystyle  \\sum^{N}_{n=1}x_{n}t_{n}}{\\displaystyle  \\sum^{N}_{n=1}x^{2}_{n}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "I asked for it. This parameterùë§ Check the given data set $\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ It can be seen that the decision can be made only from.\n",
    "\n",
    "\n",
    "Next, the parameters in the numerical example given in the example ùë§Let's ask for First, to centralize the data,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{x} &= \\dfrac{1}{3} (1 + 2 + 3) = 2 \\\\\n",
    "\\bar{t} &= \\dfrac{1}{3}(2 + 3.9 + 6.1) = 4\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And averaging each of them, and subjecting each variable to preprocessing as central processing,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{1} &= 1 - 2 = -1 \\\\\n",
    "x_{2} &= 2 -2 = 0 \\\\\n",
    "x_{3} &= 3- 2 = 1\\\\\n",
    "t_{1} &= 2 - 4 = -2\\\\\n",
    "t_{2} &= 3.9 - 4 = -0.1\\\\\n",
    "t_{3} &= 6.1 - 4 = 2.1 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. And, using the values after centering, the optimal parameters $w$ If you derive\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w &= \\dfrac{\\displaystyle \\sum_{n=1}^{N}x_{n}t_{n}}{\\displaystyle  \\sum_{n=1}^{N}x_{n}^{2}} \\\\\n",
    "&= \\dfrac{x_{1}t_{1} + x_{2}t_{2} + x_{3}t_{3}}{x_{1}^{2} + x_{2}^{2} + x_{3}^{2}} \\\\\n",
    "&= \\dfrac{-1 \\times (-2) + 0 \\times 0.1 + 1 \\times 2.1}{(-1)^{2} + 0^2 + 1^2} \\\\\n",
    "&= 2.05\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "I asked for it. This completes learning for simple regression analysis. The model using the obtained parameters is the trained **model**.\n",
    "\n",
    "Next, let's use this model to make predictions for new samples. The process of calculating predicted values ‚Äã‚Äãfor new input data using a learned model is called **inference** . For example, a new sample $x_{q}=1.5$  The predicted value for can be obtained as follows,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{c} &= wx_{c} \\\\\n",
    "y_{q} - \\bar{t} &= w(x_{q}-\\bar{x}) \\\\\n",
    "\\Rightarrow y_{q} &= w(x_{q}-\\bar{x}) + \\bar{t} \\\\\n",
    "&= 2.05 \\times (1.5 - 2) + 4 \\\\\n",
    "&= 2.975\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since the model was trained using centralized data, it is important to remember that the actual predicted values ‚Äã‚Äãwill be restored to the centralized data.\n",
    "\n",
    "The above is a series of steps of single regression analysis.\n",
    "\n",
    "\n",
    "## Multiple Regression analysis \n",
    "Next, we will deal with multiple regression analysis dealing with multivariable input variables. The knowledge of linear algebra will be deepened by learning this multiple regression analysis.\n",
    "\n",
    "Multiple regression analysis is a type of supervised learning similar to simple regression analysis, and is a method for dealing with regression. The problem setting is almost the same as single regression analysis, but in multiple regression analysis, there are multiple input variables. In other words, it is a machine learning algorithm that can predict output variables from multiple input variables.\n",
    "\n",
    "### Problem setting (multiple regression analysis) \n",
    "\n",
    "Here, considering the problem of predicting rent as in the case of simple regression analysis, rent is an output variable $y$ will do. As input variables, we will also take into consideration the distance from the station and the crime rate that could not be considered in single regression analysis. For example, the size of the room $x_{1}$, Distance from the station $x_{2}$, ..., crime rate $x_{M}$ like $M$ Suppose that there are $M=1$ In the case of, it is reduced to the problem of single regression analysis).\n",
    "\n",
    "Similar to single regression analysis, learning is performed in the following three steps.\n",
    "\n",
    "- Determine the model\n",
    "- Determine the objective function\n",
    "- Find the optimal parameter\n",
    "\n",
    "\n",
    "„Åì„Åì„Åß„ÅØÂçòÂõûÂ∏∞ÂàÜÊûê„ÅÆÂ†¥Âêà„Å®ÂêåÊßò„Å´ÂÆ∂Ë≥É„Çí‰∫àÊ∏¨„Åô„ÇãÂïèÈ°å„ÇíËÄÉ„ÅàÔºåÂÆ∂Ë≥É„ÇíÂá∫ÂäõÂ§âÊï∞ $y$ „Å®„Åó„Åæ„ÅôÔºéÂÖ•ÂäõÂ§âÊï∞„Å®„Åó„Å¶„ÅØÔºåÂçòÂõûÂ∏∞ÂàÜÊûê„Åß„ÅØËÄÉÊÖÆ„Åó„Åç„Çå„Å¶„ÅÑ„Å™„Åã„Å£„ÅüÈßÖ„Åã„Çâ„ÅÆË∑ùÈõ¢„ÇÑÁäØÁΩ™Áô∫ÁîüÁéá„Å™„Å©„ÇÇËÄÉÊÖÆ„Åó„Å¶„ÅÑ„Åç„Åæ„ÅôÔºé‰æã„Åà„Å∞ÔºåÈÉ®Â±ã„ÅÆÂ∫É„Åï $x_{1}$, ÈßÖ„Åã„Çâ„ÅÆË∑ùÈõ¢ $x_{2}$, ..., ÁäØÁΩ™Áô∫ÁîüÁéá $x_{M}$ „ÅÆ„Çà„ÅÜ„Å´ $M$ ÂÄã„ÅÆÂÖ•ÂäõÂ§âÊï∞„Åå„ÅÇ„Çã„Å®„Åó„Åæ„ÅôÔºà$M=1$„ÅÆÂ†¥ÂêàÔºåÂçòÂõûÂ∏∞ÂàÜÊûê„ÅÆÂïèÈ°å„Å´Â∏∞ÁùÄ„Åï„Çå„Åæ„ÅôÔºâÔºé\n",
    "\n",
    "ÂçòÂõûÂ∏∞ÂàÜÊûê„Å®ÂêåÊßòÔºå‰ª•‰∏ã„ÅÆ3„Çπ„ÉÜ„ÉÉ„Éó„ÅßÂ≠¶Áøí„Åó„Å¶„ÅÑ„Åç„Åæ„ÅôÔºé\n",
    "\n",
    "- „É¢„Éá„É´„ÇíÊ±∫„ÇÅ„Çã\n",
    "- ÁõÆÁöÑÈñ¢Êï∞„ÇíÊ±∫„ÇÅ„Çã\n",
    "- ÊúÄÈÅ©„Å™„Éë„É©„É°„Éº„Çø„ÇíÊ±Ç„ÇÅ„Çã\n",
    "\n",
    "### Step 1. Determine the model (multiple regression analysis) \n",
    "The model for single regression analysis is\n",
    "\n",
    "$$\n",
    "y = wx + b\n",
    "$$\n",
    "\n",
    "And,$w$ The weight, $b$ Was called a bias. In multiple regression analysis, this expression is expanded to multiple input variables,\n",
    "\n",
    "$$\n",
    "y=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+b\n",
    "$$\n",
    "\n",
    "**Expressed** in the form of **linear combination** like . In this case, it is assumed that each input variable linearly affects the output variable, which is a fairly simple modeling. In practice, if there is a non-linear dependency between input variables, you need to model it taking that into consideration. I will explain it in the future.\n",
    "\n",
    "The model of multiple regression analysis can be organized using the symbol of summation,\n",
    "$$\n",
    "y = \\sum_{m=1}^{M} w_{m} x_{m} + b\n",
    "$$\n",
    "\n",
    "Can be written as And here, $x_0 = 1$Ôºå$w_0 = b$ If you\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+b\\\\\n",
    "&=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+w_{0} x_{0}\\\\\n",
    "&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Like bias $b$  Can be included in the summation. And as we sort out this formula,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "&=\\begin{bmatrix}\n",
    "w_{0} & w_{1} & \\ldots  & w_{M}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{0} \\\\\n",
    "x_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "x_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\boldsymbol{w}^{T}\\boldsymbol{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It can be expressed as the inner product of vectors, like. Also, when handling in the future, $\\boldsymbol{x}$ Is more computationally convenient to come in front of\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "&=\\begin{bmatrix}\n",
    "x_{0} & x_{1} & \\ldots  & x_{M}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{0} \\\\\n",
    "w_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "w_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\boldsymbol{x}^{T}\\boldsymbol{w}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Express as. This is a model of multiple regression analysis. This time as a parameter $M+1$ Weight $\\boldsymbol{w}$ I will seek for\n",
    "\n",
    "\n",
    "### Step 2. Determine the objective function (multiple regression analysis) \n",
    "\n",
    "In single regression analysis, teacher data $t$ And predicted value $y$ The smaller the squared error of, the better the prediction, and the sum is defined as the objective function. Predicted value even in multiple regression analysis $y$ Since asking for is the same, we use the same objective function asÔºâ\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + \\left( t_{N}-y_{N}\\right)^{2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In this way, **the sum of squared errors** is adopted as an objective function as in single regression analysis. In single regression analysis, this is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}=\\sum^{N}_{n=1} ( t_{n} - y_{n})^{2}\n",
    "$$\n",
    "\n",
    "As in, it was summarized using the symbol of the sum,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + \\left( t_{N}-y_{N}\\right)^{2}\\\\\n",
    "&=\\begin{bmatrix} t_{1} - y_{1} & t_{2}-y_{2} & \\ldots & t_{N}-y_{N} \\end{bmatrix} \\begin{bmatrix}\n",
    "t_{1}-y_{1} \\\\\n",
    "t_{2}-y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{N}-y_{N}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\left( \\boldsymbol{t}-\\boldsymbol{y}\\right)^{T}\\left( \\boldsymbol{t}-\\boldsymbol{y}\\right) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It can also be expressed using a vector like. Also, $\\boldsymbol{y}$ With regard to\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{y}=\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{N}\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "\\boldsymbol{x}_{1}^{T}\\boldsymbol{w} \\\\\n",
    "\\boldsymbol{x}_{2}^{T}\\boldsymbol{w} \\\\\n",
    "\\vdots  \\\\\n",
    "\\boldsymbol{x}_{N}^{T}\\boldsymbol{w}\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "\\boldsymbol{x}_{1}^{T} \\\\\n",
    "\\boldsymbol{x}_{2}^{T} \\\\\n",
    "\\vdots  \\\\\n",
    "\\boldsymbol{x}_{N}^{T}\n",
    "\\end{bmatrix}\n",
    "\\boldsymbol{w}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Can be written as Organizing this,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{y}&=\n",
    "\\begin{bmatrix}\n",
    "x_{10} & x_{11} & x_{12} & \\ldots  & x_{1M} \\\\\n",
    "x_{20} & x_{21} & x_{22} & \\ldots  & x_{2M} \\\\\n",
    "\\vdots  & \\vdots  & \\vdots  & \\ddots  \\\\\n",
    "x_{N0} & x_{N1} & x_{N{2}} & \\ldots  & x_{NM}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{0} \\\\\n",
    "w_{1} \\\\\n",
    "w_{2} \\\\\n",
    "\\vdots  \\\\\n",
    "w_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\boldsymbol{X}\\boldsymbol{w}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It can be written as Here, the row (horizontal) direction represents a sample, for example, corresponding to each property. The column (vertical) direction represents the input variable, for example, the size of the room or the distance from the station. In terms of a little more concrete numbers, the size of the room $= 50m^{2}$ , Distance from the station $= 600 m$ , Crime rate $= 2$% like $n$ For the second property, the number of input variables $M=3$ And,\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_{n}^{T} = \\begin{bmatrix}\n",
    "1 & 50 & 600 & 0.02\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is an image where data is stored in the row direction like. At the beginning $1$ Is used to include bias $x_{0}$ Please note that is\n",
    "\n",
    "### Step 3. Optimize the parameter (multiple regression analysis) \n",
    "\n",
    "Then, model parameters to minimize the objective function of Step 2 $\\boldsymbol{w}$ Let's ask for\n",
    "\n",
    "‚Äª **Here we will find analytical solutions of the optimal parameters while making full use of equation transformation, but the derivation process is a bit more complicated, and the results are shown in the next section (2.3 2.3), so we are interested If you don't, skip to the next section**.\n",
    "\n",
    "First of all, regarding the objective function, $w$ If you change the expression so that it can be expressed by,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( \\boldsymbol{t}-\\boldsymbol{y}\\right)^{T}\\left( \\boldsymbol{t}-\\boldsymbol{y}\\right) \\\\\n",
    "&=\\left( \\boldsymbol{t}-\\boldsymbol{X}\\boldsymbol{w}\\right)^{T}\\left( \\boldsymbol{t}-\\boldsymbol{X}\\boldsymbol{w}\\right) \\\\\n",
    "&= \\left\\{ \\boldsymbol{t}^{T}-(\\boldsymbol{X}\\boldsymbol{w})^{T}\\right\\}\\left( \\boldsymbol{t}-\\boldsymbol{X}\\boldsymbol{w}\\right) \\\\\n",
    "&=\\left( \\boldsymbol{t}^{T}-\\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\right)\\left( \\boldsymbol{t}-\\boldsymbol{X}\\boldsymbol{w}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. Where the transposition formula$(\\boldsymbol{A}\\boldsymbol{B})^{T} = \\boldsymbol{B}^{T}\\boldsymbol{A}^{T}$ Note that we are using Furthermore, if development is advanced using the distribution law,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\boldsymbol{t}^{T}\\boldsymbol{t}-\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w}-\\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\boldsymbol{t} + \\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It becomes. Parameters for this objective function $w$ We want to take a partial derivative of, but before that we can organize this expression a bit more. First,\n",
    "\n",
    "$$\n",
    "(1)^T = 1\n",
    "$$\n",
    "\n",
    "Thus, scalars do not change even if they are transposed. Come out in the above formula $\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w}$ Is a scalar, so\n",
    "\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w})^{T} = \\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w}\n",
    "$$\n",
    "\n",
    "Is true. Furthermore, the transposition formula $(\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C})^T = \\boldsymbol{C}^T\\boldsymbol{B}^T\\boldsymbol{A}^T$ Than,\n",
    "\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w})^T = \\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{t}\n",
    "$$\n",
    "\n",
    "Is also true. Than this,\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w})^{T} = \\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w} = \\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{t}\n",
    "$$\n",
    "\n",
    "Can lead. Objective function $\\mathcal{L}$ If you use the above equation,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}=\\boldsymbol{t}^{T}\\boldsymbol{t}-2\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w} + \\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Can be summarized. here, $\\boldsymbol{w}$ To do partial differentiation with respect to $\\boldsymbol{w}$ If you put together the constant terms other than\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\boldsymbol{t}^{T}\\boldsymbol{t}-2\\boldsymbol{t}^{T}\\boldsymbol{X}\\boldsymbol{w}+\\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}\\\\\n",
    "&=\\boldsymbol{t}^{T}\\boldsymbol{t}-2\\left( \\boldsymbol{X}^{T}\\boldsymbol{t}\\right)^{T} \\boldsymbol{w}+\\boldsymbol{w}^{T}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w} \\\\\n",
    "&= \\gamma + \\boldsymbol{\\beta}^{T}\\boldsymbol{w} + \\boldsymbol{w}^{T}\\boldsymbol{A}\\boldsymbol{w} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Learned with linear algebra, like $\\boldsymbol{w}$ It was able to express in quadratic form (quadric function) about. here,$\\boldsymbol{A}= \\boldsymbol{X}^{T}\\boldsymbol{X},, \\ \\boldsymbol{\\beta} =-2 \\boldsymbol{X}^{T}\\boldsymbol{t}, , \\ \\gamma = \\boldsymbol{t}^{T}\\boldsymbol{t}$ And,$\\boldsymbol{\\beta}$ The reason for having transposed form is to devise a vector learned by linear algebra to conform to the form of derivative formula.\n",
    "\n",
    "Then, the parameter which can minimize the objective function $\\boldsymbol{w}$ Let's consider how to ask for As mentioned earlier, the objective function is a parameter $\\boldsymbol{w}$ It is a quadratic function with respect to. For example,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{w} = \\begin{bmatrix}\n",
    "w_{1} \\\\ w_{2}\n",
    "\\end{bmatrix}, \n",
    "\\boldsymbol{A}=\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix},\\boldsymbol{\\beta}=\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix}, \\gamma = 1 \n",
    "\\end{aligned} \n",
    "$$ \n",
    "\n",
    "If you think with concrete numerical examples like,\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\mathcal{L} & = \n",
    "\\boldsymbol{w}^{T}\\boldsymbol{A}\\boldsymbol{w} + \\boldsymbol{\\beta}^{T}\\boldsymbol{w} + \\gamma \\\\ \n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "w_{1} & w_{2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2}\n",
    "\\end{bmatrix}\n",
    "+\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix} \\begin{bmatrix} \n",
    "w_{1} \\\\ \n",
    "w_{2} \n",
    "\\end{bmatrix} + 1 \\\\ \n",
    "&=\n",
    "\\begin{bmatrix} \n",
    "w_{1} & w_{2} \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "w_{1} + 2w_{2} \\\\ \n",
    "3w_{1} + 4w_{2} \n",
    "\\end{bmatrix} + w_{1} + 2w_{2} + 1 \\\\ \n",
    "&=w_{1}\\left( w_{1} + 2w_{2}\\right) + w_{2}\\left( 3w_{1} + 4w_{2}\\right) + w_{1} + 2w_{2} + 1 \\\\ \n",
    "&=w^{2}_{1} + 5w_{1}w_{2} + 4w^{2}_{2} + w_{1} + 2w_{2}+1 \\\\ \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And $w_{1}, w_{2}$ In terms of\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}\n",
    "&= w^{2}_{1} + \\left( 5w_{2} + 1\\right) w_{1} + \n",
    "\\left( 4w^{2}_{2}+2w_{2}+1\\right) \\\\ \n",
    "&=4w^{2}_{2} + \\left(5w_{1} + 2\\right) w_{2} + \\left( w^{2}_{1} + w_{1} + 1\\right) \\end{aligned} \n",
    "$$\n",
    "\n",
    "You can see that it is each quadratic function like.\n",
    "\n",
    "And if it is a quadratic function, it looks like the figure below.\n",
    "\n",
    "![„Éë„É©„É°„Éº„Çø„Å®ÁõÆÁöÑÈñ¢Êï∞„ÅÆÈñ¢‰øÇÔºà2Ê¨°ÂÖÉÔºâ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/06.png)\n",
    "\n",
    "If this is imaged in three dimensions, it will become like the following figure.\n",
    "\n",
    "\n",
    "\n",
    "![„Éë„É©„É°„Éº„Çø„Å®ÁõÆÁöÑÈñ¢Êï∞„ÅÆÈñ¢‰øÇÔºà3Ê¨°ÂÖÉÔºâ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/08.png)\n",
    "\n",
    "Then, at the point where the sum of squared errors, which is the objective function, is minimum, the slope when differentiated with each variable is zero.\n",
    "\n",
    "\n",
    "![ÁõÆÁöÑÈñ¢Êï∞„ÅåÊúÄÂ∞è„Å®„Å™„ÇãÁÇπ](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/2/07.png)\n",
    "\n",
    "In this example$w_{1}$ when $w_{2}$ I considered in the case of two parameters of $w_{0}$, $w_{1}$, $w_{2}$, $\\ldots$, $w_{M}$ You can think in the same way for\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dfrac {\\partial }{\\partial w_{0}}\\mathcal{L}=0\\\\\n",
    "\\dfrac {\\partial }{\\partial w_{1}}\\mathcal{L}=0\\\\\n",
    "\\ \\ \\ \\ \\ \\vdots \\\\\n",
    "\\dfrac {\\partial }{\\partial w_{M}}\\mathcal{L}=0\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And put it together,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "\\dfrac {\\partial}{\\partial w_{0}} \\mathcal{L} \\\\\n",
    "\\dfrac {\\partial}{\\partial w_{1}} \\mathcal{L} \\\\\n",
    "\\vdots  \\\\\n",
    "\\dfrac {\\partial}{\\partial w_{M}} \\mathcal{L} \\\\\n",
    "\\end{bmatrix}&=\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots  \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\\Rightarrow \\dfrac {\\partial}{\\partial \\boldsymbol{w}} \\mathcal{L} &= \\boldsymbol{0} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It is expressed as a derivative of a vector like. After that, to satisfy the above equation $\\boldsymbol{w}$ We will decide First of allùë§Perform substitution and formula transformation to make it easier to find. (Because the following calculations use the contents learned through linear algebra, including differentiation with vectors, so if you do not know the middle of the calculation, please proceed while checking the parts of linear algebra. )\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{w}}\\mathcal{L} =\\dfrac {\\partial }{\\partial \\boldsymbol{w}}\\left( \\gamma + \\boldsymbol{\\beta}^{T}\\boldsymbol{w} + \\boldsymbol{w}^{T}\\boldsymbol{A}\\boldsymbol{w}\\right)\n",
    "= \\boldsymbol{0}\\\\\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{w}}\\left( \\gamma\\right) +\\dfrac {\\partial }{\\partial \\boldsymbol{w}}\\left( \\boldsymbol{\\beta}^{T}\\boldsymbol{w}\\right) +\\dfrac {\\partial }{\\partial \\boldsymbol{w}}\\left( \\boldsymbol{w}^{T}\\boldsymbol{A}\\boldsymbol{w}\\right) \n",
    "=\\boldsymbol{0}\\\\\n",
    "\\boldsymbol{0}+\\boldsymbol{\\beta}+\\left( \\boldsymbol{A}+\\boldsymbol{A}^{T}\\right) \\boldsymbol{w} =\\boldsymbol{0}\\\\\n",
    "-2\\boldsymbol{X}^{T}\\boldsymbol{t}+\\left\\{ \\boldsymbol{X}^{T}\\boldsymbol{X} + \\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{T}\\right\\} \\boldsymbol{w}\n",
    "=\\boldsymbol{0}\\\\\n",
    "-2\\boldsymbol{X}^{T}\\boldsymbol{t}+2\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}=\\boldsymbol{0}\\\\\n",
    "\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}=\\boldsymbol{X}^{T}\\boldsymbol{t}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "here,$\\boldsymbol{X}^{T} \\boldsymbol{X}$ From the left side on both sides, assuming that the inverse matrix exists in $\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}$ If you \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{X} \\boldsymbol{w} =\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t} \\\\\n",
    "\\boldsymbol{I}\\boldsymbol{w}=\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t} \\\\\n",
    "\\boldsymbol{w}=\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "And the given data set $\\boldsymbol{X}, \\boldsymbol{t}$ From the optimum parameters $\\boldsymbol{w}$ Was asked. here, $\\boldsymbol{I}$ Is the identity matrix. Also, at the time of equation transformation,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w} = \\dfrac{\\boldsymbol{X}^{T}\\boldsymbol{t}}{\\boldsymbol{X}^{T}\\boldsymbol{X}}\n",
    "$$\n",
    "\n",
    "Be careful not to show fractions like. This is because there is no division in matrix calculations. Therefore, it is calculated only by matrix multiplication using inverse matrix.\n",
    "\n",
    "Also, as another common mistake,$\\boldsymbol{w}$ Here is an example that transforms the equation to find.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}&=\\boldsymbol{X}^{T}\\boldsymbol{t}\\\\\n",
    "\\left( \\boldsymbol{X}^{T}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{w}&=\\left( \\boldsymbol{X}^{T}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}\\\\\n",
    "\\boldsymbol{X}\\boldsymbol{w}&=\\boldsymbol{t}\\\\\n",
    "\\boldsymbol{X}^{-1}\\boldsymbol{X}\\boldsymbol{w}&=\\boldsymbol{X}^{-1}\\boldsymbol{t}\\\\\n",
    "\\boldsymbol{w}&=\\boldsymbol{X}^{-1}\\boldsymbol{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "However, this generally does not hold. The reason is that the square matrix is not satisfied as a condition to have the inverse matrix . Generally, the number of samples $N$  And the number of input variables $M+1$ Are not equal,$\\boldsymbol{X} \\in \\mathcal{R}^{N \\times (M+1)}$)Is not square and has no inverse. For it, $\\boldsymbol{X}^{T} \\boldsymbol{X}$ Is $\\boldsymbol{X}^{T} \\boldsymbol{X}$ „ÅØ $\\boldsymbol{X}^{T}\\boldsymbol{X} \\in \\mathcal{R}^{(M+1) \\times (M+1)}$) And the number of samples $N$ It is always square matrix without depending on. (There are more strict conditions for finding the inverse matrix, but I will not explain it here.)\n",
    "\n",
    "Parameters derived from learning during inference $\\boldsymbol{w}$ Using,\n",
    "\n",
    "\n",
    "$$\n",
    "y_{q} = \\boldsymbol{w}^{T}\\boldsymbol{x}_{q}\n",
    "$$\n",
    "\n",
    "You can get the predicted value by calculating as follows.\n",
    "\n",
    "## Implementation by Numpy\n",
    "\n",
    "Let's use Python to implement linear algebra, using multiple regression analysis as an example. Python has a library called **NumPy** that can easily handle linear algebra and is widely used. NumPy is frequently used among the Chainers introduced in the next chapter, and it is important to learn how to use NumPy as a first step to learning deep learning.\n",
    "\n",
    "It is assumed that you know the syntax of Python. Specifically, you need to understand variables (numbers, strings, lists, tuples, dictionaries), control syntax (for, if), functions, and classes.\n",
    "\n",
    "In the multiple regression analysis, finally the optimal parameters $\\boldsymbol{w}$ But\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w}=\\left( \\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63jvxwSk2Y28"
   },
   "source": [
    "It turned out that it is represented by. We will deal with the following five to calculate this optimal parameter.\n",
    "\n",
    "- Definition of vector\n",
    "- Matrix definition\n",
    "- Transposition\n",
    "- Matrix product\n",
    "- Inverse matrix\n",
    "\n",
    "Specifically, let's assume the case where the following data set is given. In this example, the number of data samples $N$ Is $4$ And the input data $X$ The number of variables of $2$ is. And $t$ Is teacher data.\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "1 & 2 & 5 \\\\\n",
    "1 & 3 & 4 \\\\  \n",
    "1 & 5 & 9 \n",
    "\\end{bmatrix}, \\\n",
    "\\boldsymbol{t} = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 5 \\\\ 6 \\\\ 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "here $\\boldsymbol{X}$ Is the parameter $\\boldsymbol{w}$ Is biased ùëè Assumes a form that includesùëãIn the first column of1Is stored.\n",
    "\n",
    "Let's look at the implementation method. First we will start by reading NumPy.\n",
    "\n",
    "here $\\boldsymbol{X}$ Is the parameter $\\boldsymbol{w}$ Is biased $\\boldsymbol{b}$ Assumes a form that includes $\\boldsymbol{X}$ In the first column of $1$ Is stored.\n",
    "\n",
    "Let's look at the implementation method. First we will start by reading NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEy_FvRJ2Y2_"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43TxMSHH2Y3C"
   },
   "source": [
    "The definition of the vector is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQd-4mXv2Y3D"
   },
   "outputs": [],
   "source": [
    "t = np.array([1, 5, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1eFys0AIIR8"
   },
   "source": [
    "Let's display the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z_fjFYsu2Y3H",
    "outputId": "45bf4612-4c9c-47ab-d663-8b580db10bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvE4dLpP2Y3P"
   },
   "source": [
    "Let's define the matrix and display it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxbCgDEl2Y3R"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 5],\n",
    "    [1, 3, 4],\n",
    "    [1, 5, 9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UdFu-c3p2Y3W",
    "outputId": "bc6e6bf6-a645-4f95-fe3a-c7ad756de82b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 5]\n",
      " [1 3 4]\n",
      " [1 5 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Dej1LjB2Y3f"
   },
   "source": [
    "Here we use `np.array` the function to `np.ndarray`convert from a Python list to the NumPy multidimensional array form ( ).\n",
    "\n",
    "Next, let's transpose X. `np.ndarray`If it is defined in `.T`, you can transpose just by putting it on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Sc1SrowF2Y3g",
    "outputId": "f25a0d94-7eb3-412c-be74-01b0562bafeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [2 2 3 5]\n",
      " [3 5 4 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXWmTlNM2Y3n"
   },
   "source": [
    "You can see that the vertical and horizontal are switched.\n",
    "\n",
    "Matrix multiplication `np.dot`can be realized as follows. When doing matrix multiplication, be aware that the number of columns in the first matrix is the same as the number of rows in the second matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5Qm-akG2Y3o"
   },
   "outputs": [],
   "source": [
    "XX = np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "K2BpUnAW2Y3u",
    "outputId": "7056511c-633f-49b3-9880-1f49473aa3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4  12  21]\n",
      " [ 12  42  73]\n",
      " [ 21  73 131]]\n"
     ]
    }
   ],
   "source": [
    "print(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwDD9lQc2Y34"
   },
   "source": [
    "Further from here,$\\boldsymbol{X}^{T}\\boldsymbol{X}$ Inverse matrix for,$\\left(\\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}$Calculate. Use to get the inverse matrix `np.linalg.inv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTS7OiuF2Y36"
   },
   "outputs": [],
   "source": [
    "XX_inv = np.linalg.inv(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yUFnXFgH2Y4B",
    "outputId": "fd3a33dc-27b5-4384-b6fa-7e75f440f6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76530612 -0.39795918 -0.06122449]\n",
      " [-0.39795918  0.84693878 -0.40816327]\n",
      " [-0.06122449 -0.40816327  0.24489796]]\n"
     ]
    }
   ],
   "source": [
    "print(XX_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4UccbfX2Y4H"
   },
   "source": [
    "You now have the necessary operations for multiple regression analysis.\n",
    "\n",
    "Optimal parameter$\\left(\\boldsymbol{X}^{T}\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^{T}\\boldsymbol{t}$ If you ask for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUDf1lul2Y4I"
   },
   "outputs": [],
   "source": [
    "Xt = np.dot(X.T, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4woi1AWA2Y4P",
    "outputId": "878978be-1186-42b2-c9c6-dc85f694dff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20  70 124]\n"
     ]
    }
   ],
   "source": [
    "print(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2PDggtE2Y4U"
   },
   "outputs": [],
   "source": [
    "w = np.dot(XX_inv, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f0ldbwNx2Y4Y",
    "outputId": "b4244c83-059e-46c6-fd39-0198992007e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14285714  0.71428571  0.57142857]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwbp0Oe52Y4d"
   },
   "source": [
    "Parameters like this  $\\boldsymbol{w}$ Was asked. By using NumPy, you can write mathematical expressions as they are on a program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOcnH9gD2Y4f"
   },
   "source": [
    "## Scikit-learn the execution of the machine learning algorithm by \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3U87Nhu12Y4h"
   },
   "source": [
    "Multiple regression analysis was relatively easy to implement with NumPy, but many of the practical machine learning algorithms are complex and often difficult for beginners to write from scratch. Therefore, a framework for machine learning called **Scikit-learn** is disclosed in Python, and even **beginners** can easily handle various machine learning algorithms.\n",
    "\n",
    "Here, we will introduce **the implementation method** of multiple regression analysis **using Scikit-learn** . The data set is the same as before $\\boldsymbol{X}$ when $\\boldsymbol{t}$ In Scikit-learn, **parameters** are used. $\\boldsymbol{w}$ **Is biased** $\\boldsymbol{b}$ **Assumes a** format that **does not include** $\\boldsymbol{X}$ From the first column of1It is common to remove Therefore,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \n",
    "\\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "2 & 5 \\\\\n",
    "3 & 4 \\\\  \n",
    "5 & 9 \n",
    "\\end{bmatrix}, \\\n",
    "\\boldsymbol{t} = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 5 \\\\ 6 \\\\ 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Suppose that is given.\n",
    "\n",
    "\n",
    "\n",
    "### Scikit-learn Âü∫Á§éÁ∑®\n",
    "`sklearn` You can call Scikit-learn with the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvEybj2F2Y4i"
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5a4UQLC2Y4n"
   },
   "source": [
    "When using multiple regression analysis, call as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JroSiyCK2Y4p"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KGFnf-R2Y4v"
   },
   "source": [
    "In addition to the  [official reference](http://scikit-learn.org/), it is also useful to look at the actual code example when investigating how to use (For example, if you search using a keyword such as \"multiple regression analysis Scikit-learn\" in a search engine, many codes An example is found).\n",
    "\n",
    "The algorithm of multiple regression analysis is defined as a class, and it needs to be instantiated to use the actual model. Instantiation `()` can be done by appending the class name ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4423bMx2Y4y"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BGDOxEL2Y42"
   },
   "source": [
    "That's it, you are ready to use multiple regression analysis. Using this model, learning of parameters is performed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zxe9Bd9_2Y44",
    "outputId": "6b58551b-1728-4d8e-f2fc-625b774963d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [2, 3],\n",
    "    [2, 5],\n",
    "    [3, 4],\n",
    "    [5, 9]\n",
    "])\n",
    "t = np.array([1, 5, 6, 8])\n",
    "\n",
    "model.fit(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWySchd_2Y47"
   },
   "source": [
    "The verification of the result is performed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vn_lB9C_2Y48",
    "outputId": "50c767fe-fa79-439c-e2e8-03f138328fa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzM69ESp2Y5E"
   },
   "source": [
    "In the case of regression, an index called the **coefficient of determination**, which is expressed by the following equation, is automatically calculated.\n",
    "\n",
    "$$\n",
    "R^{2} = 1 - \\dfrac{\\sum_{i}\\left( t_{i} - y_{i} \\right)^{2}}{\\sum_{i}\\left( t_{i} - \\bar{t} \\right)^{2}}\n",
    "$$\n",
    "\n",
    "In this way, Scikit-learn allows you to communicate with a simple interface. The good point of Scikit-learn is that any algorithm can be verified `.fit()` by learning, once the algorithm is decided first `.score()`.\n",
    "\n",
    "Also, although the contents differ depending on the algorithm, the parameters are also stored as instance variables, so they can be checked after learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mkj5j0as2Y5F",
    "outputId": "64b83d57-e6bc-4995-8bdf-5a236c25fd5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.57142857])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# „Éë„É©„É°„Éº„Çøw\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XUFluRmk2Y5L",
    "outputId": "3a442a2b-7f15-4633-b919-5f7f0e76bbfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14285714285714501"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# „Éê„Ç§„Ç¢„Çπb\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXxRn6-G2Y5W"
   },
   "source": [
    "###  Scikit-learn Applied \n",
    "Scikit-learn has many features to help implement machine learning. This section introduces how to use sample data sets and how to divide them.\n",
    "\n",
    "\n",
    "####  The use of sample data set \n",
    "First we will introduce the handling of sample data sets. Several data sets are provided in Scikit-learn. This time, I will use the data set of property prices by region in the suburbs of Boston, USA.\n",
    "\n",
    "In this data set $506$ Data is registered, and the average property price of the target area in each sample and the average property information of the target area as information linked to it (the number of rooms per unit, age, distance from the employment facility, etc. This includes demographic information (proportion of low-income earners, number of students per teacher, etc.), information on living environment (such as crime incidence), etc. The purpose of using this data set is to build a model that predicts the average property price, which is an output variable, using information such as property and demographics as an input variable. There are 13 kinds of input variables in total, and the details are as follows.\n",
    "\n",
    "* CRIM: Population1Per capita crime rate\n",
    "* ZN: 25,000Percentage of residential areas over square feet\n",
    "* INDUS: Percentage of area occupied by non-retail industry\n",
    "* CHAS: Dummy variables on the Charles River (1: Along the river, 0: otherwise)\n",
    "* NOX: concentration of nitrogen oxides\n",
    "* RM: Average number of rooms per residence\n",
    "* AGE: Percentage of properties built before 1940\n",
    "* DIS: Weighted distance from five Boston employment facilities\n",
    "* RAD: Access Index to Urban Main Roads\n",
    "* TAX: \\$ $10,000Property tax rate per\n",
    "* PTRATIO: Number of students per teacher\n",
    "* B: Index that represents the proportion of blacks\n",
    "* LSTAT: Percentage of low-income people\n",
    "\n",
    "`load_boston()` Let's execute the function and read the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwlomQyI2Y5Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbYctuQb2Y5b"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_pxoCJ2JVl5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dC8gbSa2Y5f"
   },
   "source": [
    "Variables are `boston`stored in dictionary form, and while looking at the contents of variables, we will find the ones corresponding to the input data and the output data. This time is the `data` input, and `target`corresponds to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1_Sk-Zg2Y5h"
   },
   "outputs": [],
   "source": [
    "X = boston['data']\n",
    "t = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "BOx8YETS2Y5o",
    "outputId": "28cab099-f10b-415f-9f86-dc7057a2e2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mEMzGp3p2Y5u",
    "outputId": "fa47d8c9-aca1-4f1a-bd96-2e345894c1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSmYtyiW2Y53"
   },
   "source": [
    "Input data and teacher data are stored in the form of NumPy, `.shape` and you can check the number of rows and columns by using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpihJ3YW2Y55",
    "outputId": "865b2c7e-5f5d-4856-fea9-30733e1ce00d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGTdy5F42Y5_",
    "outputId": "1cdf1bf6-0441-4066-d90c-849a658a5257"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8kyb0Dg2Y6F"
   },
   "source": [
    "Array of input data $X$ To $506$ Data for the case is stored. Each sample is $13$ Expressed as a dimensional vector, each of which is $13$ Represents a kind of input variable. Teacher data $t$ The scalar value of the average property price is stored as the output variable corresponding to the input variable in.\n",
    "\n",
    "#### 2.4.2.2. Of the data set division \n",
    "Next, I will introduce how to divide this learning data into **training data** and **test data** . If the performance of the model is evaluated using the data used at the time of learning, even if the performance of the learning data is high, the unknown data (taken from the same distribution) has not been seen during learning. There is a case. This **over-learning** is called. In order to prevent this, machine learning separates and evaluates test data for evaluating performance separately from learning data. This separation and verification is called **holdout method**.\n",
    "\n",
    "Scikit-learn provides functions to divide training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5CU-k1T2Y6G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76dR6BcP2Y6K"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxBmPpxi2Y6R",
    "outputId": "8ed254c6-d29d-4d86-ce6d-bf420ecabdb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyXYZGvv2Y6Y",
    "outputId": "cd6e39d0-4a4f-47fd-bdf0-fa3b2d6db442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 13)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJyIbtj42Y6b"
   },
   "source": [
    "`train_test_split()` The argument `test_size` of the function is the ratio of data used for verification,$0.3$ And the entire $30$% Is the test data. Also, `random_state` is a random number seed, and given a fixed seed value, you can ensure the repeatability of the division. Why do random numbers appear? $70$% Randomly selected from the whole, not for training and the rest for testing $70$% For training, the rest $30$% This is because% is selected for testing.\n",
    "\n",
    "Then, learning is performed using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQ8SwP0q2Y6e"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJlBMdGY2Y6i",
    "outputId": "a0a580fd-b9e4-4462-f2fd-6568d41df286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BARQrTC2Y6q"
   },
   "source": [
    "If you do verification, it is better to check both training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQdUNZ6S2Y6r",
    "outputId": "206d5075-9bc9-42da-926f-8b47fe58da2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644563391821222"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ë®ìÁ∑¥„Éá„Éº„Çø\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77Nms7tI2Y6u",
    "outputId": "dc7d522f-9acc-44b9-8843-d57001e43a0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673528086534723"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# „ÉÜ„Çπ„Éà„Éá„Éº„Çø\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuMZqq_w2Y6y"
   },
   "source": [
    "By examining not only test data but also training data, you can isolate problems when learning fails.\n",
    "\n",
    "**Underfitting** is a condition in which the model can not predict the training data with good accuracy . If underfitting is occurring, it is considered that the current machine learning algorithm does not capture the features of the data well, and change the algorithm or think of a transformation that can represent the features of the input data more appropriately I will try to improve it. Conversely, in the case of **overfitting (overlearning)** , it is confirmed that the features of the data are captured to some extent by the algorithm, so we will take measures to prevent the model from overlearning. As a typical method, it can be solved by adjusting the parameter value used for parameter learning of each algorithm called **hyper parameter** . Thus, even if the desired results are not obtained, it is important to verify both the training data and the test data, because the measures to be taken next will change as the situation is grasped. I understand.\n",
    "\n",
    "You can also do scaling with Scikit-learn. For example, the procedure to perform data normalization to convert to mean 0, standard deviation 1 is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nQiaY0-2Y6z"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_h7JFA1n2Y62"
   },
   "outputs": [],
   "source": [
    "# „Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMHDNYMtzaWF"
   },
   "source": [
    "Calculate mean and variance using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIm7zbMO2Y66",
    "outputId": "5cb09423-b4c4-4293-ed41-6f6416d8f609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Âπ≥Âùá„Å®ÂàÜÊï£„ÇíË®àÁÆó\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8DYxLtVDzexf"
   },
   "source": [
    "Scale training data and test data using the calculated mean and variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIERf0fi2Y7A"
   },
   "outputs": [],
   "source": [
    "# Â§âÊèõ\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vectWAXvzWC5"
   },
   "source": [
    "Note that we also use the mean and variance of training data when scaling test data. Since test data is an unknown data set for a model, using the average and variance of all the data combining training data and test data will give information to the model of test data that can not be originally known. I will. Therefore, scaling is performed using only training data for which models are available.\n",
    "\n",
    "Since the mean and variance of training data and test data are different, the average of test data scaled by the mean and variance of training data is the average0, Variance1Please note that it does not necessarily become."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sXWX8bm2Y7C",
    "outputId": "199d6dea-fb1e-4919-a196-6d677635bd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20416267 -0.49997924  1.54801583 ...  1.2272573   0.42454294\n",
      "   3.10807269]\n",
      " [-0.38584317  0.34677427 -0.58974728 ...  0.05696346  0.40185312\n",
      "  -0.66643035]\n",
      " [-0.33266283 -0.49997924  1.54801583 ...  1.2272573   0.39846135\n",
      "   0.63936662]\n",
      " ...\n",
      " [-0.38147768 -0.49997924 -0.15303077 ... -0.30312696  0.39659002\n",
      "  -0.30284441]\n",
      " [-0.3720831  -0.49997924 -0.59690657 ... -0.25811566  0.37588849\n",
      "   0.89967717]\n",
      " [-0.38289844 -0.49997924 -1.00641779 ... -0.84326258  0.42454294\n",
      "   0.31822262]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKqbj6if2Y7H",
    "outputId": "5cefe9cf-e319-4a97-f2a5-6028b88271a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39152624 -0.49997924 -1.12239824 ... -0.70822867  0.17086147\n",
      "  -0.72160487]\n",
      " [ 0.70825498 -0.49997924  1.00534187 ...  0.77714428  0.0648977\n",
      "  -0.41177872]\n",
      " [-0.38588517 -0.49997924  0.4025299  ... -0.93328518  0.38758427\n",
      "  -0.27454978]\n",
      " ...\n",
      " [ 1.6177735  -0.49997924  1.00534187 ...  0.77714428  0.42454294\n",
      "   2.59876943]\n",
      " [-0.34043865 -0.49997924 -0.1687812  ... -0.03305915  0.42454294\n",
      "  -1.11772962]\n",
      " [-0.39601293 -0.49997924 -1.27417512 ...  0.10197476  0.39202867\n",
      "  -1.02294263]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-_U59bUNgLB"
   },
   "source": [
    "In addition, Scikit-learn supports various machine learning algorithms such as logistic regression, support vector machines, and random forests.\n",
    "\n",
    "For these as well, as with multiple regression analysis, a model is instantiated, and learning data is used as an argument for .`.fit()` training with a `.score()` function, and can be evaluated using a function.\n",
    "\n",
    "Please refer to [Scikit-learn](https://scikit-learn.org/) site and commentary site etc. for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Introduction to ML libs",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
