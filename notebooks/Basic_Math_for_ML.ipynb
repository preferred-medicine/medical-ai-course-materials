{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_atjBBsxuKH7"
   },
   "source": [
    "# 1. basis of the mathematics required to machine learning\n",
    "\n",
    "In this chapter, we will briefly introduce three of the fundamentals of mathematics necessary for machine learning including deep learning, \"differential\" \"linear algebra\" \"probability / statistics\".\n",
    "\n",
    "\n",
    "## 1.1. What is machine learning?\n",
    "\n",
    "Machine learning is a method of acquiring a function that extracts patterns such as rules and judgment criteria contained in the data by computer learning from data, and predicting new data using that function. Machine learning technology is now applied to a wide range of fields such as image recognition, speech recognition, document classification, medical diagnosis, spam mail detection, product recommendation.\n",
    "\n",
    "Here, (a function that is acquired by the learning **model** will be called) is often **parameters** have been characterized by a determines the behavior of the function if determined parameters. Considering the function of a straight line as the simplest example, this is a gradient $a$ and a cut point $b$It is characterized by two parameters,$f(x; a, b) = ax + b$ I will write like this. (here $x$ is called the input variable of the function . Also $Ôºõ$ Parameters are written after the). The goal of machine learning is to determine these parameters using learning data.\n",
    "\n",
    "Machine learning determines parameters that will learn, that is, make the desired behavior by minimizing (or maximizing) the **objective function** . Therefore, the objective function is designed to take a small (or large) value if the output value of the model is desired, and a large (or small) value if not.\n",
    "\n",
    "For example, as a learning data, a data set composed of input and output pairs $D=\\left((x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n) \\right)$ You are given. Here,$x_{i}$ The input of the second sample,$y_{i}$ Represents the output of the second sample. A straight line that passes as close as possible to these points $f(x; a, b) = ax + b$ You want to learn. If the output is a real value, the parameter $\\theta = (a, b)$ Then, the following objective function is often used.\n",
    "\n",
    "$L( \\theta) = \\sum_{i=1}^n (y_i - f(x_i; \\theta))^2$\n",
    "\n",
    "Consider minimizing this function. In the above equation, the predicted value of the model $f(x_i; \\theta)$ And the correct answer $y_i$ We calculate the total value by finding the square error between and. Only when prediction and correct answer are consistent with all data $0$ Otherwise, it takes a large positive value as it makes a big mistake. Functions that measure the degree of mistake are sometimes called **loss functions** in particular . Further, purposes such as obtaining the total value of the penalty for the entire data given set function **cost function** sometimes also called. The argument of the objective function is $\\theta$ It is optimal to minimize the objective function $\\theta$, The data set $D$ Function to predict accurately$f(x; \\theta)$Will be obtained\n",
    "\n",
    "In order to solve the problem of minimizing the objective function, knowledge of differentiation and linear algebra is required. However, knowledge of all differentiation and linear algebra is not necessary. After that, I will explain the minimum knowledge necessary for understanding machine learning.\n",
    "\n",
    "\n",
    "## 1.2. Derivative \n",
    "\n",
    "Differentiation in the input value of the function corresponds to **the slope** of the **tangent** of the graph at that point and can be expressed as a straight line that contacts the function as shown below.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/01.png)\n",
    "\n",
    "For example, in the function shown above,$a$ The tangent line at the point of $+3$ It has become. The inclination of the straight line rising to the right is a positive value.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/02.png)\n",
    "\n",
    "On the other hand, in the figure below $b$  , The slope is -1, and the tangent line is a straight downward sloping straight line.\n",
    "\n",
    "If the value of the objective function can be calculated for all parameters, it is possible to select the minimum value of the objective function from among them, but such is usually impossible. However, if you can calculate the derivative with respect to parameters at a certain point, you can determine the slope of the tangent and you can see how the objective function changes when changing the parameters, even if you do not know the graph shape across the parameter. Based on this information, you can update the parameters to reduce the objective function.\n",
    "\n",
    "Returning to the explanation of differentiation again, I will look in detail about its definition, multivariable input, and multivariable output.\n",
    "\n",
    "\n",
    "### 1.2.1. Slope of a straight line passing through two \n",
    "\n",
    "First, in order to understand the principle of differentiation, the slope of a straight line passing through two points shown in the figure below $a$ Let's ask.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/04.png)\n",
    "\n",
    "At this time, the inclination $a$ ,\n",
    "\n",
    "$$\n",
    "a = \\dfrac{f(x_{2}) - f(x_{1})}{x_{2}-x_{1}}\n",
    "$$\n",
    "\n",
    "You can get.\n",
    "\n",
    "### 1.2.2. Slope of tangent at one point\n",
    "\n",
    "Next, we will find the slope of the tangent of the given function. To do that, the **limit** idea is necessary. In the limit, when the variable approaches a certain value as close as possible, we will consider how the function described by that variable behaves. In order to express the limit,$\\lim$ The symbol 'common' is used. For example,\n",
    "\n",
    "$$\n",
    "\\displaystyle \\lim _{x\\rightarrow 0}3x=3\\times 0=0\n",
    "$$\n",
    "$x$ The variable $0$ The value of the expression will be given when approaching it.\n",
    "\n",
    "Then, some point in the figure below $x$ Slope of tangent at $a$ Let's seek for.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/05.png)\n",
    "\n",
    "Tangent can be obtained by combining the straight line passing through the two points I thought earlier and the limit.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/06.png)\n",
    "\n",
    "First, $x$  From $h$ Only a point away $x+h$ Consider the slope of the straight line passing through the two points. next $h$ to $h \\rightarrow 0$ If you make it as small as you can, the starting point and ending point of the line converge to 1 point and you can think of it as a tangent at 1 point. Looking at this expression\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a &=\\lim _{h\\rightarrow 0}\\dfrac {f\\left( x+h\\right) -f\\left( x\\right) }{\\left( x+h\\right) -x}\\\\\n",
    "&=\\lim _{h\\rightarrow 0}\\dfrac {f\\left( x+h\\right) -f\\left( x\\right) }{h}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The above equation is called a **derivative** ,ùëì‚Ä≤(ùë•)It is represented by. It is said to **differentiate** finding **derivatives**. Also, as a way of using the symbols,\n",
    "\n",
    "$$\n",
    "(\\cdot)' = \\dfrac{d}{dx}(\\cdot)\n",
    "$$\n",
    "\n",
    "It can be expressed as follows. this $d$ The symbol \"differentiation\" represents,$d(\\cdot)$Is the change in the value of the object, $dx$ But $x$ It shows the amount of change and expresses the limit when decreasing them. This notation is cumbersome, but the variable $x$Ôºå$y$ If there are multiple such as,$x$ Whether differentiating,$y$ It becomes clear whether to differentiate, so you can express accurately.\n",
    "\n",
    "\n",
    "### 1.2.3. Differentiation\n",
    "\n",
    "There are some useful formulas for differentiation to keep in mind, so I will introduce some of them below ($c$Is a constant,$x$ Represents a variable).\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left( c\\right) ^{'}&=0 \\\\\n",
    "\\left( x\\right)^{'}&=1\\\\\n",
    "\\left( cf(x) \\right)^{'} &= c f'(x) \\\\\n",
    "\\left( x^{n} \\right)^{'} &=nx^{n-1} \\\\\n",
    "\\left( f(x) + g(x) \\right) ^{'} &=f^{'}(x)+g^{'}(x) \\\\\n",
    "\\left( f(x) g(x) \\right) ^{'} &= f^{'}(x)g(x) + f(x)g^{'}(x) \\\\\n",
    "\\left( f(g(x)) \\right) ^{'} &= \\frac{df(u)}{du}\\frac{du}{dx}, u = g(x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For example, consider the following differentiation.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left( 3x^{2} + 4x + 5 \\right)' &= \\left( 3x^{2} \\right)' + \\left( 4x \\right)' + \\left( 5 \\right)' \\\\ \n",
    "&= 3 \\times \\left( x^{2} \\right)' + 4 \\times \\left( x \\right)' + 5 \\times \\left( 1 \\right)' \\\\ \n",
    "&= 3 \\times 2x + 4 \\times 1 + 5 \\times 0  \\\\ \n",
    "&= 6x + 4 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "n this way, the derivation of each term with respect to the sum is differentiated with respect to each term and even if it is summed, the relationship of equality is established. Also, when differentiating each term, the coefficients of the constant (the number of variables) can be placed outside the differential operation. These are the properties called **linearity** of differential , and by using this property, we can easily calculate the differentiation.\n",
    "\n",
    "\n",
    "\n",
    "### 1.2.4. Derivative of the synthetic function \n",
    "\n",
    "In detail later in the chapter, in general machine learning it is necessary to consider the **differentiation** of complicated **synthetic functions** . As a simple example,\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{ (3x + 4)^{2} \\right\\}'\n",
    "$$\n",
    "\n",
    "Consider to calculate. In this equation,$3x+4$ And the inner part $(\\cdot)^{2}$ It is composed of the outside part. This equation $(9x^2 + 24x + 16)'$‚Ä≤It is OK to calculate the derivative after it has been expanded, but it will be hard to develop it as it becomes the third power or the fourth power. The useful idea here is the differentiation of the composite function. It is an expression that appeared at the end of the differentiation formula introduced earlier. Differentiation of the composite function can be obtained by doing inner differentiation and outer differentiation and multiplying the result with each other. When external differentiation, argument of function is regarded as input and differentiation is taken on its input.\n",
    "\n",
    "\n",
    "\n",
    "Well then,$(3x+4)^2$) Consider the differentiation of the function.\n",
    "\n",
    "\n",
    "First, inside functions ùë¢=(3ùë•+4) And,\n",
    "First, inside functions  $u = (3x+4)$ And,\n",
    "\n",
    "$$\n",
    "\\left\\{ (3x + 4)^{2} \\right\\}' = (u^{2})'\n",
    "$$\n",
    "\n",
    "Will do. here,$(\\cdot)'$ We need to think more strictly. now,$x$ When $u$ Two variables have appeared,$(\\cdot)'$ Then,$x$ Differentiating with $u$ You can not distinguish whether you are differentiating with. So, it looks somewhat complicated, but as I mentioned earlier $d$ If you strictly describe the variable to be differentiated by the notation using\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left\\{ (3x + 4)^{2} \\right\\}' &= \\dfrac{d}{dx} \\left\\{ (3x + 4)^{2} \\right\\} \\\\\n",
    "&= \\dfrac{du}{dx} \\dfrac{d}{du} (u^2) \\\\\n",
    "&= \\dfrac{d}{du} (u^{2}) \\cdot \\dfrac{d}{dx} (3x + 4) \\\\ \n",
    "&= 2u \\cdot 3 \\\\ \n",
    "&= 6u = 6(3x + 4) = 18x + 24 \\\\ \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Learn this calculation method firmly as scenes using derivative of composite function appear many times in learning of neural network.\n",
    "\n",
    "\n",
    "### 1.2.5 Partial derivative\n",
    "\n",
    "In machine learning, one input variable $x$ Output variable from $y$ The case of predicting is rare, basically it is possible to use multiple input variables $x_{1}$, $x_{2}$, $\\ldots$, $x_{M}$ Output variable using $y$ It handles multivariable functions that predicts. For example, when predicting rent, it is expected that it is more accurate to predict not only the size of the room, but also the distance from the station and the rate of crime occurrence. Multiple inputs $x_1, x_2, \\ldots, x_M$ A function that takes into consideration $f(x_1, x_2, \\ldots, x_M)$ Is called a multivariable function. In this multivariable function,$x_m$ Differentiating by focusing attention only on **partial derivatives** is called **partial differentiation** ,\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial}{\\partial x_{m}} f(x_{1}, x_{2}, \\ldots, x_{M})\n",
    "$$\n",
    "\n",
    "It is expressed as follows. The symbol representing the differentiation, $d$ From $\\partial$ As a calculation, $\\dfrac{\\partial}{\\partial x_{m}}$ In the case of $x_{m}$ Think of it as a constant except for $x_{m}$ We focus only on the differentiation. (However, if the input variable is not independent of other input variables, it can not be thought of as a constant.There is no such case in this lecture.)\n",
    "\n",
    "Let's check the flow of concrete calculation by example.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial x_{1}}\\left( 3x_{1}+4x_{2}\\right) &=\\dfrac {\\partial }{\\partial x_{1}}\\left( 3x_{1}\\right) +\\dfrac {\\partial }{\\partial x_{1}}\\left( 4x_{2}\\right) \\\\\n",
    "&=3\\times \\dfrac {\\partial }{\\partial x_{1}}\\left( x_{1}\\right) +4x_{2}\\times \\dfrac {\\partial }{\\partial x_{1}}\\left( 1\\right) \\\\\n",
    "&=3\\times 1+4x_{2}\\times 0\\\\\n",
    "&= 3\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Even partial derivatives can apply the same formulas as differentiation. In this case,$x_{1}$ To focus only on,$x_{2}$ If you grasp that it treats it as a constant, you should be able to understand the flow of the above calculation.\n",
    "\n",
    "\n",
    "## 1.3. Linear\n",
    "\n",
    "### 1.3.1. What is linear algebra? \n",
    "\n",
    "Next, I will explain about **linear algebra** . Vectors, matrices, inverse matrices etc. will appear.\n",
    "\n",
    "Introducing linear algebra makes it possible to simply describe the relationship between multiple variables, so it will appear frequently in machine learning. It is a very important concept, so let's definitely wear it.\n",
    "\n",
    "### 1.3.2. Scalar, vector, matrix, \n",
    "\n",
    "We first explain four scalars, vectors, matrices, and tensors used in linear algebra.\n",
    "\n",
    "**A scalar** is a value or variable. For example,\n",
    "$$\n",
    "x, \\ y,\\  M,\\  N\n",
    "$$\n",
    "\n",
    "It is expressed as follows. A scalar is used to represent a single quantity such as temperature or height.\n",
    "\n",
    "**A vector** is a collection of a plurality of scalars arranged in a vertical direction (or a horizontal direction)\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "x_{3}\n",
    "\\end{bmatrix}, \\\n",
    "\\boldsymbol{y}=\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{N}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is expressed as follows. The notation of a vector is often expressed in boldface, so it can distinguish between scalar and vector. When expressing a vector, columns aligned in the vertical direction are called column vectors, and those arranged in the horizontal direction are called row vectors. Since there are many papers and reference books that use column vectors in mathematics and machine learning, unless otherwise specified, we will refer to column vectors when expressed simply as vectors.\n",
    "\n",
    "A matrix is obtained by arranging a plurality of vectors of the same size,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X}=\\begin{bmatrix}\n",
    "x_{11} & x_{12} \\\\\n",
    "x_{21} & x_{22} \\\\\n",
    "x_{31} & x_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is expressed as follows. The size of the matrix is represented by rows and columns. For example,$\\boldsymbol{X}$ Is 3 rows by 2 columns and is called a matrix of size (3, 2). In many cases, matrices are written in uppercase letters or upper case bold letters.\n",
    "\n",
    "**Tensors** are generalized concepts of vectors and matrices, vectors can be expressed as tensors on the first floor and matrices as tensors on the second floor. Also, as shown in the figure, the further arranged in the depth direction is the tensor on the third floor. For example, in the case of digital representation of a color image, it is common to use a color space such as RGB (Red Green Blue) for each pixel constituting an image, and by using three axes (row number, column number, color) In order to specify one value, it is represented by the tensor on the third floor. When including this course, if it is expressed simply as a tensor, it often points to the tensor of the third floor or more, so please be careful.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/07.png)\n",
    "\n",
    "\n",
    "In linear algebra $\\boldsymbol{y}$ Ya $\\boldsymbol{X}$ It is easy to understand what type of numerical value is handled because it deforms expressions with only letters like this, but be careful not to lose sight of its shape by always keeping aware of vectors etc Let's see.\n",
    "\n",
    "\n",
    "|        | Â∞èÊñáÂ≠ó         | Â§ßÊñáÂ≠ó         |\n",
    "| ------ | -------------- | -------------- |\n",
    "| Á¥∞ÊñáÂ≠ó | „Çπ„Ç´„É©„Éº„ÅÆÂ§âÊï∞ | „Çπ„Ç´„É©„Éº„ÅÆÂÆöÊï∞ |\n",
    "| Â§™ÊñáÂ≠ó | „Éô„ÇØ„Éà„É´       | Ë°åÂàóÔºå„ÉÜ„É≥„ÇΩ„É´ |\n",
    "\n",
    "\n",
    "### 1.3.3. Addition, subtraction \n",
    "\n",
    "Let's memorize matrices and vector operations. The addition is established only between matrices of the same size and vectors, and is defined as follows.\n",
    "$$\n",
    "\\begin{aligned}&\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "4 \\\\\n",
    "5 \\\\\n",
    "6\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "1+4 \\\\\n",
    "2+5 \\\\\n",
    "3+6\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "5 \\\\\n",
    "7 \\\\\n",
    "9\n",
    "\\end{bmatrix}\\\\\n",
    "&\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "7 & 8 & 9 \\\\\n",
    "10 & 11 & 12 \n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "1+7 & 2+8 & 3+9 \\\\\n",
    "4+10 & 5+11 & 6+12\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "8 & 10 & 12 \\\\\n",
    "14 & 16 & 18\n",
    "\\end{bmatrix}\\end{aligned}\n",
    "$$\n",
    "\n",
    "In this way add the corresponding places with the **elements** in the matrix or vector . Subtraction is similar. Let's remember that **calculation is not established unless it is the same size**.\n",
    "\n",
    "\n",
    "### 1.3.4. Dot inner\n",
    "\n",
    "Dot product can be defined between vectors of the same size. The inner product is the sum of the corresponding values of the same position and adding them together.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}& \\begin{bmatrix}\n",
    "1 & 2 & 3\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "4 \\\\ \n",
    "5 \\\\ \n",
    "6\n",
    " \\end{bmatrix} = 1 \\times 4 + 2 \\times 5  + 3 \\times 6 = 32 \\end{aligned}\n",
    "$$\n",
    "\n",
    "### 1.3.5. Multiplication (matrix multiplication) \n",
    "\n",
    "There are multiple kinds of matrix multiplication, such as matrix multiplication, cross product, element product (Hadamard product). Here we explain the most commonly used **matrix product** . Unless explicitly stated below, matrix multiplication refers to matrix multiplication.\n",
    "\n",
    "matrix $A$ And matrix $B$ The matrix product of $A$With each row of $B$ It is defined as an array of dot products of each column of. For example, the inner product of the row vector of the second row of matrix A and the column vector of the third column of matrix B corresponds to the second row and the third column of matrix C of the result.\n",
    "\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/08.png)\n",
    "\n",
    "And the condition that the inner product is defined is that the size of the vector is equal, but also here it holds that the size of row A (= the number of columns of A) and the size of the column of B (= B The number of lines) must match. The result is a matrix consisting of the number of rows of A and the number of columns of B.\n",
    "\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/09.png)\n",
    "\n",
    "Also, as one of the properties where matrix multiplication is significantly different from scalar product,$AB$ When $BA$ It is not necessarily the same thing.\n",
    "\n",
    "Matrix products are used for many problems of linear algebra and machine learning. Although there is no operation equivalent to division in the matrix, using the inverse matrix described later\n",
    "$4 / 2 = 4 \\times \\dfrac{1}{2}$ Describe the division as multiplication of reciprocal (inverse matrix) as shown in.\n",
    "\n",
    "Then, based on the confirmation of the calculation condition, please solve the following three as exercises.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\left( 1\\right) \n",
    "\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "3 \\\\ \n",
    "4\n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 2\\right) \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\ \n",
    "3 & 4 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "5 \\\\ \n",
    "6 \n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 3\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 & 4 \\\\ \n",
    "5 & 6 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "1\n",
    "\\end{bmatrix} \n",
    "\\end{aligned} \n",
    "$$ \n",
    "\n",
    "Here is the answer. \n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "&\\left( 1\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "4 \n",
    "\\end{bmatrix} = 1\\times 3 + 2 \\times 4 = 11\\\\ \n",
    "&\\left( 2\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \\\\ \n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "5 \\\\ \n",
    "6\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "1 \\times 5 + 2 \\times 6 \\\\ \n",
    "3 \\times 5 + 4 \\times 6 \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "17 \\\\ \n",
    "39 \n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 3\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 & 4 \\\\ \n",
    "5 & 6 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "1 \n",
    "\\end{bmatrix} \n",
    "=\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\times 3 + 4 \\times 1 \\\\ \n",
    "5 \\times 3 + 6 \\times 1 \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "13 \\\\ \n",
    "21 \n",
    "\\end{bmatrix}\n",
    "= 1 \\times 13 + 2 \\times 21 \n",
    "=55\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "Calculations of this form often appear in machine learning. Let's keep in mind that the matrix product changes shape after operation.\n",
    "\n",
    "### 1.3.6. Transpose \n",
    "\n",
    "Vectors are based on portrait oriented column vectors, but sometimes you may want to use a vector of landscape orientation. Therefore, the operation of swapping vertically oriented vectors to transverse vectors and horizontally oriented vectors into vertically oriented vectors is called **Transpose)ùëá** I will write it. For example,\n",
    "$$\n",
    "\\begin{aligned}\\boldsymbol{x}&=\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3\n",
    "\\end{bmatrix}, \\ \n",
    "\\boldsymbol{x}^{T}=\\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} \\\\\n",
    "\\boldsymbol{X}&=\\begin{bmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "3 & 6\n",
    "\\end{bmatrix}, \\\n",
    "\\boldsymbol{X}^{T}=\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}\\end{aligned}\n",
    "$$\n",
    "\n",
    "It looks like. On transposition to a matrix, the size is$(N, M)$ From $(M, N)$ become,$i$ line $j$ After transposing the value of the column $j$ line $i$ It becomes the value of the column column. It is a good idea to remember the following as the transpose formula.\n",
    "\n",
    "\n",
    "„ÅÆ„Çà„ÅÜ„Å´„Å™„Çä„Åæ„ÅôÔºéË°åÂàó„Å´ÂØæ„Åô„ÇãËª¢ÁΩÆ„Åß„ÅØÔºå„Çµ„Ç§„Ç∫„Åå$(N, M)$„Åã„Çâ$(M, N)$„Å´„Å™„ÇäÔºå$i$Ë°å$j$ÂàóÁõÆ„ÅÆÂÄ§„ÅåËª¢ÁΩÆÂæå„Å´„ÅØ$j$Ë°å$i$ÂàóÁõÆ„ÅÆÂÄ§„Å´„Å™„Çä„Åæ„ÅôÔºéËª¢ÁΩÆ„ÅÆÂÖ¨Âºè„Å®„Åó„Å¶Ê¨°„ÇíË¶ö„Åà„Å¶„Åä„Åè„Å®„Çà„ÅÑ„Åß„Åó„Çá„ÅÜÔºé\n",
    "\n",
    "$$\n",
    "\\begin{aligned}&\\left( 1\\right) \\ \\left( \\boldsymbol{A}^{T}\\right)^{T}=\\boldsymbol{A}\\\\\n",
    "&\\left( 2\\right) \\ \\left( \\boldsymbol{A}\\boldsymbol{B}\\right) ^{T}=\\boldsymbol{B}^{T}\\boldsymbol{A}^{T}\\\\\n",
    "&\\left( 3\\right) \\ \\left( \\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C}\\right) ^{T}=\\boldsymbol{C}^{T}\\boldsymbol{B}^{T}\\boldsymbol{A}^{T}\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### 1.3.7. Vector, size of matrix\n",
    "\n",
    "After matrix multiplication, matrix size will change. size is $(L, M)$ With a matrix of $(M ,N)$ The matrix multiplication result of $(L, N)$. For example, when summarizing how the sizes of the three exercise problems changed,\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/10.png)\n",
    "\n",
    "(3) Note that the result of the first vector and matrix are horizontal vectors and result in (1). Also, if the size of a dimension becomes 1, the dimension may be deleted, the vector may be a scalar, and the matrix may be a vector.\n",
    "\n",
    "\n",
    "### 1.3.8. Unit matrix\n",
    "\n",
    "Scalar value1,$10 \\times 1 = 10$ It has the property that it does not change even if that number is multiplied by an arbitrary number. In matrices, matrices that work like this are **unit matrices**.\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{I}=\\begin{bmatrix}\n",
    "1 & 0 & \\ldots  & 0 \\\\\n",
    "0 & 1 & \\ldots  & 0 \\\\\n",
    "\\vdots & \\vdots  & \\ddots  & \\vdots  \\\\\n",
    "0 & 0 & \\ldots  & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "It has the shape as above and the symbol $\\boldsymbol{I}$ It is common to be represented by. The diagonal elements of a matrix are called **diagonal elements** , and the other elements are called offdiagonal elements. An identity matrix is a **square matrix** ( **a matrix** whose number of row elements matches the number of column elements) such that the diagonal elements are 1 and the off-diagonal elements are 0 . For example, in the case of a 2 √ó 2 matrix,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{I} =\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In the case of a 3 √ó 3 matrix,Ôºå\n",
    "\n",
    "$$\n",
    "\\boldsymbol{I}=\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If you want to specify the size of the matrix,$I_{n}$ ($n√ón$ and subscripts to distinguish them.\n",
    "\n",
    "An identity matrix is an arbitrary matrix $\\boldsymbol{A}$ The following holds.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{A}\\boldsymbol{I}&=\\boldsymbol{A}\\\\\n",
    "\\boldsymbol{I}\\boldsymbol{A}&=\\boldsymbol{A}\n",
    "\\end{aligned}\n",
    "$$\n",
    "As explained earlier, in order for multiplication of a matrix to be established,$I$ The size of $A$ It must be the same as.\n",
    "\n",
    "By actually calculating and checking whether the value does not change from the original matrix,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "&=\\begin{bmatrix}\n",
    "1\\times 1+2\\times 0 & 1\\times 0+2\\times 1 \\\\\n",
    "3\\times 1+4\\times 0 & 3\\times 0+4\\times 1\n",
    "\\end{bmatrix}\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As you can see, it matches the original value.\n",
    "\n",
    "\n",
    "### 1.3.9. Inverse matrix\n",
    "\n",
    "**The inverse matrix** is a matrix that becomes an identity matrix when multiplied by the original matrix, and the reciprocal number in the scalar ($2 \\times 2^{-1} = 1$) It is a matrix corresponding to. matrix $\\boldsymbol{A}$, Its inverse matrix is $\\boldsymbol{A}^{-1}$ I will write like this.\n",
    "\n",
    "When the definition of the inverse matrix is represented by a mathematical expression,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{A}\\boldsymbol{A}^{-1}=\\boldsymbol{I}\\\\\n",
    "\\boldsymbol{A}^{-1}\\boldsymbol{A}=\\boldsymbol{I}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "here,$\\boldsymbol{I}$ Is the unit matrix of the previous time. size is$2 \\times 2$ Ya $3 \\times 3$ In the case of a small matrix such as small matrix, there are formulas for inverse matrix calculation, but in machine learning a matrix of larger size ( $1000 \\times 1000$ Etc.), it is necessary to deal with calculation methods for efficient inversion of inverse matrices.\n",
    "\n",
    "\n",
    "\n",
    "Inverse matrices do not always exist. A matrix in which an inverse matrix exists is called a **regular matrix** (conditions for the matrix being regular are not explained this time).\n",
    "\n",
    "\n",
    "### 1.3.10. Linear joins and quadratic \n",
    "\n",
    "As a form often appearing in machine learning equations, $\\boldsymbol{b}^{T}\\boldsymbol{x}$  When $\\boldsymbol{x}^{T}\\boldsymbol{A}\\boldsymbol{x}$ There are two forms. The former linear combination or linear combination , the latter quadratic form has been called. For scalars, linear expressions $ax+b$Ôºâ And quadratic equation Ôºà$ax^2+bx+c$Ôºâ, But it is an extension of it to a vector.\n",
    "\n",
    "Looking at the contents of the linear combination calculation,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{b}&=\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix},\\ \n",
    "\\boldsymbol{x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\boldsymbol{b}^{T}\\boldsymbol{x}&=\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}=x_{1}+2x_{2}\\end{aligned}\n",
    "$$\n",
    "\n",
    "like $\\boldsymbol{x}$ It is an element of $x_{1}$ Or $x_{2}$ As you can see, it is a primary equation.\n",
    "\n",
    "Also, if you check the contents of the calculation for the quadratic form as well,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{A}&=\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix},\\ \n",
    "\\boldsymbol{x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\boldsymbol{x}^{T}\\boldsymbol{A}\\boldsymbol{x}\n",
    "&=\\begin{bmatrix} x_{1} & x_{2}\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\begin{bmatrix}x_{1} & x_{2}\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1}+2x_{2} \\\\\n",
    "3x_{1}+4x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "&=x_{1}\\left( x_{1}+2x_{2}\\right) +x_{2}\\left( 3x_{1}+4x_{2}\\right) \\\\\n",
    "&=x^{2}_{1}+5x_{1}x_{2}+4x_{2}^{2}\\end{aligned}\n",
    "$$\n",
    "\n",
    "It turns out that each element has a quadratic expression.\n",
    "\n",
    "Therefore, an arbitrary quadratic function\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}^{T}\\boldsymbol{A}\\boldsymbol{x} + \\boldsymbol{b}^{T}\\boldsymbol{x} + c\n",
    "$$\n",
    "\n",
    "It can be expressed in the form of. here, $c$ Is a constant term of a scalar.\n",
    "\n",
    "\n",
    "### 1.3.11. Differential by the vector and gradient\n",
    "\n",
    "Differential is described as the amount of change in function value when input is changed. Likewise, if the input of the function is a vector, we can think of a differentiation with a vector. Calculate partial derivatives for each vector component of the function, and arrange them into vectors called **gradients**.\n",
    "\n",
    "Before introducing the gradient calculation, let's calculate the following example.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{b}&=\\begin{bmatrix}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}, \\ \n",
    "\\boldsymbol{x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\boldsymbol{b}^{T}\\boldsymbol{x}&=\\begin{bmatrix}\n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\n",
    "=3x_{1}+4x_{2}\\end{aligned}\n",
    "$$\n",
    "\n",
    "this $\\boldsymbol{b}^{T}\\boldsymbol{x}$  With vector $\\boldsymbol{x}$ ,\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{b}^{T}\\boldsymbol{x}\\right)\n",
    "$$\n",
    "\n",
    "„Å®It is expressed. It is said **to differentiate** this with a **vector** . In this example,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{b}^{T}\\boldsymbol{x}\\right) &=\\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( 3x_{1}+4x_{2}\\right) \\\\\n",
    "&=\\begin{bmatrix}\n",
    "\\dfrac {\\partial }{\\partial x_{1}} \\left( 3x_{1}+4x_{2}\\right)  \\\\\n",
    "\\dfrac {\\partial }{\\partial x_{2}} \\left( 3x_{1}+4x_{2}\\right) \n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As we go forward with the calculation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\dfrac {\\partial }{\\partial x_{1}}\\left( 3x_{1}+4x_{2}\\right) &=\\dfrac {\\partial }{\\partial x_{1}}\\left( 3x_{1}\\right) +\\dfrac {\\partial }{\\partial x_{1}}\\left( 4x_{2}\\right) \\\\\n",
    "&=3\\times \\dfrac {\\partial }{\\partial x_{1}}\\left( x_{1}\\right) +4x_{2}\\times \\dfrac {\\partial }{\\partial x_{1}}\\left( 1\\right) \\\\\n",
    "&=3\\times 1+4x_{2}\\times 0\\\\\n",
    "&=3\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\dfrac {\\partial }{\\partial x_{2}}\\left( 3x_{1}+4x_{2}\\right)&=\\dfrac {\\partial }{\\partial x_{2}}\\left( 3x_{1}\\right) +\\dfrac {\\partial }{\\partial x_{2}}\\left( 4x_{2}\\right) \\\\\n",
    "&=3x_{1}\\times \\dfrac {\\partial }{\\partial x_{2}}\\left( 1\\right) +4\\times \\dfrac {\\partial }{ax_{2}}\\left( x_{2}\\right) \\\\\n",
    "&=3x_{1} \\times 0 + 4 \\times 1 \\\\\n",
    "&= 4\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The following calculation results are obtained.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{b}^{T}\\boldsymbol{x}\\right) \n",
    "&=\\begin{bmatrix}\n",
    "\\dfrac {\\partial }{\\partial x_{1}} \\left( 3x_{1}+4x_{2}\\right)  \\\\\n",
    "\\dfrac {\\partial }{\\partial x_{2}} \\left( 3x_{1}+4x_{2}\\right) \n",
    "\\end{bmatrix} =\\begin{bmatrix}\n",
    "3  \\\\\n",
    "4\n",
    "\\end{bmatrix} = \\boldsymbol{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Another question, let's consider the following example.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{b}&=\\begin{bmatrix}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}, \\ \n",
    "\\boldsymbol{x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{b}\\right) &=\\begin{bmatrix}\n",
    "\\dfrac {\\partial }{\\partial x_{1}}\\left( 3 \\right)  \\\\\n",
    "\\dfrac {\\partial }{\\partial x_{2}}\\left( 4 \\right) \n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}=\\boldsymbol{0}\\end{aligned}\n",
    "$$\n",
    "\n",
    "If the variable to be subjected to partial differentiation is not included, its partial differential is 0. Elements0A vector consisting solely of it is called a **zero (zero) vector**.\n",
    "\n",
    "Based on these, let's summarize as official.\n",
    "\n",
    "Ôºé\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\left( 1\\right) \\ \\dfrac {\\partial}{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{c} \\right) = \\boldsymbol{0}\\\\\n",
    "&\\left( 2\\right) \\ \\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{b}^{T}\\boldsymbol{x}\\right) = \\boldsymbol{b}\\\\\n",
    "&\\left( 3\\right) \\ \\dfrac {\\partial }{\\partial \\boldsymbol{x}}\\left( \\boldsymbol{x}^{T}\\boldsymbol{A}\\boldsymbol{x}\\right) =\\left( \\boldsymbol{A}+\\boldsymbol{A}^{T}\\right) \\boldsymbol{x}\\end{aligned}\n",
    "$$\n",
    "\n",
    "(1)„Å®(2) „ÅØ„Åô„Åß„Å´Â∞éÂá∫Ê∏à„Åø„Åß„ÅôÔºé(3) „ÅØÂ∞éÂá∫„ÅåÂ∞ë„ÅóË§áÈõë„Å™„ÅÆ„ÅßÁúÅÁï•„Åó„Åæ„Åô„ÅåÔºåÊï∞ÂÄ§„Çí‰ª£ÂÖ•„Åó„Å¶Á¢∫Ë™ç„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑÔºé„Åì„ÅÆ3„Å§„ÅÆÂÖ¨Âºè„ÅØÊ©üÊ¢∞Â≠¶Áøí„ÇíÂ≠¶„Çì„Åß„ÅÑ„Åè‰∏ä„ÅßÈùûÂ∏∏„Å´ÈáçË¶Å„Å™ÂÖ¨Âºè„Å®„Å™„Çä„Åæ„Åô„ÅÆ„ÅßÔºåÂøÖ„ÅöË¶ö„Åà„Å¶„Åä„Åç„Åæ„Åó„Çá„ÅÜÔºé\n",
    "\n",
    "There are many other formulas in such matrices etc. It is also important to know what formulas are available when reading papers and the like. For example, please refer to [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf). \n",
    "\n",
    "In addition, this time we introduced gradients as derivatives of the multiple input single output function, but the Jacobian matrix (Jacobian), which is a derivative of the multiple input multiple output function, is also necessary to understand the error back propagation method of the neural network However, in most cases it is sufficient to memorize that the Jacobian matrix multiplied by a matrix is its transposed matrix.) For more information, please refer to, for example, The [The Matrix Calculus You Need For Deep Learning](https://arxiv.org/abs/1802.01528).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.4. Probability and Statistics \n",
    "\n",
    "### 1.4.1. What are probability and statistics available for? \n",
    "\n",
    "Speaking of machine learning, I think that there are many studying in the image such as probability and statistics, but if it is a simple algorithm, it can explain by just understanding differential and linear algebra, probability and statistics come out There is nothing to come. So, why are probability and statistics necessary?\n",
    "\n",
    "Machine learning is a method of handling data. Data is a collection of individual events, but the purpose of learning is to capture the universality and the law behind that data. Probability can formulate the concept of data distribution and uncertainty. Also, by statistics, various statistics can be obtained for a certain group, and normalization is made so that data can be easily learned using them, and it is judged whether each data is valid or outliers can do.\n",
    "\n",
    "\n",
    "### 1.4.2. Probability\n",
    "\n",
    "The probability represents the degree to which the event is expected to occur for various possible events. In the context of parameter estimation, there may be cases in which the probability represents a belief that it is likely to occur. The probability is $p(x)$ In the form of a function like $x$ The random variable is called. A random variable is a variable that takes one of the possible events. further $p(x=u)$ As a random variable $x$ The value of the $u$ It is assumed to be the probability when it was. I omit this $p(x=u)$ In the form of. The probability is \"the sum of the probabilities of all events is 1\" The probability of all events is0 It meets the two constraints of \"It is over\". When writing this with an expression,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{x } p(x) &= 1 \\\\\n",
    "p(x) & \\geq  0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The probability that two events occur **simultaneously** is called **simultaneous probability** $p(x, y)$ It is expressed as follows. For example, swipe the dice twice, the first eye $0$, The second eye $5$ Probability to be represented by joint probability.\n",
    "\n",
    "Among the joint probability, paying attention only to a particular random variable, the operation to be erased by taking the sum for the other random variable **marginalization** is called (the word marginalization is, first of random variables a row, column Is associated with the second random variable and the joint probability is written in a table, it is said that it is because the sum of the rows and the sum of the columns are written around the table). The result of marginalization matches the probability of random variables of interest.\n",
    "\n",
    "$$\n",
    "p(x) = \\sum_y p(x, y) \\\\\n",
    "p(y) = \\sum_x p(x, y)\n",
    "$$\n",
    "\n",
    "The conditional probability is called the probability distribution that shows the probability of the other under the condition that one random variable is fixed with a certain value ,$p(y|x)$It is expressed as follows. For exampleùë¶A random variable representing whether it is raining outside,ùë•As a random variable representing whether the person who entered the room had an umbrella ($y=1$ Rain is shaking,$y=0$ Assign it as if the rain did not shake). At this time $p(y|x)$ Represents the conditional probability of rain outside when the person who entered the room had an umbrella.\n",
    "\n",
    "The conditional probability is equal to the value obtained by dividing the joint probability by the probability of the condition.\n",
    "\n",
    "\n",
    "$$\n",
    "p(y|x) = \\frac{p(x, y)}{p(x)}\n",
    "$$\n",
    "\n",
    "Here, we modified the expression of the conditional probability $p(y|x)p(x) = p(x, y)$ Note that,\n",
    "\n",
    "$$\n",
    "p(x|y) = \\frac{p(x, y)}{p(y)} = \\frac{p(y | x)p(x)}{p(y)}\n",
    "$$\n",
    "\n",
    "can be obtained. This is called **Bayes' theorem** . It is an important theorem, so let's remember.\n",
    "\n",
    "\n",
    "For example, as an application example of Bayes' theorem, there is a spam (unsolicited) mail filter. A word in e-mailùëñA probability variable representing whether or not $i$ , A random variable representing whether or not the mail is spam $y$ Then, $p(x_{i}=1)$ \"Mail is a wordùëñProbability including \" $p(y=1)$ \"Probability that mail is spam\",$p(x_{i}=1|y=1)$ \"When the mail was spam, a wordùëñProbability of being included \". By aggregating each proportion from the received large number of e-mails and applying Bayes' theorem, $p(y=1|x_{i}=1)$ As a word \"$i$ The probability that the mail is spam \"can be obtained.\n",
    "\n",
    "### 1.4.3. The likelihood and maximum likelihood estimation \n",
    "\n",
    "(Parametric) stochastic model $p(x; \\theta)$ Is the parameter $\\theta$ It is a function as characterized by. Probabilistic model $p(x)$ Event onùë¢Probability of observation $p(x=u; \\theta)$ Event $u$ It is called the likelihood of . The likelihood likelihood means \"likelihood (more) likely\" and it indicates the likelihood of the event.\n",
    "\n",
    "here,$N$ Pieces of data $X = \\left( x^{(1)}, x^{(2)}, \\ldots, x^{(N)} \\right)$ And the data $X$ We will consider the problem of estimating the probability distribution that generates. In this case, a method called maximum likelihood estimation is often used. **Maximum likelihood estimation** is based on observed data $X$ Parameters most likely to be generated $\\theta$ It is a method to estimate. When the data to be observed are generated independently, the likelihood is\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\theta) = p(X; \\theta) = \\prod_{i=1}^N p(x^{(i)}; \\theta)\n",
    "$$\n",
    "\n",
    "It is represented as follows. this $\\prod$ The sign $\\sum$ It means to multiply all the values with the multiplication version of. As for the likelihood for multiple data,1. Since it is a product of smaller values, it becomes a very small number and becomes difficult to handle on a computer. When maximizing the likelihood, it is known that maximization of product form is difficult. Therefore, instead of likelihood, we consider the log likelihood taking the logarithm.\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\log p(X; \\theta) = \\sum_{i=1}^N \\log p(x^{(i)}; \\theta)\n",
    "$$\n",
    "\n",
    "Parameters that maximize this log likelihood $\\theta$ If it can be determined that the value is data $X$ It is a parameter of the probability model that is most likely to generate.\n",
    "\n",
    "Here, as a concrete example easy to understand, let us consider the problem of estimating the probability that the front and back of a coin will appear. A random variable representing the front and back of the coinùë•Aside,$x$ = 1 If it is a table,$x$ =0 If it is, it will be behind. Also, in the table ($X$=1) As a parameter representing the probability of $\\theta$ I will leave. Coin $10$ As a result of throwing, the following observation result $X$ Is obtained.\n",
    "\n",
    "$$\n",
    "X = \\left(1, 0, 1, 1, 1, 0, 0, 1, 0, 0 \\right)\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &= \\theta \\cdot (1 - \\theta) \\cdot  \\ldots  \\cdot (1 - \\theta) \\cdot (1 - \\theta) \\\\ \n",
    "&= \\theta^{5} \\cdot (1 - \\theta)^{5}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The log likelihood is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = 5 \\log \\theta + 5 \\log \\left( 1 - \\theta \\right)\n",
    "$$\n",
    "\n",
    "this $\\theta$ Differentiate with $0$ Is obtained,\n",
    "\n",
    "$$\n",
    "\\frac{5}{\\theta} - \\frac{5}{\\left( 1 - \\theta \\right)} = 0 \n",
    "$$\n",
    "\n",
    "ThanÔºå$\\theta = 0.5$ is obtained by maximum likelihood estimation.Ôºé\n",
    "\n",
    "In the case of using the sum of the square error of the true value and the predicted value as the objective function of the regression model ( called the **least squares method** ), the maximum likelihood estimation is performed assuming the error of the normal distribution (described later) to the output value of the model It is known to be equivalent to being.\n",
    "\n",
    "\n",
    "### 1.4.4. Posterior probability maximization estimation (MAP estimation) \n",
    "\n",
    "Although maximum likelihood estimation is effective in many cases, if there is some prior information in the parameter to be obtained, maximum likelihood estimation can not handle that a priori information. Therefore, trying to estimate the parameters while the number of trials is small may not work well with maximum likelihood estimation.\n",
    "\n",
    "As in the previous example, let's consider an example of estimating the probability that the front and back of a coin will appear. Coin5When throwing it, it happens $5$ Times and tables ($x = 1$) Has come out. In this case, in the maximum likelihood estimation, the probability that the table appears is $100$% (Probability of backing out $0$%) In the future. However, the probability of obvious backing out is0If there is prior information that it should be larger than that, it is likely to make a better estimate.\n",
    "\n",
    "In such a case, the method of estimating the parameters based on observation data while also considering prior information is estimation of a posteriori probability **(Maximum A Posteriori, MAP)** . In MAP estimation, parameters $\\theta$ Is also a random variable, its distribution ( also called **prior probability**)$p\\left( \\theta \\right)$ I think that it exists. Then, observation data $X$ In the given condition, the parameters $\\theta$ The conditional probability ( also called **posteriori probability**) $p\\left( \\theta|X\\right)$ To maximize $\\theta$ You will be asked.\n",
    "\n",
    "\n",
    "Let's recall Bayes' theorem here. When using Bayes' theorem, the posterior probability is\n",
    "\n",
    "\n",
    "$$\n",
    "p(\\theta|X) = \\frac{p(X|\\theta)p(\\theta)}{p(X)}\n",
    "$$\n",
    "Considering maximizing this for parameters,$P(X)$ Can not be ignored since it has no relation with the parameter,\n",
    "\n",
    "\n",
    "$$\n",
    "p(X|\\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "You will be asked to maximize parameters.$p(X|\\theta)$ is the same as the maximum likelihood estimation, but in the MAP estimation, the prior probability of the parameter $p(\\theta)$ It will maximize the probability of multiplication. (I will not explain the process of obtaining the solution of MAP estimation here.)\n",
    "\n",
    "When optimizing parameters in machine learning, we set a penalty term for the large value of the parameter called regularization, but this can be regarded as the prior probability (the log of) of the parameters, It can be interpreted as MAP estimation.\n",
    "\n",
    "\n",
    "### 1.4.5. Statistics\n",
    "\n",
    "Here, I will introduce the representative statistics, mean, variance, standard deviation.\n",
    "\n",
    "First, I will introduce the average . For example, the average of 300 yen, 400 yen, 500 yen,\n",
    "$$\n",
    "\\dfrac{300 + 400 + 500}{3} = 400\n",
    "$$\n",
    "\n",
    "Then, add up all and divide by the number of targets. When this is formulated,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\overline {x}=\\dfrac {x_{1}+x_{2}+\\ldots +x_{N}}{N}\n",
    "=\\dfrac {1}{N}\\sum ^{N}_{n=1}x_{n}\\end{aligned}\n",
    "$$\n",
    "\n",
    "It looks like. $N$ Represents the number of samples . The average, $\\bar{x}$ Ya $\\mu$ It is common to be represented by a symbol such as. In the data distribution, the average is the value corresponding to its center of gravity.\n",
    "\n",
    "Next, I will introduce distribution . The definition of dispersion\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\\sigma ^{2}=\\dfrac {1}{N}\\sum ^{N}_{n=1}\\left( x_{n}-\\overline {x}\\right) ^{2}\\end{aligned}\n",
    "$$\n",
    "\n",
    "Average of each sample $\\bar{x}$ Difference from $x- \\bar{x}$ And calculate the average value of their squared errors. There is another definition in dispersion,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma ^{2}=\\dfrac {1}{N-1}\\sum ^{N}_{n=1}\\left( x_{n}-\\overline {x}\\right) ^{2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "t may be expressed as. The former is called specimen variance and the latter is called unbiased variance . The derivation of these expressions will be handed over to other books, and here we will explain their use properly.\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/12.png)\n",
    "\n",
    "When analyzing data, it is important to be conscious of analysis on **population** or analysis on **specimen group** . The population is a case where all the data is available for the range of assumptions to be analyzed, and the sample group is for extracting a part of them. For example, when aggregating height and weight of primary school students nationwide, if you can collect elementary school students nationwide without leakage of one person, it is a population, but if you collect 100 people in each prefecture and compile it, it becomes a specimen group. It is practically difficult to gather population data and it is common to estimate population distribution from sample group data. In that case, you will basically use the unbiased variance, which is for sample groups. The number of samples $N$ If there are many, there is almost no difference between population variance and unbiased variance, but be careful as the number of samples is small when it is small.\n",
    "\n",
    "By using variance, it becomes possible to quantitatively evaluate the variation of data. For example, if there are many variations in the results of experiments, it is possible that reproducibility could not be ensured in each experiment. In this way, it is important to quantify and evaluate the degree of variation in situations where it is desirable that the results of many trials gather at certain values. Besides, depending on the variation of data, you can also evaluate the difference in scale by using variance.\n",
    "\n",
    "Finally, I will introduce the standard deviation . In the variance, the unit is the square of the original unit because of the sum of the square of the difference from the average of each sample. For example, if the original unit is kg, the variance is in units of square of kg. So I took the square root of the variance $\\sigma$ By using, it becomes equal to the original unit, making interpretation easier. This is called standard deviation.\n",
    "\n",
    "Let's check the concrete calculation procedure with exercises. Please calculate average, variance, standard deviation for the following data in ‚ë† and ‚ë°. However, we will use the mother variance this time.\n",
    "\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/13.png)\n",
    "\n",
    "The answers to ‚ë† are as follows.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{x}&=\\dfrac {1}{5}\\left( -2-1+0+1+2\\right) =0\\\\\n",
    "\\sigma ^{2}&=\\dfrac {1}{5}\\left\\{ \\left( -2-0\\right) ^{2}+\\left( -1-0\\right) ^{2}+(0-0)^{2}+(1-0)^{2}+(2-0)^{2}\\right\\} \\\\\n",
    "&=\\dfrac {1}{5}\\times 10=2\\\\\n",
    "\\sigma &=\\sqrt {2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The answer to ‚ë° is as follows.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\overline {x}&=\\dfrac {1}{5}\\left( -4-2+0+2+4\\right) =0\\\\\n",
    "\\sigma ^{2}&=\\dfrac {1}{5}\\left\\{ \\left( -4-0\\right) ^{2}+\\left( -2-0\\right) ^{2}+\\left( 0-0\\right) ^{2}+\\left( 2-0\\right) ^{2}+\\left( 4-0\\right) ^{2}\\right\\} \\\\\n",
    "&=\\dfrac {1}{5}\\times 40=8\\\\\n",
    "\\sigma &=\\sqrt {8}=2\\sqrt {2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "From this, it can be seen that the case of ‚ë° has larger variance and large data variation.\n",
    "\n",
    "\n",
    "### 1.4.6. Normal distribution and the normalized \n",
    "Here, we will introduce the normal distribution that appears frequently with probability . It is also called **Gaussian distribution** . average$\\mu$,standard deviation $\\sigma$ The normal distribution with the shape has the following form.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/14.png)\n",
    "\n",
    "Why does this normal distribution appear frequently? There are the following physical and mathematical background as the reason.\n",
    "\n",
    "- A random variable expressed as a sum of independent and numerous factors approximates a normal distribution\n",
    "- Easy to handle formulas\n",
    "\n",
    "Many data seen in the world are known to follow the normal distribution (eg height according to gender age, points of examination, measurement error of physical experiments, etc.). On the other hand, the data does not always obey the normal distribution. In many cases there are many cases where wrong conclusions are derived by applying it to a normal distribution for distribution that is not a normal distribution. Always think whether distributing the data can be handled as a normal distribution by making it diagrammatic.\n",
    "\n",
    "For normal distribution average $\\mu$  And standard deviation $\\sigma$ We will do a lot of discussions on what percentage is in that distribution. For example,$\\mu \\pm 3\\sigma$ Since 99.7% of the total of the data falls within the range of $\\mu \\pm 3 \\sigma$ It can be used to define an area that does not fall into an outlier value (a value greatly deviating from other values).\n",
    "\n",
    "\n",
    "### 1.4.7. Scaling using the standard deviation \n",
    "\n",
    "Scaling is important as preprocessing in most machine learning algorithms,\n",
    "\n",
    "To illustrate why scaling is important, I will take an example of calculating the distance between two points. Variables with different scales $x1$ When $x2$ If there is, the situation will be as shown in the figure below. Please note that the scales on the vertical axis and the horizontal axis are greatly different here.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/15.png)\n",
    "\n",
    "Distance between these two points $d$  Is obtained,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d&=\\sqrt {\\left( 100-1000\\right) ^{2}+\\left( 0.1-1\\right) ^{2}}\\\\\n",
    "&= \\sqrt {900^{2}+0.9^{2}}\\\\\n",
    "&= \\sqrt {810000+0.81} \\\\\n",
    "&= \\sqrt {810000.81}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It looks like. distance $d$ among $x_{1}$ Influence amount is large $x_{2}$ As for the scale, it has little influence because it is small. With this $x_{2}$ Can not be taken into account even when the meaning of data is important. One method of solving these problems is the **scaling described** here. There are two typical scaling methods.\n",
    "\n",
    "The first method scales the sample set to a **minimum value of 0** and a **maximum value of 1** . This is called **Min-Max scaling** . In this method, the minimum value $x_{\\min}$ And the maximum value $x_{\\max}$ For all the data,\n",
    "\n",
    "\n",
    "$$\n",
    "\\widetilde{x} = \\dfrac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n",
    "$$\n",
    "\n",
    "Calculation is performed. Although Min-Max scaling has the merit of simple calculation, on the other hand, as shown in the figure below $x_1$ If data points with outliers are present, $x_{\\max}$ There is a weak point that it is greatly pulled by outliers.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/16.png)\n",
    "\n",
    "Another way of scaling is to scale to an **average of 0** and a **standard deviation of 1** . This is commonly referred to as **normalization** . When you subtract the average from all data, the average $0$ When dividing by the standard deviation, the standard deviation becomes 1 It becomes.\n",
    "\n",
    "$$\n",
    "\\widetilde{x}  = \\dfrac{x - \\bar{x}}{\\sigma}\n",
    "$$\n",
    "\n",
    "Applying this scaling to the example ‚ë† in which the variance was calculated,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{1}&=\\dfrac {-2-0}{\\sqrt {2}}=-\\dfrac {2}{\\sqrt {2}}\\\\\n",
    "x_{2}&=\\dfrac {-1-0}{\\sqrt {2}}=-\\dfrac {1}{\\sqrt {2}}\\\\\n",
    "x_{3}&=\\dfrac {0-0}{\\sqrt {2}}=0\\\\\n",
    "x_{4}&=\\dfrac {1-0}{\\sqrt {2}}=\\dfrac {1}{\\sqrt {2}}\\\\\n",
    "x_{5}&=\\dfrac {2-0}{\\sqrt {2}}=\\dfrac {2}{\\sqrt {2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The data is converted like this. When we look at the mean and standard deviation at this time,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\overline {x}&=\\dfrac {1}{5}\\left( -\\dfrac {2}{\\sqrt {2}}-\\dfrac {1}{\\sqrt {2}}+0+\\dfrac {1}{\\sqrt {2}}+\\dfrac {2}{\\sqrt {2}}\\right) =0\\\\\n",
    "\\sigma ^{2}&=\\dfrac {1}{5}\\left\\{ \\left( -\\dfrac {2}{\\sqrt {2}}-0\\right) ^{2}+\\left( -\\dfrac {1}{\\sqrt {2}}-0\\right) ^{2}+\\left( 0-0\\right) ^{2}\n",
    " +\\left( \\dfrac {1}{\\sqrt {2}}-0\\right) ^{2}+\\left( \\dfrac {2}{\\sqrt {2}}-0\\right) ^{2}\\right\\} =1\\\\\n",
    "\\sigma &=\\sqrt {\\sigma ^{2}}=1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As you can see, you can scaled to 0 average and 1 standard deviation. With this method, strong scaling can be achieved for a small number of outliers compared with Min-Max scaling.\n",
    "\n",
    "### 1.4.8. Outlier removal \n",
    "\n",
    "Let's handle data that varies with time as follows. For example, the horizontal axis is time and the vertical axis is temperature. Also assume that the average temperature is constant and the temperature fluctuates randomly.\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/17.png)\n",
    "\n",
    "If you want to detect abnormality (outlier) of temperature due to abnormality of thermometer or failure of this data, how should we define and detect this outlier? One way is to focus on the **frequency** of values .\n",
    "\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/18.png)\n",
    "\n",
    "As shown above, if you draw a line against the mean, calculate the frequency at each value and draw a histogram, a normal distribution appears. Here we assume that normality can be assumed for the distribution followed by the data (there is a method such as normality test if you want to check statistically whether the data follows the normal distribution), to define outliers, Average of data $\\mu$ And standard deviation $\\sigma$ Is calculated, $\\mu \\pm 3\\sigma$ You can remove outliers by subtracting a line to the value of. This is called the 3œÉ method . However, when the number of outliers increases or the outliers have extreme values, the mean and standard deviation are pulled to their outliers, and the 3œÉ method may not be able to cope well.\n",
    "\n",
    "In that case, you can also arrange the data in descending order and remove the top 5% and bottom 5%."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basic Math for ML",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
