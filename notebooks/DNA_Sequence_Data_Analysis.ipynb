{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoiTUC_zXAb9"
   },
   "source": [
    "[![colab-logo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/preferred-medicine/medical-ai-course-materials/blob/master/notebooks/DNA_Sequence_Data_Analysis.ipynb)\n",
    "\n",
    "# Practical part: sequence analysis using deep learning \n",
    "In recent years, with the development of the Next Generation Sequencer (NGS), nucleotide sequences of genes have been read at high speed, in large amounts, and at low cost.\n",
    "\n",
    "Here we will address the issue of predicting epigenetic effects and transcriptional control from DNA sequences using deep learning. Deep learning can express a complicated model, it can also take into account the effects of long distances and it can be expected to predict with higher accuracy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkqRZHc8crS4"
   },
   "source": [
    "## Environment \n",
    "The library used here are:\n",
    "\n",
    "* Chainer\n",
    "* Cupy\n",
    "* matplotlib\n",
    "\n",
    "On Google Colab, you can install as follows. Execute the following cell (Shit + Enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muhQoVk7c9y1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1580  100  1580    0     0   6531      0 --:--:-- --:--:-- --:--:--  6556\n",
      "sh: line 9: nvidia-smi: command not found\n",
      "********************************************************************************\n",
      "GPU is not enabled!\n",
      "Open \"Runtime\" > \"Change runtime type\" and set \"Hardware accelerator\" to \"GPU\".\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "!curl https://colab.chainer.org/install | sh -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEPaj4MfdEyh"
   },
   "source": [
    "When installation is completed, run the following cell and check the version of each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "p4X-dmKrdDhd",
    "outputId": "4a4a89ef-9fed-4cba-cc55-09cad5c6b1aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytakeda/venvs/py37/lib/python3.7/site-packages/chainer/_environment_check.py:37: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Please be aware that Mac OS X is not an officially supported OS.\n",
      "\n",
      "  ''')  # NOQA\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4d91d41dbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_runtime_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import cupy\n",
    "import matplotlib\n",
    "\n",
    "chainer.print_runtime_info()\n",
    "print('matplotlib:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nsNNeFEkjB_"
   },
   "source": [
    "```\n",
    "Platform: Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic\n",
    "Chainer: 5.1.0\n",
    "NumPy: 1.14.6\n",
    "CuPy:\n",
    "  CuPy Version          : 5.1.0\n",
    "  CUDA Root             : /usr/local/cuda\n",
    "  CUDA Build Version    : 9020\n",
    "  CUDA Driver Version   : 9020\n",
    "  CUDA Runtime Version  : 9020\n",
    "  cuDNN Build Version   : 7301\n",
    "  cuDNN Version         : 7301\n",
    "  NCCL Build Version    : 2307\n",
    "iDeep: 2.0.0.post3\n",
    "('matplotlib:', '2.1.2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzdDwd7aeYmT"
   },
   "source": [
    "##  For the sequence analysis \n",
    "Along with the development and popularization of next-generation sequencers, a large number of gene sequences have been read. Under such circumstances, GWAS (Genome Wide Association Study) that estimates the relationship between the genotype expressed in the base sequence and the phenotype such as disease and morphology has been performed, It has been learned that mutation alone can not explain all phenotypic changes. In particular, various experimental results have shown that untranslated regions influence gene expression and cause phenotypic changes. Various methods have been proposed to investigate how the surrounding area affects gene expression.\n",
    "\n",
    "![Epigenome analysis schematic（cited in Encode Project）](https://www.encodeproject.org/images/c45f4d8c-0340-4fcb-abe3-e4ff0bb919be/download/attachment/EncodeDatatypes2013-7.png)\n",
    "\n",
    "For example, ChIP-Seq (chromatin immunoprecipitation sequence) is a method to identify histone modification status and the binding site of transcriptional regulatory elements exhaustively (genome-wide) by combining ChIP (chromatin immunoprecipitation) and high-speed DNA sequence. As a result, it is possible to identify the binding site of histone modification and DNA binding protein which controls the transcriptional regulatory function throughout the genome, it becomes possible to obtain vast amounts of information related to cellular phenotype which can not be fully explained by gene mutation alone.\n",
    "\n",
    "Therefore, in this section, by learning patterns of DNA base sequences corresponding to binding sites of transcriptional regulatory factors obtained by ChIP-Seq by deep learning, we will predict the possibility of binding to an arbitrary DNA base sequence with a specific transcriptional regulatory factor. This method can deal with a wide range of biological phenomena such as prediction of the histone modification site of the whole genome and prediction of the open chromatin region and gives useful insights.\n",
    "\n",
    "One of the technical difficulties in dealing with this task with machine learning is a phenomenon called long-distance interaction of DNA base sequence. This is because DNA in the nucleus exists in a complicated folded manner, two distant regions as a sequence on the base sequence are spatially close to each other, and it may affect the binding of the transcriptional regulatory factor. Therefore, we will construct an efficient model that enables training with this long distance interaction taken into account, and receive a DNA base sequence having a length exceeding 100,000 bp (base pair: a unit that counts bases constituting DNA) as an input, then we will try to predict if a certain region in the DNA base sequence can be the binding site for the transcriptional regulatory factor.\n",
    "\n",
    "In this case, we will take DNA base sequence, obtained from dataset of thousands of ChIP-Seq, DNase-seq (one method of comprehensive analysis of open chromatin region) obtained from hundreds of human cell types, as input, then examine the problem of estimating the expression level of mRNA measured from the result of CAGE (Cap Analysis of Gene Expression)[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "db3ngEYHgSmd"
   },
   "source": [
    "##  Data Set\n",
    "\n",
    "Here we use some of the experimental data set used in Basenji [1], which is a data set obtained by performing sequence analysis such as CAGE.\n",
    "\n",
    "Please run the cell below and download the data.\n",
    "\n",
    "Each of these arrays consists of 131072 bp in length, and its coverage value is recorded every 128 bp. The array length of this coverage value is 131072/128 = 1024.\n",
    "\n",
    "The goal of this problem is to estimate the coverage value every 128 bp when receiving an array of length 131072 bp as input.\n",
    "\n",
    "This time we will deal with the problem of simultaneously predicting coverage values of 10 different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "LjxWi_2chwkX",
    "outputId": "69c63cd9-0c1e-4e16-e04e-20bdb5fde838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-06 10:49:35--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190506T174936Z&X-Amz-Expires=300&X-Amz-Signature=7b95541ce0c07323709274af077569f3e5cbd0883349be7025703fa5f0de3c21&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2019-05-06 10:49:35--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190506T174936Z&X-Amz-Expires=300&X-Amz-Signature=7b95541ce0c07323709274af077569f3e5cbd0883349be7025703fa5f0de3c21&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.233.35\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.233.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 594118876 (567M) [application/octet-stream]\n",
      "Saving to: ‘seq.h5.1’\n",
      "\n",
      "seq.h5.1            100%[===================>] 566.60M  21.1MB/s    in 44s     \n",
      "\n",
      "2019-05-06 10:50:19 (13.0 MB/s) - ‘seq.h5.1’ saved [594118876/594118876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9yuEHGl_XC2B",
    "outputId": "6e0e3ee2-0dc3-4b22-cb0a-f44bf829a950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2363288\r\n",
      "-rw-r--r--   1 ytakeda  staff    62K Apr  1 18:10 Basic_Math_for_ML.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff   442K Apr 24 19:03 Blood_Cell_Detection.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff    80K May  1 16:10 DNA_Sequence_Data_Analysis.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff   221K Apr 19 10:47 Image_Segmentation.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff   503K Apr 30 14:41 Introduction_to_Chainer.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff    73K Apr  1 18:10 Introduction_to_ML_libs.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff    57K Apr  8 12:46 Introduction_to_Neural_Network.ipynb\r\n",
      "-rw-r--r--   1 ytakeda  staff   246K Apr 24 19:03 Sequential_Data_Analysis_with_Deep_Learning.ipynb\r\n",
      "drwxr-xr-x  15 ytakeda  staff   480B Apr 19 11:07 \u001b[1m\u001b[36mimages\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 ytakeda  staff   567M Dec  2 22:54 seq.h5\r\n",
      "-rw-r--r--   1 ytakeda  staff   567M Dec  2 22:54 seq.h5.1\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8NsMudgiHBI"
   },
   "source": [
    "Please check that the file seq.h5 is downloaded correctly. The size is 567 MB.\n",
    "\n",
    "seq.h 5 is a file that stores data in HDF5 format. Like the file system, the HDF5 file can store data hierarchically, and can store matrix and tensor data named at each position.\n",
    "\n",
    "There is a library called h5py to manipulate HDF5 format files. Open the file with h5py's File() function and enumerate the keys contained in it with the keys() function. By specifying the acquired key within '[]', you can refer to each stored data linked to that key.\n",
    "\n",
    "Like the numpy, you can get size of tensor data with the attribute called shape.\n",
    "\n",
    "Run the following cell and check the stored data.\n",
    "\n",
    "A prefix of train (training), validate (validation), test (test) is attached to the name of each data, in corresponds to the base sequence of the input, and out corresponds to the coverage value of the output.\n",
    "\n",
    "For example, 'train_in' is input data for training and has a size of (5000, 131072, 4). This is an array with 5000 arrays of length 130172, where the corresponding dimension values of A, T, C and G are 1 and the others are 0.\n",
    "\n",
    "'Train_out' is output data for training and has a size of '(5000, 1024, 10'). There are 5000 arrays of length 1024, and each contains the coverage value of 10 different ChIP-Seq results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "bBQVPyKxi-uE",
    "outputId": "7c950b79-5422-4dea-9889-f9d15294ca31"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3c26f0ebd2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seq.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('seq.h5', 'r') as hf:\n",
    "    for key in hf.keys():\n",
    "        print(key, hf[key].shape, hf[key].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7OkqzE-jXlq"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "(u'target_labels', (10,), dtype('S29'))\n",
    "(u'test_in', (500, 131072, 4), dtype('bool'))\n",
    "(u'test_out', (500, 1024, 10), dtype('<f2'))\n",
    "(u'train_in', (5000, 131072, 4), dtype('bool'))\n",
    "(u'train_out', (5000, 1024, 10), dtype('<f2'))\n",
    "(u'valid_in', (500, 131072, 4), dtype('bool'))\n",
    "(u'valid_out', (500, 1024, 10), dtype('<f2'))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkAYTB2ZkEXr"
   },
   "source": [
    "To handle h5py format files as numpy data, you need to copy them. The following code reads the tensor data corresponding to the key 'train_in' as numpy data and displays part of that data.\n",
    "\n",
    "Let's try to extract the first data and display the output value of it.\n",
    "\n",
    "Please run the cell below. It outputs three values of the first data output as a line graph. (Please run the cells up to here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "lik6qHPD4m9V",
    "outputId": "10cf0762-52a0-45da-ff84-0b4dfe32043a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHwAAAEvCAYAAAA3qtbRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03d6048908>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with h5py.File('seq.h5') as hf:\n",
    "    y = hf['train_out'][:100]\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 20\n",
    "    fig_size[1] = 5\n",
    "    for i in range(3):\n",
    "        plt.bar(range(y.shape[1]), y[0,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dB69Y47k-y_"
   },
   "source": [
    "##  Dilated Convolution analysis using \n",
    "\n",
    "\n",
    "### Strategy of sequence analysis \n",
    "Let's handle the problem that array data is input.\n",
    "\n",
    "There are three major strategies to handle array data.\n",
    "\n",
    "The first is to discard the sequence information in the array and to consider the array as a set of its features. This is called Bag of Words (BoW) expression. This BoW expression is a powerful technique if enough information is included in the feature, but it is difficult to capture its features only with an array of four kinds of characters such as a DNA sequence or a partial sequence thereof.\n",
    "\n",
    "The second method is to read elements in the array from left to right in order and calculate. This is analyzed using RNN which I mentioned a little in Chapter 4 as well. RNN reads input one by one at each time and updates the internal state. The problem with RNN is that its calculation is sequential and the amount of calculation is proportional to the length of the array. The current computer achieves high speed by parallelizing the calculation, but it is difficult for RNN to parallelize the calculation. Another problem is that it is difficult to capture relationships between long distances. Because of the calculation method, RNN needs to store all intermediate results in a fixed-length internal state vector. When trying to capture relationships between long distances, we need to remember a lot of information, but since state vector size is finite, it becomes difficult to capture relationships between long distances.\n",
    "\n",
    "The third method is to analyze array data as one dimensional image and analyze it using CNN as in the case of image processing. Unlike the case of RNN, CNN can process each position independently, so it can process in parallel.\n",
    "\n",
    "In this time we will adopt this third strategy, a method to analyze using CNN. In addition, by using Dilated Convolution, processing at each position can directly read information at a long distance. In the next chapter we will look at Dilated Convolution in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWl4yYm_nqg7"
   },
   "source": [
    "###  Dilated Convolution \n",
    "\n",
    "Consider the case of sequence analysis using the conventional convolutional layer. As shown in the figure below, the input information of a certain position is read only from the adjacent position in each layer. The kernel size determines how much information is acquired from the distance, and if the kernel size is K, the D / K layer is required to acquire the information that is at a distance D from the kernel size. In the case of this problem D is hundreds to tens of thousands and K is the value of 3 or 5 so it is not realistic that the number of necessary layers will also be from one hundred to ten thousand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJ2MdbaHneLk"
   },
   "source": [
    "\n",
    "![Conventional convolutional layer calculation](http://musyoku.github.io/images/post/2016-09-17/naive_conv.png)\n",
    "\n",
    "Cited from [WaveNet: A Generative Model for Raw Audio](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gazys1FUoV4m"
   },
   "source": [
    "On the other hand, Dilated Convolution (also called atrous convolution and convolution weith holes) receives from the place where the reading place shifts. For example, if Dilation = 4, we will receive information from a distance of 4. If we double this Dilated and set the kernel size to 2, only log2𝐷 layer is needed to receive information separated by D. If this time D is hundreds to tens of thousands, only about 10 to 20 layers will be enough.\n",
    "\n",
    "This time, using this Dilated Convolution, we will create a model that can take distant information into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vl5f4eonQGU9"
   },
   "source": [
    "\n",
    "![Calculation image of Dilated Convolution](https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif)\n",
    "\n",
    "[WAVENET: A GENERATIVE MODEL FOR RAW AUDIO, blog](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) blogpost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0bcCznko_wD"
   },
   "source": [
    "###  \n",
    "Let's start by designing the whole network. This network consists of two blocks.\n",
    "\n",
    "The first block takes an array from length $2^{17}$ and outputs a vector of length $2^{10}$. This makes the input 128(=$2^{17}$/$2^{10}$) bp corresponds to one position of the output. This is realized by SqueezeBlock. That is, SqueezeBlock accepts the base sequence of the DNA consisting of the length 131072 bp as an input and performs convolution processing so that the information of every 128 bp corresponding to the length of each fragment becomes one value. As a result, a vector sequence with length of 131072/128 = 1024 is output. This vector sequence can be regarded as the feature of each fragment compressed into one vector.\n",
    "\n",
    "The second block is the part which calculates the value of each vector in consideration of the information in the long distance, and is handled by DilatedBlock. DilatedBlock receives a vector sequence of 1024 length output from SqueezeBlock and uses the mechanism of Dilated Convolution to efficiently consider the information at mutually separated positions and process it and returns the same lenth of output as the input. We will proceed with training so that this output agrees with the numerical value (coverage value) representing the possibility of binding of DNA-related protein given for each fragment.\n",
    "\n",
    "Let's run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5M6BDmVdpLkE"
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import cupy as cp\n",
    "\n",
    "bc = 24 # base channel\n",
    "\n",
    "default_squeeze_params = [\n",
    "    # out_ch, kernel, stride, dropout\n",
    "    [bc*2, 21, 2, 0], #1 128 -> 64\n",
    "    [int(bc*2.5), 7, 4, 0.05], #2  64 -> 16\n",
    "    [int(bc*3.2), 7, 4, 0.05], #3  16 -> 4\n",
    "    [bc*4, 7, 4, 0.05]  #4  4 -> 1\n",
    "]\n",
    "\n",
    "\n",
    "default_dilated_params = [\n",
    "# out_ch, kernel, dilated\n",
    "  [bc, 3, 1, 0.1],\n",
    "  [bc, 3, 2, 0.1], \n",
    "  [bc, 3, 4, 0.1], \n",
    "  [bc, 3, 8, 0.1], \n",
    "  [bc, 3, 16, 0.1], \n",
    "  [bc, 3, 32, 0.1],\n",
    "  [bc, 3, 64, 0.1]\n",
    "]\n",
    "\n",
    "\n",
    "class Net(chainer.Chain):\n",
    "\n",
    "    def __init__(self, squeeze_params=default_squeeze_params, dilated_params=default_dilated_params, n_targets=10):\n",
    "        super(Net, self).__init__()\n",
    "        self._n_squeeze = len(squeeze_params)\n",
    "        self._n_dilated = len(dilated_params)\n",
    "        with self.init_scope():\n",
    "            in_ch = 4\n",
    "            for i, param in enumerate(squeeze_params):\n",
    "                out_ch, kernel, stride, do_rate = param\n",
    "                setattr(self, \"s_{}\".format(i), SqueezeBlock(in_ch, out_ch, kernel, stride, do_rate))\n",
    "                in_ch = out_ch\n",
    "            for i, param in enumerate(dilated_params):\n",
    "                out_ch, kernel, dilated, do_rate = param\n",
    "                setattr(self, \"d_{}\".format(i), DilatedBlock(in_ch, out_ch, kernel, dilated, do_rate))\n",
    "                in_ch += out_ch\n",
    "            self.l = L.ConvolutionND(1, None, n_targets, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x : (B, X, 4)\n",
    "        xp = cp.get_array_module(x)\n",
    "        h = xp.transpose(x, (0, 2, 1))\n",
    "        h = h.astype(xp.float32)\n",
    "                \n",
    "        for i in range(self._n_squeeze):\n",
    "            h = self[\"s_{}\".format(i)](h)\n",
    "    \n",
    "        hs = [h]\n",
    "        for i in range(self._n_dilated):\n",
    "            h = self[\"d_{}\".format(i)](hs)\n",
    "            hs.append(h)\n",
    "\n",
    "        h = self.l(F.concat(hs, axis=1))\n",
    "        h = xp.transpose(h, (0, 2, 1))\n",
    "        return h\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc3RNwK_qHzS"
   },
   "source": [
    "This network receives parameters related to SqueezeBlock and parameters related to DilatedBlock as initialization arguments.\n",
    "\n",
    "Each receives a list of triples of output channels, kernel sizes, and pooling, and a list of triples of output channels, kernel sizes, and dilated sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3T5pRubrlba"
   },
   "source": [
    "Next, we define the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shOuWcBkrpOE"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1a46fb495a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWNConvolutionND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolutionND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import cupy as cp\n",
    "\n",
    "class WNConvolutionND(L.ConvolutionND):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(WNConvolutionND, self).__init__(*args, **kwargs)\n",
    "        self.add_param('g', self.W.data.shape[0])\n",
    "        norm = np.linalg.norm(self.W.data.reshape(\n",
    "            self.W.data.shape[0], -1), axis=1)\n",
    "        self.g.data[...] = norm\n",
    "\n",
    "    def __call__(self, x):\n",
    "        norm = F.batch_l2_norm_squared(self.W) ** 0.5\n",
    "        channel_size = self.W.data.shape[0]\n",
    "        norm_broadcasted = F.broadcast_to(\n",
    "            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)\n",
    "        g_broadcasted = F.broadcast_to(\n",
    "            F.reshape(self.g, (channel_size, 1, 1)), self.W.data.shape)\n",
    "        return F.convolution_nd(\n",
    "            x, g_broadcasted * self.W / norm_broadcasted, self.b, self.stride,\n",
    "            self.pad, self.cover_all, self.dilate)\n",
    "\n",
    "class SqueezeBlock(chainer.Chain):  \n",
    "    def __init__(self, in_ch, out_ch, kernel, stride, do_rate):\n",
    "        super(SqueezeBlock, self).__init__()\n",
    "        \n",
    "        self.do_rate = do_rate\n",
    "        with self.init_scope():\n",
    "            pad = kernel // 2\n",
    "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=pad, stride=stride)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h, g = F.split_axis(h, 2, 1)\n",
    "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
    "        return h\n",
    "\n",
    "class DilatedBlock(chainer.Chain):\n",
    "     def __init__(self, in_ch, out_ch, kernel, dilate, do_rate):\n",
    "        super(DilatedBlock, self).__init__()\n",
    "        self.do_rate = do_rate\n",
    "        with self.init_scope():\n",
    "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=dilate, dilate=dilate)\n",
    "      \n",
    "     def forward(self, xs):\n",
    "        x = F.concat(xs, axis=1)\n",
    "        h = self.conv(x)\n",
    "        h, g = F.split_axis(h, 2, 1)\n",
    "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHZuRr36bxHv"
   },
   "source": [
    "![Network Structure](https://raw.githubusercontent.com/preferred-medicine/medical-ai-course-materials/master/notebooks/images/7/network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrTAARyW2AYQ"
   },
   "source": [
    "WeightNormalization [2] is a method of expressing parameter representation in length and direction, and is a normalization method used in cases like this series problem. In the code WeightNormalization `WNConvolutionND` is defined as the convolved layer applied .\n",
    "\n",
    "\n",
    "SqueezeBlock is a block to shorten the array with a length of $2^{17}$ to the sequence of $2^{10}$ (upper figure). We use WNConvolutionND to handle a one-dimensional array, and specify 1, which indicates that it is a one-dimensional array, for the first argument. Also, in the activation function, we use the Gated Linear Unit [3] which is denoted as ℎ=𝑊𝑥∗𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝑈𝑥). For efficiency in computation, instead of calculating Wx and Ux separately, applying Convolution with twice the number of output channels, and then divide the output result into two in the channel direction(𝑊𝑥,𝑈𝑥), and then multiply them by element after applying the sigmoid function to one side.\n",
    "\n",
    "DilatedBlock is a block that calculates using long distance information using Dilated Convolution for an array whose length has already become 1024 (upper figure). It takes dilated as an argument. When using Dilated Convolution you can calculate by simply adding dilated to the argument of the usual Convolution layer (this time ConvolutionND but also Convolution 2D).\n",
    "\n",
    "Also, In DilatedBlock, we adopts a method called DenseNet [4], in which all previous intermediate results are used as inputs for the next layer (corresponding to `concat` in forward() within DilatedBlock). This is based on making a lot of skip connections in the neural network so that the gradient does not decay and the training becomes easy even if the number of layers increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-ZdRuhSq2Rq"
   },
   "source": [
    "Let's build a network on a trial and let the sample data flow there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DARrKIMurGiH",
    "outputId": "5435968a-95a9-4fc6-d1c6-5c5ee39a25dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1024, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = Net()\n",
    "size = 131072 # 128 * 1024\n",
    "batchsize = 4\n",
    "x = np.empty((batchsize, size, 4), dtype=np.bool)\n",
    "y = n.forward(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydR6gwYCsATQ"
   },
   "source": [
    "```\n",
    "(4, 1024, 10)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyJ8lu_psGlk"
   },
   "source": [
    "Here, the array which was originally of batch size (B) = 4, input length (L) = 131072, number of input channels (C) = 4 became the array of B = 4, L = 1024, C = 10 after calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLNgEVh0vjOt"
   },
   "source": [
    "The coverage value predicted this time can be regarded as count data showing how frequently the DNA related protein binds to each fragment. Therefore, we use logarithmic Poisson loss function which is loss function for count data in training.\n",
    "\n",
    "When using the logarithmic Poisson loss function, the model predicts the mean which is the only parameter of the Poisson distribution, and calculates the likelihood of the training data when using the Poisson distribution with the predicted mean. Then maximize its likelihood and minimize the same negative logarithmic likelihood. In this case, ignoring the term which does not include the parameter to be trained on the program. Note that the minimum value of this function will not become 0 as it is, so subtract the minimum value $t \\log t$ beforehand so that the minimum value of the loss function will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgQmu0Pgvh0P"
   },
   "outputs": [],
   "source": [
    "import chainer.functions as F\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "def log_poisson_loss(log_x, t):\n",
    "    loss =  F.mean(F.exp(log_x) - t * log_x) \n",
    "    t = chainer.cuda.to_cpu(t.astype(np.float32))  \n",
    "    offset = F.mean(cp.array(t - t * np.ma.log(t)))\n",
    "    return loss - offset\n",
    "\n",
    "\n",
    "def log_r2_score(log_x, t):\n",
    "    return F.r2_score(F.exp(log_x), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40kTUr3O2lu5"
   },
   "source": [
    "We also use CosineScheduler to adjust the learning rate. In training of neural networks, we know that we can find solutions with higher generalization performance gradually as we gradually reduce the learning rate. Since the objective function of the training of the neural network has many poor performance local solutions, the first is to increase the learning rate so that it does not fit into the local solution and find a good solution in the whole, and in the second half, the learning rate is gradually brought close to 0 and converged. CosineScheduler changes the learning rate like the change of the Cosine function from 0 degrees to 90 degrees. Since training is initially unstable, it is also common to increase the learning rate linearly from 0 to the initial learning rate for the first n_warmup cycles. Since learning rate is low and training is stable this time, n_warmup is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QvjM_C-z2o8m"
   },
   "outputs": [],
   "source": [
    "from chainer import training\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CosineScheduler(training.Extension):\n",
    "\n",
    "    def __init__(self, attr='lr', init_val=0.0001, n_decays=200, n_warmups=3, target=None, optimizer=None):\n",
    "        self._attr = attr\n",
    "        self._target = target\n",
    "        self._optimizer = optimizer\n",
    "        self._min_loss = None\n",
    "        self._last_value = None\n",
    "        self._init_val = init_val\n",
    "        self._n_decays = n_decays - n_warmups\n",
    "        self._decay_count = 0\n",
    "        self._n_warmups = n_warmups\n",
    "\n",
    "    def __call__(self, trainer):\n",
    "        updater = trainer.updater\n",
    "        optimizer = self._get_optimizer(trainer)\n",
    "        epoch = updater.epoch\n",
    "        if epoch < self._n_warmups:\n",
    "            value = self._init_val / (self._n_warmups + 1) * (epoch + 1)\n",
    "        else:\n",
    "            value = 0.5 * self._init_val * (1 + math.cos(math.pi * (epoch - self._n_warmups) / self._n_decays))\n",
    "        self._update_value(optimizer, value)\n",
    "\n",
    "\n",
    "    def _get_optimizer(self, trainer):\n",
    "        return self._optimizer or trainer.updater.get_optimizer('main')\n",
    "\n",
    "    def _update_value(self, optimizer, value):\n",
    "        setattr(optimizer, self._attr, value)\n",
    "        self._last_value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56jZaaD82p-X"
   },
   "source": [
    "Finally, we apply Data Augmentation which makes a change which does not change meaning to training data during training. This is the same as rotating and translating in the image. Although coverage value is predicted every 128 bp this time, it is expected that the coverage value will be about the same even if it moves several bases (eg 4 to 8). So we shift the array back and forth by max_shift max. (Putting a completely random base sequence in the remaining part may change from the actual base sequence distribution, so here we roll-shift the roll() function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX2NE83o274Y"
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import random\n",
    "\n",
    "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, xs, ys, max_shift):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        self.max_shift = max_shift\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        # It applies following preprocesses:\n",
    "        #     - Cropping\n",
    "        #     - Random flip\n",
    "\n",
    "        x = self.xs[i]\n",
    "        y = self.ys[i]\n",
    "\n",
    "\n",
    "        s = random.randint(-self.max_shift, self.max_shift)\n",
    "        x = np.roll(x, s, axis=0)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RCVvBw0v9i-"
   },
   "source": [
    "All the preparations are complete now. The rest is to remodel the Chainer's trainer and train it. Run the following code.\n",
    "\n",
    "Since training takes time in the entire original data, only data / `ratio`  portion is used as training and validation data. This time `ratio` is set to 1. In this case, training is completed in about 30 minutes. If you want to try it in a short time, experiment with ratio = 1 as ratio = 10 or ratio = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "b1_e0bE7wB48",
    "outputId": "dc2ce3b1-a66f-4c42-935c-223dab2c9685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J0           2.48903                           67.7519       \n",
      "\u001b[J0           1.84639                           117.127       \n",
      "\u001b[J0           1.89686                           166.72        \n",
      "\u001b[J0           1.81704                           215.449       \n",
      "\u001b[J1           1.85827     1.85512               274.106       \n",
      "\u001b[J1           1.81286                           323.281       \n",
      "\u001b[J1           1.74802                           372.488       \n",
      "\u001b[J1           1.80567                           421.261       \n",
      "\u001b[J1           1.7467                            470.755       \n",
      "\u001b[J2           1.70371     1.78047               528.83        \n",
      "\u001b[J2           1.77928                           577.477       \n",
      "\u001b[J2           1.67051                           626.814       \n",
      "\u001b[J2           1.6415                            675.927       \n",
      "\u001b[J2           1.67238                           725.017       \n",
      "\u001b[J3           1.69656     1.70897               782.987       \n",
      "\u001b[J3           1.63935                           831.673       \n",
      "\u001b[J3           1.64996                           881.092       \n",
      "\u001b[J3           1.63925                           930.107       \n",
      "\u001b[J3           1.71683                           979.111       \n",
      "\u001b[J4           1.63116     1.71748               1036.98       \n",
      "\u001b[J4           1.64786                           1085.9        \n",
      "\u001b[J4           1.6442                            1134.54       \n",
      "\u001b[J4           1.57821                           1183.92       \n",
      "\u001b[J4           1.62886                           1232.91       \n",
      "\u001b[J5           1.61523     1.66392               1290.8        \n",
      "\u001b[J5           1.65216                           1339.78       \n",
      "\u001b[J5           1.61142                           1388.37       \n",
      "\u001b[J5           1.61483                           1437.71       \n",
      "\u001b[J5           1.57835                           1486.61       \n",
      "\u001b[J6           1.56529     1.63406               1544.53       \n",
      "\u001b[J6           1.59062                           1593.49       \n",
      "\u001b[J6           1.61102                           1642.09       \n",
      "\u001b[J6           1.60003                           1691.49       \n",
      "\u001b[J6           1.57222                           1740.46       \n",
      "\u001b[J7           1.55098     1.62176               1798.31       \n",
      "\u001b[J7           1.54207                           1847.28       \n",
      "\u001b[J7           1.5653                            1895.92       \n",
      "\u001b[J7           1.57523                           1944.68       \n",
      "\u001b[J7           1.61043                           1993.73       \n",
      "\u001b[J8           1.57391     1.62377               2051.65       \n",
      "\u001b[J8           1.51835                           2100.61       \n",
      "\u001b[J8           1.58225                           2149.57       \n",
      "\u001b[J8           1.59289                           2198.5        \n",
      "\u001b[J8           1.56643                           2247.32       \n",
      "\u001b[J9           1.55151     1.62115               2305.72       \n",
      "\u001b[J9           1.53593                           2354.7        \n",
      "\u001b[J9           1.57812                           2403.76       \n",
      "\u001b[J9           1.54277                           2452.85       \n",
      "\u001b[J9           1.55514                           2501.51       \n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "from chainer.training import extensions\n",
    "from chainer import training\n",
    "import h5py\n",
    "\n",
    "ml_h5 = h5py.File('seq.h5')\n",
    "\n",
    "train_x = ml_h5['train_in']\n",
    "train_y = ml_h5['train_out']\n",
    "\n",
    "valid_x = ml_h5['valid_in']\n",
    "valid_y = ml_h5['valid_out']\n",
    "\n",
    "test_x = ml_h5['test_in']\n",
    "test_y = ml_h5['test_out']\n",
    "\n",
    "ratio = 1\n",
    "train_x = train_x[:len(train_x)//ratio]\n",
    "train_y = train_y[:len(train_y)//ratio]\n",
    "valid_x = valid_x[:len(valid_x)//ratio]\n",
    "valid_y = valid_y[:len(valid_y)//ratio]\n",
    "\n",
    "\n",
    "max_shift_for_data_augmentation = 5\n",
    "train = PreprocessedDataset(train_x, train_y, max_shift_for_data_augmentation)\n",
    "val = chainer.datasets.TupleDataset(valid_x, valid_y)\n",
    "\n",
    "batchsize = 8\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_r2_score)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = chainer.optimizers.Adam(alpha=lr, beta1=0.97, beta2=0.98)\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer_hooks.GradientClipping(threshold=0.01))\n",
    "\n",
    "\n",
    "updater = training.updaters.StandardUpdater(\n",
    "     train_iter, optimizer, device=0)\n",
    "\n",
    "n_epochs = 10\n",
    "n_warmups = 0\n",
    "out = \"out\"\n",
    "trainer = training.Trainer(updater, (n_epochs, 'epoch'), out=out)\n",
    "trainer.extend(CosineScheduler(attr='alpha', init_val=lr, n_decays=n_epochs, n_warmups=n_warmups), trigger=(1, 'epoch'))\n",
    "\n",
    "trainer.extend(extensions.Evaluator(val_iter, model, device = 0))\n",
    "trainer.extend(extensions.LogReport(trigger=(0.2, 'epoch')))\n",
    "trainer.extend(extensions.snapshot_object(model, 'model_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n",
    "\n",
    "trainer.extend(extensions.PrintReport(\n",
    "          ['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger = (0.1, 'epoch'))\n",
    "\n",
    "# trainer.extend(extensions.ProgressBar())\n",
    "           \n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mN4nDWQW3Dki"
   },
   "source": [
    "If training is successful, the model trained should be output under directory out. Let's see if the model is actually being output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "hfT1yyTl3C9X",
    "outputId": "3e2fc02b-8924-4703-dd64-ae99fd04073e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14172\n",
      "-rw-r--r-- 1 root root   10080 Dec 16 05:24 log\n",
      "-rw-r--r-- 1 root root 1445890 Dec 16 04:47 model_epoch_1\n",
      "-rw-r--r-- 1 root root 1447626 Dec 16 05:25 model_epoch_10\n",
      "-rw-r--r-- 1 root root 1446428 Dec 16 04:51 model_epoch_2\n",
      "-rw-r--r-- 1 root root 1446742 Dec 16 04:55 model_epoch_3\n",
      "-rw-r--r-- 1 root root 1447061 Dec 16 04:59 model_epoch_4\n",
      "-rw-r--r-- 1 root root 1447268 Dec 16 05:04 model_epoch_5\n",
      "-rw-r--r-- 1 root root 1447473 Dec 16 05:08 model_epoch_6\n",
      "-rw-r--r-- 1 root root 1447585 Dec 16 05:12 model_epoch_7\n",
      "-rw-r--r-- 1 root root 1447649 Dec 16 05:16 model_epoch_8\n",
      "-rw-r--r-- 1 root root 1447650 Dec 16 05:21 model_epoch_9\n"
     ]
    }
   ],
   "source": [
    "!ls -l out/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4eQCDXG3L6e"
   },
   "source": [
    "Next, let us also predict test data using the trained model. Let's load the model after training as follows and apply the model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "UfJ7ZEQX3UQS",
    "outputId": "17722083-b2b4-4114-f4c0-138e7ba82987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "(1, 1024, 10)\n",
      "variable([1.8674504  2.004048   1.68377    ... 0.81418294 0.7608197\n",
      "          0.8720923 ])\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_n_epoch = 10\n",
    "out_dir = 'out'\n",
    "model = L.Classifier(Net())\n",
    "chainer.serializers.load_npz('{}/model_epoch_{}'.format(out_dir, model_n_epoch), model)\n",
    "predictor = model.predictor\n",
    "\n",
    "print(len(test_x))\n",
    "with chainer.no_backprop_mode():\n",
    "    test_y_estimated = F.exp(predictor(test_x[:1]))\n",
    "\n",
    "test_y = test_y[:1]\n",
    "\n",
    "print(test_y_estimated.shape)     \n",
    "print(test_y_estimated[0,:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlA0DLxY3atL"
   },
   "source": [
    "Let's excerpt the result and display it. Here, the correct answer and estimation result are output for the first (i = 0) output. Even in this case, although we narrowed down the training data (the number of classes was set to 10) and the number of training is also small, you can see that the peak is captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "colab_type": "code",
    "id": "nN4rkeuU7rjV",
    "outputId": "3e7300c6-abab-4729-bf04-3c56233a1288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f037ea9f6d8>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIIAAAI/CAYAAAALEXL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f037ea94a58>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = test_y_estimated.data\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 10\n",
    "i = 0\n",
    "b1 = plt.bar(range(y.shape[1]), y[0,:,i])\n",
    "b2 = plt.bar(range(y.shape[1]), test_y[0,:,i])\n",
    "plt.legend((b1, b2), ('estimated', 'observed'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmaz68ZrsFOb"
   },
   "source": [
    "If you have time, you can find out if more accurate models would be trained by increasing n_epochs of training from 10 to somewhere in between 30 and 50, or increasing the number of layers, or increasing the number of channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ThNVkbDGWrN"
   },
   "source": [
    "\n",
    "\n",
    "*   [1] \"Sequential regulatory activity prediction across chromosomes with convolutional neural networks\", D. R. Kelly and et al., Genome Res. 2018. 28: 739-750\n",
    "*  [2] \"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks\",  T. Salimans and et al., arXiv:1602.07868\n",
    "*  [3]  \"Language Modeling with Gated Convolutional Networks\", Y. N. Dauphin and et al., arXiv:1612.08083\n",
    "*  [4] \"Densely Connected Convolutional Networks\", G. Huang, and et al., CVPR 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNA Sequence Data Analysis",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
