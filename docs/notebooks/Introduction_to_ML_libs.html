

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2. Basics of machine learning &mdash; ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå°‚é–€ã‚³ãƒ¼ã‚¹ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Basics of neural network" href="Introduction_to_Neural_Network.html" />
    <link rel="prev" title="1. Basis of the mathematics required to machine learning" href="Basic_Math_for_ML.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-797798-11"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-797798-11');
  </script>

  <meta name="description" content="ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå­¦ä¼šå…¬èªè³‡æ ¼å‘ã‘ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™ã€‚æ©Ÿæ¢°å­¦ç¿’ã«å¿…è¦ãªæ•°å­¦ã®åŸºç¤ã®è§£èª¬ã‹ã‚‰æ·±å±¤å­¦ç¿’ï¼ˆãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰ã‚’ç”¨ã„ãŸå®Ÿè·µçš„ãªå†…å®¹ã¾ã§Google Colaboratoryä¸Šã§GPUã‚’ç”¨ã„ã¦å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œå¯èƒ½ãªå½¢å¼ã«ã—ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è³‡æ–™ã¨ã—ã¦ç„¡æ–™å…¬é–‹ã€‚">
  <meta property="og:title" content="ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå°‚é–€ã‚³ãƒ¼ã‚¹ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™">
  <meta property="og:description" content="ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå­¦ä¼šå…¬èªè³‡æ ¼å‘ã‘ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™ã€‚æ©Ÿæ¢°å­¦ç¿’ã«å¿…è¦ãªæ•°å­¦ã®åŸºç¤ã®è§£èª¬ã‹ã‚‰æ·±å±¤å­¦ç¿’ï¼ˆãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰ã‚’ç”¨ã„ãŸå®Ÿè·µçš„ãªå†…å®¹ã¾ã§Google Colaboratoryä¸Šã§GPUã‚’ç”¨ã„ã¦å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œå¯èƒ½ãªå½¢å¼ã«ã—ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è³‡æ–™ã¨ã—ã¦ç„¡æ–™å…¬é–‹ã€‚">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://japan-medical-ai.github.io/medical-ai-course-materials/">
  <meta property="og:image" content="https://raw.githubusercontent.com/japan-medical-ai/medical-ai-course-materials/master/notebooks/images/medical_ai.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@PreferredNetJP">
  <meta name="twitter:creator" content="@PreferredNetJP">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå°‚é–€ã‚³ãƒ¼ã‚¹ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Basic_Math_for_ML.html">1. Basis of the mathematics required to machine learning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. Basics of machine learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Single-regression-analysis">2.1. Single regression analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Problem-setting-(single-regression-analysis)">2.1.1. Problem setting (single regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-1.-Determine-the-model-(single-regression-analysis)">2.1.2. Step 1. Determine the model (single regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-2.-Determine-the-objective-function-(single-regression-analysis)">2.1.3. Step 2. Determine the objective function (single regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-3.-Find-the-optimal-parameter-(single-regression-analysis)">2.1.4. Step 3. Find the optimal parameter (single regression analysis)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Multiple-Regression-analysis">2.2. Multiple Regression analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Problem-setting-(multiple-regression-analysis)">2.2.1. Problem setting (multiple regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-1.-Determine-the-model-(multiple-regression-analysis)">2.2.2. Step 1. Determine the model (multiple regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-2.-Determine-the-objective-function-(multiple-regression-analysis)">2.2.3. Step 2. Determine the objective function (multiple regression analysis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-3.-Optimize-the-parameter-(multiple-regression-analysis)">2.2.4. Step 3. Optimize the parameter (multiple regression analysis)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Implementation-by-Numpy">2.3. Implementation by Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Scikit-learn-the-execution-of-the-machine-learning-algorithm-by">2.4. Scikit-learn the execution of the machine learning algorithm by</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Scikit-learn-åŸºç¤ç·¨">2.4.1. Scikit-learn åŸºç¤ç·¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Scikit-learn-Applied">2.4.2. Scikit-learn Applied</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#The-use-of-sample-data-set">2.4.2.1. The use of sample data set</a></li>
<li class="toctree-l4"><a class="reference internal" href="#2.4.2.2.-Of-the-data-set-division">2.4.2.2. 2.4.2.2. Of the data set division</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Neural_Network.html">3. Basics of neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Chainer.html">4. Introduction to Deep Learning Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_Segmentation.html">5. Practice: Segmentation of MRI</a></li>
<li class="toctree-l1"><a class="reference internal" href="Blood_Cell_Detection.html">6. Practice section: Detection of cells from microscopic images of</a></li>
<li class="toctree-l1"><a class="reference internal" href="DNA_Sequence_Data_Analysis.html">7. Practical part: sequence analysis using deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html">8. Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Electrocardiogram-(ECG)-and-arrhythmia-diagnosis">9. Electrocardiogram (ECG) and arrhythmia diagnosis</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Data-sets">10. Data sets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Data-pre-processing">11. Data pre-processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Series-data-analysis-when-using-the-deep-learning">12. Series data analysis when using the deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Evaluation">13. Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Towards-the-accuracy">14. Towards the accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#Conclusion">15. Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html#References">16. References</a></li>
</ul>

            
          
          <div style="padding-right:20px; bottom:10px;">
            <a href="https://short-term.kikagaku.co.jp/dnn-seminar/">
              <img src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/img_handson.png" />
              <p style="padding:5px; font-size:small; line-height: 150%">ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®è©³ã—ã„è§£èª¬ã‚„ç”»åƒãƒ»è‡ªç„¶è¨€èªã®å–ã‚Šæ‰±ã„ã€ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®GPUã‚’ä½¿ã£ãŸå®Ÿè·µçš„ãªæ¼”ç¿’ã‚’ã”å¸Œæœ›ã®æ–¹ã¯ã“ã¡ã‚‰ãŒãŠã™ã™ã‚ã§ã™</p>
            </a>
          </div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«AIå°‚é–€ã‚³ãƒ¼ã‚¹ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›ç¾©è³‡æ–™</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>2. Basics of machine learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Introduction_to_ML_libs.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p><a class="reference external" href="https://colab.research.google.com/github/preferred-medicine/medical-ai-course-materials/blob/master/notebooks/Introduction_to_ML_libs.ipynb"><img alt="colab-logo" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="Basics-of-machine-learning">
<h1>2. Basics of machine learning<a class="headerlink" href="#Basics-of-machine-learning" title="Permalink to this headline">Â¶</a></h1>
<p>In this chapter, we introduce the representative machine learning algorithms and the points of how to use them, together with the mathematical background. Letâ€™s think about algorithms of <strong>single regression analysis</strong> and <strong>multiple regression analysis</strong> together with mathematical expressions as a practice to acquire the concept of machine learning . By learning these, you will see how to use differentiation, linear algebra, and statistics. There are many places in the neural network which will
be introduced in the next chapter that will be based on the concept of multiple regression analysis.</p>
<div class="section" id="Single-regression-analysis">
<h2>2.1. Single regression analysis<a class="headerlink" href="#Single-regression-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>First, we will discuss single regression analysis, which is one of the most basic methods of machine learning algorithms. Machine learning algorithms are roughly divided into <strong>supervised learning</strong> and <strong>unsupervised learning</strong>, and simple regression analysis is a type of supervised learning. As a typical problem of supervised learning,10Or0.1There are <strong>regressions</strong> to predict numerical values (strictly continuous values) as in, and <strong>classification</strong> to predict category values like red wine
or white wine . Simple regression analysis, as the name implies, is a method that handles regression, and is a machine learning algorithm that predicts one output variable from one input variable.</p>
<div class="section" id="Problem-setting-(single-regression-analysis)">
<h3>2.1.1. Problem setting (single regression analysis)<a class="headerlink" href="#Problem-setting-(single-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>In machine learning, learning is performed based on data, but it is necessary for humans to decide what to use and what to predict from the information contained in the data.</p>
<p>Here, as an example, let us consider the problem of predicting rent. Therefore, rent is an <strong>output variable</strong> <span class="math notranslate nohighlight">\(y\)</span> It becomes.</p>
<p>Then, the <strong>input variables</strong> consider what should be adopted as. For rent forecasting, for example, the room size, the distance from the station, and the crime rate can be considered as input variables. Here we input the size of the room variable <span class="math notranslate nohighlight">\(x\)</span> Letâ€™s adopt as. In practice, when there are multiple input variable candidates, modeling that can handle all of them is generally used, but this will be introduced later in the multiple regression analysis.</p>
<p>In the machine learning algorithm, each method is roughly divided into the following three steps.</p>
<ul class="simple">
<li>Step 1: Determine the model</li>
<li>Step 2: Determine the objective function</li>
<li>Step 3: Find the optimal parameters</li>
</ul>
<p>We will explain the above three steps in order.</p>
</div>
<div class="section" id="Step-1.-Determine-the-model-(single-regression-analysis)">
<h3>2.1.2. Step 1. Determine the model (single regression analysis)<a class="headerlink" href="#Step-1.-Determine-the-model-(single-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>First, decide the <strong>model</strong> in Step1 . Model is an output variable <span class="math notranslate nohighlight">\(y\)</span> And input variables <span class="math notranslate nohighlight">\(x\)</span> It is a <strong>formulation</strong> of the relationship of . How can we formulate the rent and predict it well? Currently, this model design is generally performed manually, and machines do not automatically determine this (in recent years, research has also progressed to automatically determine models such as AutoML).</p>
<p>For example, in a given data set, suppose that the relationship between rent and room size is as follows.</p>
<p><img alt="å®¶è³ƒã¨éƒ¨å±‹ã®åºƒã•ã®é–¢ä¿‚" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/01.png" /></p>
<p>In this case, the larger the room, the higher the rent, and it seems reasonable to use a straight line for prediction.</p>
<p><img alt="ç›´ç·šå¼ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«åŒ–" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/02.png" /></p>
<p>In this case, the straight line is adopted as a model, and the model of Step 1 is formulated as follows.</p>
<div class="math notranslate nohighlight">
\[y = wx + b\]</div>
<p>here <span class="math notranslate nohighlight">\(w\)</span> Is inclined, <span class="math notranslate nohighlight">\(b\)</span> Is a parameter called intercept (in machine learning, <strong>weight</strong> is the slope ) <span class="math notranslate nohighlight">\(w\)</span>, <strong>Bias the segment (bias)</strong> <span class="math notranslate nohighlight">\(b\)</span> It is common to express with the symbol).</p>
<p>In single regression analysis, the model is thus straight <span class="math notranslate nohighlight">\(y = wx + b\)</span> Decide the weightğ‘¤And bias <span class="math notranslate nohighlight">\(b\)</span> Adjust the to fit the data well.</p>
<p>The goal of many machine learning is to use a model characterized by such parameters and to find the optimal parameters to fit a given <strong>data set</strong> . Here, the data set is the size of the room, which is an input variable <span class="math notranslate nohighlight">\(x\)</span> And the rent to be teacher data <span class="math notranslate nohighlight">\(t\)</span> A set of data consisting of a set of <span class="math notranslate nohighlight">\(y\)</span> , Give something as teacher data <span class="math notranslate nohighlight">\(t\)</span> And I use it separately).</p>
<p>The data set is <span class="math notranslate nohighlight">\(\mathcal{D} = \{x_n, t_n\}_{n=1}^{N}\)</span> It may also be represented as. Where subscriptğ‘› (<span class="math notranslate nohighlight">\(n=1,2,\ldots,N\)</span>) Is <span class="math notranslate nohighlight">\(n\)</span> It means the second property,<span class="math notranslate nohighlight">\(N\)</span> Is the total number of properties. this <span class="math notranslate nohighlight">\(N\)</span> Is called the <strong>number of samples</strong> .</p>
<p>Here, we will introduce a technique called <strong>data centering</strong> to facilitate the subsequent calculations . As shown in the figure below, the room size and the rent both have positive values, so it looks like the graph on the left. Centering means <strong>averaging</strong> <span class="math notranslate nohighlight">\(\boldsymbol{0}\)</span> It performs conversion processing such as placing it in the center. This centralization is generally performed as preprocessing in many algorithms. Strictly speaking, centralization scaling described in the previous
chapter is often used.</p>
<p><img alt="ä¸­å¿ƒåŒ–å‡¦ç†" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/03.png" /></p>
<p>As one of the reasons for this process, as shown in the figure below, bias is due to centralization of data <span class="math notranslate nohighlight">\(b\)</span>But <span class="math notranslate nohighlight">\(0\)</span> And <span class="math notranslate nohighlight">\(y_{c} = wx_{c}\)</span> It can be mentioned that the model can be expressed without bias components, as this can reduce the parameters to be adjusted.</p>
<p><img alt="ä¸­å¿ƒåŒ–å¾Œã®ç›´ç·šå¼" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/04.png" /></p>
<p>Centralization of the data is achieved by subtracting the average of the input and output from the whole of the data. In other words,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x_{c} &amp;= x - \bar{x} \\
t_{c} &amp;= t - \bar{t}
\end{aligned}\end{split}\]</div>
<p>It becomes. For example, looking at specific numbers, it is as shown in the figure below.</p>
<p><img alt="ä¸­å¿ƒåŒ–å‰å¾Œã®æ•°å€¤æ¯”è¼ƒ" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/05.png" /></p>
<p>Indexed to indicate after centering ğ‘Because the expression is redundant with respect to, it is assumed in the future that this subscript is omitted and data centralization is performed in advance. At this time, the model is</p>
<div class="math notranslate nohighlight">
\[y = wx\]</div>
<p>And the goal of simple regression analysis is the data set <span class="math notranslate nohighlight">\(\mathcal{D} = \{x_n, t_n\}_{n=1}^{N}\)</span> Parameters based on ğ‘¤The right will be adjusted.</p>
</div>
<div class="section" id="Step-2.-Determine-the-objective-function-(single-regression-analysis)">
<h3>2.1.3. Step 2. Determine the objective function (single regression analysis)<a class="headerlink" href="#Step-2.-Determine-the-objective-function-(single-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>As explained in Chapter 1, supervised learning often involves designing an objective function and learning the model by minimizing (or maximizing) the objective function.</p>
<p>This time, the goal is to match the teacher data and the predicted value, and the squared error of the teacher data and the predicted value is used as an objective function to express it. The squared error is0And only when <span class="math notranslate nohighlight">\(t = y\)</span> It can be said that we have achieved perfect prediction. <span class="math notranslate nohighlight">\(n\)</span> Teacher data for the second property <span class="math notranslate nohighlight">\(t_{n}\)</span> And predicted value <span class="math notranslate nohighlight">\(y_{n}\)</span> The squared error of</p>
<div class="math notranslate nohighlight">
\[(t_{n} - y_{n})^{2}\]</div>
<p>It becomes. Since it is necessary to consider this for all properties, the final objective function takes its sum</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + (t_{N}-y_{N})^{2} \\
&amp;=\sum^{N}_{n=1}\left( t_{n}-y_{n}\right)^{2}\\
\end{aligned}\end{split}\]</div>
<p>It becomes. Also, the model decided in Step 1</p>
<div class="math notranslate nohighlight">
\[y_{n} = wx_{n}\]</div>
<p>The objective function is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\sum^{N}_{n=1}\left( t_{n}-wx_{n}\right)^{2}\]</div>
<p>It can be expressed in a form that includes and parameters. Remember that such a function is called a loss function.</p>
</div>
<div class="section" id="Step-3.-Find-the-optimal-parameter-(single-regression-analysis)">
<h3>2.1.4. Step 3. Find the optimal parameter (single regression analysis)<a class="headerlink" href="#Step-3.-Find-the-optimal-parameter-(single-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>The last step is to find parameters that minimize the objective function. Here we have already learned that differentiation can be used as a way to find points to minimize a function. In the case of the square of the difference like this time, the point at which â€œSlope 0â€ is differentiated is the loss.0The point is The derivative of the objective function is as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac{\partial }{\partial w} \mathcal{L}  &amp;= \dfrac{\partial}{\partial w} { \sum^{N}_{n=1} ( t_{n}-wx_{n})^{2} }\\
\end{aligned}\end{split}\]</div>
<p>Here, the derivative has the property of <strong>linearity</strong>, and in particular, the derivative of the sum is obtained using the fact that it is the sum of derivatives.</p>
<div class="math notranslate nohighlight">
\[\dfrac{\partial}{\partial w} \mathcal{L}=\sum^{N}_{n=1}\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}\]</div>
<p>Where differentiation and summation <span class="math notranslate nohighlight">\(\sum\)</span> The symbol of is replaced. Next, looking at the terms of the sum,</p>
<div class="math notranslate nohighlight">
\[\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}\]</div>
<p>Part of <span class="math notranslate nohighlight">\(t_n - wx_n\)</span> You can see that it is a composite function of and its square .<span class="math notranslate nohighlight">\(u_{n} = t_{n} - wx_{n}\)</span>, <span class="math notranslate nohighlight">\(f(u_{n}) = u_{n}^{2}\)</span> If you</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2} &amp;=  \dfrac {\partial }{\partial w} f(u_{n}) \\
&amp;= \dfrac {\partial u_{n}}{\partial w} \dfrac{\partial f(u_{n})}{\partial u_{n}} \\
&amp;=-x_{n} \times 2 u_{n}  \\
&amp;= -2x_{n}( t_{n}-wx_{n} )
\end{aligned}\end{split}\]</div>
<p>can be obtained. Than this,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac{\partial }{\partial w} \mathcal{L}
&amp;=\sum^{N}_{n=1}\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}
\\&amp;=-\sum^{N}_{n=1}2x_{n}\left( t_{n}-wx_{n}\right)
\end{aligned}\end{split}\]</div>
<p>It becomes. So that the value of this derivative is 0 <span class="math notranslate nohighlight">\(w\)</span> When you ask for</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial w} \mathcal{L} &amp;=0\\
-2\sum^{N}_{n=1}x_{n}\left( t_{n}-wx_{n}\right) &amp;=0\\
-2 \sum^{N}_{n=1}x_{n}t_{n} + 2\sum^{N}_{n=1}wx^{2}_{n}&amp;=0\\
-2\sum^{N}_{n=1}x_{n}t_{n}+2w\sum^{N}_{n=1}x^{2}_{n}&amp;=0\\
w\sum^{N}_{n=1}x^{2}_{n}&amp;=\sum^{N}_{n=1}x_{n}t_{n}\\
\end{aligned}\end{split}\]</div>
<p>Than,</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
w&amp;=\dfrac {\displaystyle  \sum^{N}_{n=1}x_{n}t_{n}}{\displaystyle  \sum^{N}_{n=1}x^{2}_{n}}
\end{aligned}\]</div>
<p>I asked for it. This parameterğ‘¤ Check the given data set <span class="math notranslate nohighlight">\(\mathcal{D} = \{x_n, t_n\}_{n=1}^{N}\)</span> It can be seen that the decision can be made only from.</p>
<p>Next, the parameters in the numerical example given in the example ğ‘¤Letâ€™s ask for First, to centralize the data,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\bar{x} &amp;= \dfrac{1}{3} (1 + 2 + 3) = 2 \\
\bar{t} &amp;= \dfrac{1}{3}(2 + 3.9 + 6.1) = 4
\end{aligned}\end{split}\]</div>
<p>And averaging each of them, and subjecting each variable to preprocessing as central processing,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x_{1} &amp;= 1 - 2 = -1 \\
x_{2} &amp;= 2 -2 = 0 \\
x_{3} &amp;= 3- 2 = 1\\
t_{1} &amp;= 2 - 4 = -2\\
t_{2} &amp;= 3.9 - 4 = -0.1\\
t_{3} &amp;= 6.1 - 4 = 2.1
\end{aligned}\end{split}\]</div>
<p>It becomes. And, using the values after centering, the optimal parameters <span class="math notranslate nohighlight">\(w\)</span> If you derive</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
w &amp;= \dfrac{\displaystyle \sum_{n=1}^{N}x_{n}t_{n}}{\displaystyle  \sum_{n=1}^{N}x_{n}^{2}} \\
&amp;= \dfrac{x_{1}t_{1} + x_{2}t_{2} + x_{3}t_{3}}{x_{1}^{2} + x_{2}^{2} + x_{3}^{2}} \\
&amp;= \dfrac{-1 \times (-2) + 0 \times 0.1 + 1 \times 2.1}{(-1)^{2} + 0^2 + 1^2} \\
&amp;= 2.05
\end{aligned}\end{split}\]</div>
<p>I asked for it. This completes learning for simple regression analysis. The model using the obtained parameters is the trained <strong>model</strong>.</p>
<p>Next, letâ€™s use this model to make predictions for new samples. The process of calculating predicted values â€‹â€‹for new input data using a learned model is called <strong>inference</strong> . For example, a new sample <span class="math notranslate nohighlight">\(x_{q}=1.5\)</span> The predicted value for can be obtained as follows,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y_{c} &amp;= wx_{c} \\
y_{q} - \bar{t} &amp;= w(x_{q}-\bar{x}) \\
\Rightarrow y_{q} &amp;= w(x_{q}-\bar{x}) + \bar{t} \\
&amp;= 2.05 \times (1.5 - 2) + 4 \\
&amp;= 2.975
\end{aligned}\end{split}\]</div>
<p>Since the model was trained using centralized data, it is important to remember that the actual predicted values â€‹â€‹will be restored to the centralized data.</p>
<p>The above is a series of steps of single regression analysis.</p>
</div>
</div>
<div class="section" id="Multiple-Regression-analysis">
<h2>2.2. Multiple Regression analysis<a class="headerlink" href="#Multiple-Regression-analysis" title="Permalink to this headline">Â¶</a></h2>
<p>Next, we will deal with multiple regression analysis dealing with multivariable input variables. The knowledge of linear algebra will be deepened by learning this multiple regression analysis.</p>
<p>Multiple regression analysis is a type of supervised learning similar to simple regression analysis, and is a method for dealing with regression. The problem setting is almost the same as single regression analysis, but in multiple regression analysis, there are multiple input variables. In other words, it is a machine learning algorithm that can predict output variables from multiple input variables.</p>
<div class="section" id="Problem-setting-(multiple-regression-analysis)">
<h3>2.2.1. Problem setting (multiple regression analysis)<a class="headerlink" href="#Problem-setting-(multiple-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>Here, considering the problem of predicting rent as in the case of simple regression analysis, rent is an output variable <span class="math notranslate nohighlight">\(y\)</span> will do. As input variables, we will also take into consideration the distance from the station and the crime rate that could not be considered in single regression analysis. For example, the size of the room <span class="math notranslate nohighlight">\(x_{1}\)</span>, Distance from the station <span class="math notranslate nohighlight">\(x_{2}\)</span>, â€¦, crime rate <span class="math notranslate nohighlight">\(x_{M}\)</span> like <span class="math notranslate nohighlight">\(M\)</span> Suppose that there are <span class="math notranslate nohighlight">\(M=1\)</span> In the case of, it is
reduced to the problem of single regression analysis).</p>
<p>Similar to single regression analysis, learning is performed in the following three steps.</p>
<ul class="simple">
<li>Determine the model</li>
<li>Determine the objective function</li>
<li>Find the optimal parameter</li>
</ul>
<p>ã“ã“ã§ã¯å˜å›å¸°åˆ†æã®å ´åˆã¨åŒæ§˜ã«å®¶è³ƒã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã‚’è€ƒãˆï¼Œå®¶è³ƒã‚’å‡ºåŠ›å¤‰æ•° <span class="math notranslate nohighlight">\(y\)</span> ã¨ã—ã¾ã™ï¼å…¥åŠ›å¤‰æ•°ã¨ã—ã¦ã¯ï¼Œå˜å›å¸°åˆ†æã§ã¯è€ƒæ…®ã—ãã‚Œã¦ã„ãªã‹ã£ãŸé§…ã‹ã‚‰ã®è·é›¢ã‚„çŠ¯ç½ªç™ºç”Ÿç‡ãªã©ã‚‚è€ƒæ…®ã—ã¦ã„ãã¾ã™ï¼ä¾‹ãˆã°ï¼Œéƒ¨å±‹ã®åºƒã• <span class="math notranslate nohighlight">\(x_{1}\)</span>, é§…ã‹ã‚‰ã®è·é›¢ <span class="math notranslate nohighlight">\(x_{2}\)</span>, â€¦, çŠ¯ç½ªç™ºç”Ÿç‡ <span class="math notranslate nohighlight">\(x_{M}\)</span> ã®ã‚ˆã†ã« <span class="math notranslate nohighlight">\(M\)</span> å€‹ã®å…¥åŠ›å¤‰æ•°ãŒã‚ã‚‹ã¨ã—ã¾ã™ï¼ˆ<span class="math notranslate nohighlight">\(M=1\)</span>ã®å ´åˆï¼Œå˜å›å¸°åˆ†æã®å•é¡Œã«å¸°ç€ã•ã‚Œã¾ã™ï¼‰ï¼</p>
<p>å˜å›å¸°åˆ†æã¨åŒæ§˜ï¼Œä»¥ä¸‹ã®3ã‚¹ãƒ†ãƒƒãƒ—ã§å­¦ç¿’ã—ã¦ã„ãã¾ã™ï¼</p>
<ul class="simple">
<li>ãƒ¢ãƒ‡ãƒ«ã‚’æ±ºã‚ã‚‹</li>
<li>ç›®çš„é–¢æ•°ã‚’æ±ºã‚ã‚‹</li>
<li>æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±‚ã‚ã‚‹</li>
</ul>
</div>
<div class="section" id="Step-1.-Determine-the-model-(multiple-regression-analysis)">
<h3>2.2.2. Step 1. Determine the model (multiple regression analysis)<a class="headerlink" href="#Step-1.-Determine-the-model-(multiple-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>The model for single regression analysis is</p>
<div class="math notranslate nohighlight">
\[y = wx + b\]</div>
<p>And,<span class="math notranslate nohighlight">\(w\)</span> The weight, <span class="math notranslate nohighlight">\(b\)</span> Was called a bias. In multiple regression analysis, this expression is expanded to multiple input variables,</p>
<div class="math notranslate nohighlight">
\[y=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+b\]</div>
<p><strong>Expressed</strong> in the form of <strong>linear combination</strong> like . In this case, it is assumed that each input variable linearly affects the output variable, which is a fairly simple modeling. In practice, if there is a non-linear dependency between input variables, you need to model it taking that into consideration. I will explain it in the future.</p>
<p>The model of multiple regression analysis can be organized using the symbol of summation,</p>
<div class="math notranslate nohighlight">
\[y = \sum_{m=1}^{M} w_{m} x_{m} + b\]</div>
<p>Can be written as And here, <span class="math notranslate nohighlight">\(x_0 = 1\)</span>ï¼Œ<span class="math notranslate nohighlight">\(w_0 = b\)</span> If you</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+b\\
&amp;=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+w_{0} x_{0}\\
&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
\end{aligned}\end{split}\]</div>
<p>Like bias <span class="math notranslate nohighlight">\(b\)</span> Can be included in the summation. And as we sort out this formula,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
&amp;=\begin{bmatrix}
w_{0} &amp; w_{1} &amp; \ldots  &amp; w_{M}
\end{bmatrix}\begin{bmatrix}
x_{0} \\
x_{1} \\
\vdots  \\
x_{M}
\end{bmatrix}\\
&amp;=\boldsymbol{w}^{T}\boldsymbol{x}
\end{aligned}\end{split}\]</div>
<p>It can be expressed as the inner product of vectors, like. Also, when handling in the future, <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> Is more computationally convenient to come in front of</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
&amp;=\begin{bmatrix}
x_{0} &amp; x_{1} &amp; \ldots  &amp; x_{M}
\end{bmatrix}\begin{bmatrix}
w_{0} \\
w_{1} \\
\vdots  \\
w_{M}
\end{bmatrix}\\
&amp;=\boldsymbol{x}^{T}\boldsymbol{w}
\end{aligned}\end{split}\]</div>
<p>Express as. This is a model of multiple regression analysis. This time as a parameter <span class="math notranslate nohighlight">\(M+1\)</span> Weight <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> I will seek for</p>
</div>
<div class="section" id="Step-2.-Determine-the-objective-function-(multiple-regression-analysis)">
<h3>2.2.3. Step 2. Determine the objective function (multiple regression analysis)<a class="headerlink" href="#Step-2.-Determine-the-objective-function-(multiple-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>In single regression analysis, teacher data <span class="math notranslate nohighlight">\(t\)</span> And predicted value <span class="math notranslate nohighlight">\(y\)</span> The smaller the squared error of, the better the prediction, and the sum is defined as the objective function. Predicted value even in multiple regression analysis <span class="math notranslate nohighlight">\(y\)</span> Since asking for is the same, we use the same objective function asï¼‰</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\mathcal{L}&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + \left( t_{N}-y_{N}\right)^{2}
\end{aligned}\]</div>
<p>In this way, <strong>the sum of squared errors</strong> is adopted as an objective function as in single regression analysis. In single regression analysis, this is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\sum^{N}_{n=1} ( t_{n} - y_{n})^{2}\]</div>
<p>As in, it was summarized using the symbol of the sum,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + \left( t_{N}-y_{N}\right)^{2}\\
&amp;=\begin{bmatrix} t_{1} - y_{1} &amp; t_{2}-y_{2} &amp; \ldots &amp; t_{N}-y_{N} \end{bmatrix} \begin{bmatrix}
t_{1}-y_{1} \\
t_{2}-y_{2} \\
\vdots \\
t_{N}-y_{N}
\end{bmatrix}\\
&amp;=\left( \boldsymbol{t}-\boldsymbol{y}\right)^{T}\left( \boldsymbol{t}-\boldsymbol{y}\right)
\end{aligned}\end{split}\]</div>
<p>It can also be expressed using a vector like. Also, <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> With regard to</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{y}=\begin{bmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{N}
\end{bmatrix}=\begin{bmatrix}
\boldsymbol{x}_{1}^{T}\boldsymbol{w} \\
\boldsymbol{x}_{2}^{T}\boldsymbol{w} \\
\vdots  \\
\boldsymbol{x}_{N}^{T}\boldsymbol{w}
\end{bmatrix}
=\begin{bmatrix}
\boldsymbol{x}_{1}^{T} \\
\boldsymbol{x}_{2}^{T} \\
\vdots  \\
\boldsymbol{x}_{N}^{T}
\end{bmatrix}
\boldsymbol{w}
\end{aligned}\end{split}\]</div>
<p>Can be written as Organizing this,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{y}&amp;=
\begin{bmatrix}
x_{10} &amp; x_{11} &amp; x_{12} &amp; \ldots  &amp; x_{1M} \\
x_{20} &amp; x_{21} &amp; x_{22} &amp; \ldots  &amp; x_{2M} \\
\vdots  &amp; \vdots  &amp; \vdots  &amp; \ddots  \\
x_{N0} &amp; x_{N1} &amp; x_{N{2}} &amp; \ldots  &amp; x_{NM}
\end{bmatrix}\begin{bmatrix}
w_{0} \\
w_{1} \\
w_{2} \\
\vdots  \\
w_{M}
\end{bmatrix}\\
&amp;=\boldsymbol{X}\boldsymbol{w}
\end{aligned}\end{split}\]</div>
<p>It can be written as Here, the row (horizontal) direction represents a sample, for example, corresponding to each property. The column (vertical) direction represents the input variable, for example, the size of the room or the distance from the station. In terms of a little more concrete numbers, the size of the room <span class="math notranslate nohighlight">\(= 50m^{2}\)</span> , Distance from the station <span class="math notranslate nohighlight">\(= 600 m\)</span> , Crime rate <span class="math notranslate nohighlight">\(= 2\)</span>% like <span class="math notranslate nohighlight">\(n\)</span> For the second property, the number of input variables <span class="math notranslate nohighlight">\(M=3\)</span> And,</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{x}_{n}^{T} = \begin{bmatrix}
1 &amp; 50 &amp; 600 &amp; 0.02
\end{bmatrix}\]</div>
<p>It is an image where data is stored in the row direction like. At the beginning <span class="math notranslate nohighlight">\(1\)</span> Is used to include bias <span class="math notranslate nohighlight">\(x_{0}\)</span> Please note that is</p>
</div>
<div class="section" id="Step-3.-Optimize-the-parameter-(multiple-regression-analysis)">
<h3>2.2.4. Step 3. Optimize the parameter (multiple regression analysis)<a class="headerlink" href="#Step-3.-Optimize-the-parameter-(multiple-regression-analysis)" title="Permalink to this headline">Â¶</a></h3>
<p>Then, model parameters to minimize the objective function of Step 2 <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Letâ€™s ask for</p>
<p>â€» <strong>Here we will find analytical solutions of the optimal parameters while making full use of equation transformation, but the derivation process is a bit more complicated, and the results are shown in the next section (2.3 2.3), so we are interested If you donâ€™t, skip to the next section</strong>.</p>
<p>First of all, regarding the objective function, <span class="math notranslate nohighlight">\(w\)</span> If you change the expression so that it can be expressed by,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=\left( \boldsymbol{t}-\boldsymbol{y}\right)^{T}\left( \boldsymbol{t}-\boldsymbol{y}\right) \\
&amp;=\left( \boldsymbol{t}-\boldsymbol{X}\boldsymbol{w}\right)^{T}\left( \boldsymbol{t}-\boldsymbol{X}\boldsymbol{w}\right) \\
&amp;= \left\{ \boldsymbol{t}^{T}-(\boldsymbol{X}\boldsymbol{w})^{T}\right\}\left( \boldsymbol{t}-\boldsymbol{X}\boldsymbol{w}\right) \\
&amp;=\left( \boldsymbol{t}^{T}-\boldsymbol{w}^{T}\boldsymbol{X}^{T}\right)\left( \boldsymbol{t}-\boldsymbol{X}\boldsymbol{w}\right)
\end{aligned}\end{split}\]</div>
<p>It becomes. Where the transposition formula<span class="math notranslate nohighlight">\((\boldsymbol{A}\boldsymbol{B})^{T} = \boldsymbol{B}^{T}\boldsymbol{A}^{T}\)</span> Note that we are using Furthermore, if development is advanced using the distribution law,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=\boldsymbol{t}^{T}\boldsymbol{t}-\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w}-\boldsymbol{w}^{T}\boldsymbol{X}^{T}\boldsymbol{t} + \boldsymbol{w}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}\\
\end{aligned}\end{split}\]</div>
<p>It becomes. Parameters for this objective function <span class="math notranslate nohighlight">\(w\)</span> We want to take a partial derivative of, but before that we can organize this expression a bit more. First,</p>
<div class="math notranslate nohighlight">
\[(1)^T = 1\]</div>
<p>Thus, scalars do not change even if they are transposed. Come out in the above formula <span class="math notranslate nohighlight">\(\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w}\)</span> Is a scalar, so</p>
<div class="math notranslate nohighlight">
\[(\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w})^{T} = \boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w}\]</div>
<p>Is true. Furthermore, the transposition formula <span class="math notranslate nohighlight">\((\boldsymbol{A}\boldsymbol{B}\boldsymbol{C})^T = \boldsymbol{C}^T\boldsymbol{B}^T\boldsymbol{A}^T\)</span> Than,</p>
<div class="math notranslate nohighlight">
\[(\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w})^T = \boldsymbol{w}^{T} \boldsymbol{X}^{T} \boldsymbol{t}\]</div>
<p>Is also true. Than this,</p>
<div class="math notranslate nohighlight">
\[(\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w})^{T} = \boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w} = \boldsymbol{w}^{T} \boldsymbol{X}^{T} \boldsymbol{t}\]</div>
<p>Can lead. Objective function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> If you use the above equation,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}=\boldsymbol{t}^{T}\boldsymbol{t}-2\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w} + \boldsymbol{w}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}\\
\end{aligned}\end{split}\]</div>
<p>Can be summarized. here, <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> To do partial differentiation with respect to <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> If you put together the constant terms other than</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=\boldsymbol{t}^{T}\boldsymbol{t}-2\boldsymbol{t}^{T}\boldsymbol{X}\boldsymbol{w}+\boldsymbol{w}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}\\
&amp;=\boldsymbol{t}^{T}\boldsymbol{t}-2\left( \boldsymbol{X}^{T}\boldsymbol{t}\right)^{T} \boldsymbol{w}+\boldsymbol{w}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w} \\
&amp;= \gamma + \boldsymbol{\beta}^{T}\boldsymbol{w} + \boldsymbol{w}^{T}\boldsymbol{A}\boldsymbol{w}
\end{aligned}\end{split}\]</div>
<p>Learned with linear algebra, like <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> It was able to express in quadratic form (quadric function) about. here,<span class="math notranslate nohighlight">\(\boldsymbol{A}= \boldsymbol{X}^{T}\boldsymbol{X},, \ \boldsymbol{\beta} =-2 \boldsymbol{X}^{T}\boldsymbol{t}, , \ \gamma = \boldsymbol{t}^{T}\boldsymbol{t}\)</span> And,<span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> The reason for having transposed form is to devise a vector learned by linear algebra to conform to the form of derivative formula.</p>
<p>Then, the parameter which can minimize the objective function <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Letâ€™s consider how to ask for As mentioned earlier, the objective function is a parameter <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> It is a quadratic function with respect to. For example,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{w} = \begin{bmatrix}
w_{1} \\ w_{2}
\end{bmatrix},
\boldsymbol{A}=\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix},\boldsymbol{\beta}=\begin{bmatrix}
1 \\
2
\end{bmatrix}, \gamma = 1
\end{aligned}\end{split}\]</div>
<p>If you think with concrete numerical examples like,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L} &amp; =
\boldsymbol{w}^{T}\boldsymbol{A}\boldsymbol{w} + \boldsymbol{\beta}^{T}\boldsymbol{w} + \gamma \\
&amp;=
\begin{bmatrix}
w_{1} &amp; w_{2}
\end{bmatrix}\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}\begin{bmatrix}
w_{1} \\
w_{2}
\end{bmatrix}
+\begin{bmatrix}
1 &amp; 2
\end{bmatrix} \begin{bmatrix}
w_{1} \\
w_{2}
\end{bmatrix} + 1 \\
&amp;=
\begin{bmatrix}
w_{1} &amp; w_{2}
\end{bmatrix}
\begin{bmatrix}
w_{1} + 2w_{2} \\
3w_{1} + 4w_{2}
\end{bmatrix} + w_{1} + 2w_{2} + 1 \\
&amp;=w_{1}\left( w_{1} + 2w_{2}\right) + w_{2}\left( 3w_{1} + 4w_{2}\right) + w_{1} + 2w_{2} + 1 \\
&amp;=w^{2}_{1} + 5w_{1}w_{2} + 4w^{2}_{2} + w_{1} + 2w_{2}+1 \\
\end{aligned}\end{split}\]</div>
<p>And <span class="math notranslate nohighlight">\(w_{1}, w_{2}\)</span> In terms of</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}
&amp;= w^{2}_{1} + \left( 5w_{2} + 1\right) w_{1} +
\left( 4w^{2}_{2}+2w_{2}+1\right) \\
&amp;=4w^{2}_{2} + \left(5w_{1} + 2\right) w_{2} + \left( w^{2}_{1} + w_{1} + 1\right) \end{aligned}\end{split}\]</div>
<p>You can see that it is each quadratic function like.</p>
<p>And if it is a quadratic function, it looks like the figure below.</p>
<p><img alt="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ç›®çš„é–¢æ•°ã®é–¢ä¿‚ï¼ˆ2æ¬¡å…ƒï¼‰" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/06.png" /></p>
<p>If this is imaged in three dimensions, it will become like the following figure.</p>
<p><img alt="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ç›®çš„é–¢æ•°ã®é–¢ä¿‚ï¼ˆ3æ¬¡å…ƒï¼‰" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/08.png" /></p>
<p>Then, at the point where the sum of squared errors, which is the objective function, is minimum, the slope when differentiated with each variable is zero.</p>
<p><img alt="ç›®çš„é–¢æ•°ãŒæœ€å°ã¨ãªã‚‹ç‚¹" src="https://github.com/preferred-medicine/medical-ai-course-materials/raw/master/notebooks/images/2/07.png" /></p>
<p>In this example<span class="math notranslate nohighlight">\(w_{1}\)</span> when <span class="math notranslate nohighlight">\(w_{2}\)</span> I considered in the case of two parameters of <span class="math notranslate nohighlight">\(w_{0}\)</span>, <span class="math notranslate nohighlight">\(w_{1}\)</span>, <span class="math notranslate nohighlight">\(w_{2}\)</span>, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(w_{M}\)</span> You can think in the same way for</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}
\dfrac {\partial }{\partial w_{0}}\mathcal{L}=0\\
\dfrac {\partial }{\partial w_{1}}\mathcal{L}=0\\
\ \ \ \ \ \vdots \\
\dfrac {\partial }{\partial w_{M}}\mathcal{L}=0\\
\end{cases}\end{split}\]</div>
<p>And put it together,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\begin{bmatrix}
\dfrac {\partial}{\partial w_{0}} \mathcal{L} \\
\dfrac {\partial}{\partial w_{1}} \mathcal{L} \\
\vdots  \\
\dfrac {\partial}{\partial w_{M}} \mathcal{L} \\
\end{bmatrix}&amp;=\begin{bmatrix}
0 \\
0 \\
\vdots  \\
0 \\
\end{bmatrix} \\
\Rightarrow \dfrac {\partial}{\partial \boldsymbol{w}} \mathcal{L} &amp;= \boldsymbol{0} \\
\end{aligned}\end{split}\]</div>
<p>It is expressed as a derivative of a vector like. After that, to satisfy the above equation <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> We will decide First of allğ‘¤Perform substitution and formula transformation to make it easier to find. (Because the following calculations use the contents learned through linear algebra, including differentiation with vectors, so if you do not know the middle of the calculation, please proceed while checking the parts of linear algebra. )</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial \boldsymbol{w}}\mathcal{L} =\dfrac {\partial }{\partial \boldsymbol{w}}\left( \gamma + \boldsymbol{\beta}^{T}\boldsymbol{w} + \boldsymbol{w}^{T}\boldsymbol{A}\boldsymbol{w}\right)
= \boldsymbol{0}\\
\dfrac {\partial }{\partial \boldsymbol{w}}\left( \gamma\right) +\dfrac {\partial }{\partial \boldsymbol{w}}\left( \boldsymbol{\beta}^{T}\boldsymbol{w}\right) +\dfrac {\partial }{\partial \boldsymbol{w}}\left( \boldsymbol{w}^{T}\boldsymbol{A}\boldsymbol{w}\right)
=\boldsymbol{0}\\
\boldsymbol{0}+\boldsymbol{\beta}+\left( \boldsymbol{A}+\boldsymbol{A}^{T}\right) \boldsymbol{w} =\boldsymbol{0}\\
-2\boldsymbol{X}^{T}\boldsymbol{t}+\left\{ \boldsymbol{X}^{T}\boldsymbol{X} + \left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{T}\right\} \boldsymbol{w}
=\boldsymbol{0}\\
-2\boldsymbol{X}^{T}\boldsymbol{t}+2\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}=\boldsymbol{0}\\
\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}=\boldsymbol{X}^{T}\boldsymbol{t}\\
\end{aligned}\end{split}\]</div>
<p>here,<span class="math notranslate nohighlight">\(\boldsymbol{X}^{T} \boldsymbol{X}\)</span> From the left side on both sides, assuming that the inverse matrix exists in <span class="math notranslate nohighlight">\(\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\)</span> If you</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{X} \boldsymbol{w} =\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t} \\
\boldsymbol{I}\boldsymbol{w}=\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t} \\
\boldsymbol{w}=\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t}
\end{aligned}\end{split}\]</div>
<p>And the given data set <span class="math notranslate nohighlight">\(\boldsymbol{X}, \boldsymbol{t}\)</span> From the optimum parameters <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Was asked. here, <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> Is the identity matrix. Also, at the time of equation transformation,</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{w} = \dfrac{\boldsymbol{X}^{T}\boldsymbol{t}}{\boldsymbol{X}^{T}\boldsymbol{X}}\]</div>
<p>Be careful not to show fractions like. This is because there is no division in matrix calculations. Therefore, it is calculated only by matrix multiplication using inverse matrix.</p>
<p>Also, as another common mistake,<span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Here is an example that transforms the equation to find.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}&amp;=\boldsymbol{X}^{T}\boldsymbol{t}\\
\left( \boldsymbol{X}^{T}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{w}&amp;=\left( \boldsymbol{X}^{T}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t}\\
\boldsymbol{X}\boldsymbol{w}&amp;=\boldsymbol{t}\\
\boldsymbol{X}^{-1}\boldsymbol{X}\boldsymbol{w}&amp;=\boldsymbol{X}^{-1}\boldsymbol{t}\\
\boldsymbol{w}&amp;=\boldsymbol{X}^{-1}\boldsymbol{t}
\end{aligned}\end{split}\]</div>
<p>However, this generally does not hold. The reason is that the square matrix is not satisfied as a condition to have the inverse matrix . Generally, the number of samples <span class="math notranslate nohighlight">\(N\)</span> And the number of input variables <span class="math notranslate nohighlight">\(M+1\)</span> Are not equal,<span class="math notranslate nohighlight">\(\boldsymbol{X} \in \mathcal{R}^{N \times (M+1)}\)</span>)Is not square and has no inverse. For it, <span class="math notranslate nohighlight">\(\boldsymbol{X}^{T} \boldsymbol{X}\)</span> Is <span class="math notranslate nohighlight">\(\boldsymbol{X}^{T} \boldsymbol{X}\)</span> ã¯
<span class="math notranslate nohighlight">\(\boldsymbol{X}^{T}\boldsymbol{X} \in \mathcal{R}^{(M+1) \times (M+1)}\)</span>) And the number of samples <span class="math notranslate nohighlight">\(N\)</span> It is always square matrix without depending on. (There are more strict conditions for finding the inverse matrix, but I will not explain it here.)</p>
<p>Parameters derived from learning during inference <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Using,</p>
<div class="math notranslate nohighlight">
\[y_{q} = \boldsymbol{w}^{T}\boldsymbol{x}_{q}\]</div>
<p>You can get the predicted value by calculating as follows.</p>
</div>
</div>
<div class="section" id="Implementation-by-Numpy">
<h2>2.3. Implementation by Numpy<a class="headerlink" href="#Implementation-by-Numpy" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s use Python to implement linear algebra, using multiple regression analysis as an example. Python has a library called <strong>NumPy</strong> that can easily handle linear algebra and is widely used. NumPy is frequently used among the Chainers introduced in the next chapter, and it is important to learn how to use NumPy as a first step to learning deep learning.</p>
<p>It is assumed that you know the syntax of Python. Specifically, you need to understand variables (numbers, strings, lists, tuples, dictionaries), control syntax (for, if), functions, and classes.</p>
<p>In the multiple regression analysis, finally the optimal parameters <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> But</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{w}=\left( \boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t}\]</div>
<p>It turned out that it is represented by. We will deal with the following five to calculate this optimal parameter.</p>
<ul class="simple">
<li>Definition of vector</li>
<li>Matrix definition</li>
<li>Transposition</li>
<li>Matrix product</li>
<li>Inverse matrix</li>
</ul>
<p>Specifically, letâ€™s assume the case where the following data set is given. In this example, the number of data samples <span class="math notranslate nohighlight">\(N\)</span> Is <span class="math notranslate nohighlight">\(4\)</span> And the input data <span class="math notranslate nohighlight">\(X\)</span> The number of variables of <span class="math notranslate nohighlight">\(2\)</span> is. And <span class="math notranslate nohighlight">\(t\)</span> Is teacher data.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{X} =
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
1 &amp; 2 &amp; 5 \\
1 &amp; 3 &amp; 4 \\
1 &amp; 5 &amp; 9
\end{bmatrix}, \
\boldsymbol{t} =
\begin{bmatrix}
1 \\ 5 \\ 6 \\ 8
\end{bmatrix}\end{split}\]</div>
<p>here <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> Is the parameter <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Is biased ğ‘ Assumes a form that includesğ‘‹In the first column of1Is stored.</p>
<p>Letâ€™s look at the implementation method. First we will start by reading NumPy.</p>
<p>here <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> Is the parameter <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Is biased <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> Assumes a form that includes <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> In the first column of <span class="math notranslate nohighlight">\(1\)</span> Is stored.</p>
<p>Letâ€™s look at the implementation method. First we will start by reading NumPy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
<p>The definition of the vector is as follows.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Letâ€™s display the vector.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[1 5 6 8]
</pre></div></div>
</div>
<p>Letâ€™s define the matrix and display it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 2 3]
 [1 2 5]
 [1 3 4]
 [1 5 9]]
</pre></div></div>
</div>
<p>Here we use <code class="docutils literal notranslate"><span class="pre">np.array</span></code> the function to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>convert from a Python list to the NumPy multidimensional array form ( ).</p>
<p>Next, letâ€™s transpose X. <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>If it is defined in <code class="docutils literal notranslate"><span class="pre">.T</span></code>, you can transpose just by putting it on.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 1 1 1]
 [2 2 3 5]
 [3 5 4 9]]
</pre></div></div>
</div>
<p>You can see that the vertical and horizontal are switched.</p>
<p>Matrix multiplication <code class="docutils literal notranslate"><span class="pre">np.dot</span></code>can be realized as follows. When doing matrix multiplication, be aware that the number of columns in the first matrix is the same as the number of rows in the second matrix.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[  4  12  21]
 [ 12  42  73]
 [ 21  73 131]]
</pre></div></div>
</div>
<p>Further from here,<span class="math notranslate nohighlight">\(\boldsymbol{X}^{T}\boldsymbol{X}\)</span> Inverse matrix for,<span class="math notranslate nohighlight">\(\left(\boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\)</span>Calculate. Use to get the inverse matrix <code class="docutils literal notranslate"><span class="pre">np.linalg.inv</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">XX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">XX_inv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[ 1.76530612 -0.39795918 -0.06122449]
 [-0.39795918  0.84693878 -0.40816327]
 [-0.06122449 -0.40816327  0.24489796]]
</pre></div></div>
</div>
<p>You now have the necessary operations for multiple regression analysis.</p>
<p>Optimal parameter<span class="math notranslate nohighlight">\(\left(\boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{t}\)</span> If you ask for</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[ 20  70 124]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">XX_inv</span><span class="p">,</span> <span class="n">Xt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[-0.14285714  0.71428571  0.57142857]
</pre></div></div>
</div>
<p>Parameters like this <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> Was asked. By using NumPy, you can write mathematical expressions as they are on a program.</p>
</div>
<div class="section" id="Scikit-learn-the-execution-of-the-machine-learning-algorithm-by">
<h2>2.4. Scikit-learn the execution of the machine learning algorithm by<a class="headerlink" href="#Scikit-learn-the-execution-of-the-machine-learning-algorithm-by" title="Permalink to this headline">Â¶</a></h2>
<p>Multiple regression analysis was relatively easy to implement with NumPy, but many of the practical machine learning algorithms are complex and often difficult for beginners to write from scratch. Therefore, a framework for machine learning called <strong>Scikit-learn</strong> is disclosed in Python, and even <strong>beginners</strong> can easily handle various machine learning algorithms.</p>
<p>Here, we will introduce <strong>the implementation method</strong> of multiple regression analysis <strong>using Scikit-learn</strong> . The data set is the same as before <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> when <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> In Scikit-learn, <strong>parameters</strong> are used. <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> <strong>Is biased</strong> <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> <strong>Assumes a</strong> format that <strong>does not include</strong> <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> From the first column of1It is common to remove Therefore,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{X} =
\begin{bmatrix}
2 &amp; 3 \\
2 &amp; 5 \\
3 &amp; 4 \\
5 &amp; 9
\end{bmatrix}, \
\boldsymbol{t} =
\begin{bmatrix}
1 \\ 5 \\ 6 \\ 8
\end{bmatrix}\end{split}\]</div>
<p>Suppose that is given.</p>
<div class="section" id="Scikit-learn-åŸºç¤ç·¨">
<h3>2.4.1. Scikit-learn åŸºç¤ç·¨<a class="headerlink" href="#Scikit-learn-åŸºç¤ç·¨" title="Permalink to this headline">Â¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> You can call Scikit-learn with the name:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sklearn</span>
</pre></div>
</div>
</div>
<p>When using multiple regression analysis, call as follows.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</pre></div>
</div>
</div>
<p>In addition to the <a class="reference external" href="http://scikit-learn.org/">official reference</a>, it is also useful to look at the actual code example when investigating how to use (For example, if you search using a keyword such as â€œmultiple regression analysis Scikit-learnâ€ in a search engine, many codes An example is found).</p>
<p>The algorithm of multiple regression analysis is defined as a class, and it needs to be instantiated to use the actual model. Instantiation <code class="docutils literal notranslate"><span class="pre">()</span></code> can be done by appending the class name .</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Thatâ€™s it, you are ready to use multiple regression analysis. Using this model, learning of parameters is performed as follows.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</pre></div>
</div>
</div>
<p>The verification of the result is performed as follows.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.6923076923076923
</pre></div>
</div>
</div>
<p>In the case of regression, an index called the <strong>coefficient of determination</strong>, which is expressed by the following equation, is automatically calculated.</p>
<div class="math notranslate nohighlight">
\[R^{2} = 1 - \dfrac{\sum_{i}\left( t_{i} - y_{i} \right)^{2}}{\sum_{i}\left( t_{i} - \bar{t} \right)^{2}}\]</div>
<p>In this way, Scikit-learn allows you to communicate with a simple interface. The good point of Scikit-learn is that any algorithm can be verified <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> by learning, once the algorithm is decided first <code class="docutils literal notranslate"><span class="pre">.score()</span></code>.</p>
<p>Also, although the contents differ depending on the algorithm, the parameters are also stored as instance variables, so they can be checked after learning.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿w</span>
<span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.71428571, 0.57142857])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ãƒã‚¤ã‚¢ã‚¹b</span>
<span class="n">model</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>-0.14285714285714501
</pre></div>
</div>
</div>
</div>
<div class="section" id="Scikit-learn-Applied">
<h3>2.4.2. Scikit-learn Applied<a class="headerlink" href="#Scikit-learn-Applied" title="Permalink to this headline">Â¶</a></h3>
<p>Scikit-learn has many features to help implement machine learning. This section introduces how to use sample data sets and how to divide them.</p>
<div class="section" id="The-use-of-sample-data-set">
<h4>2.4.2.1. The use of sample data set<a class="headerlink" href="#The-use-of-sample-data-set" title="Permalink to this headline">Â¶</a></h4>
<p>First we will introduce the handling of sample data sets. Several data sets are provided in Scikit-learn. This time, I will use the data set of property prices by region in the suburbs of Boston, USA.</p>
<p>In this data set <span class="math notranslate nohighlight">\(506\)</span> Data is registered, and the average property price of the target area in each sample and the average property information of the target area as information linked to it (the number of rooms per unit, age, distance from the employment facility, etc. This includes demographic information (proportion of low-income earners, number of students per teacher, etc.), information on living environment (such as crime incidence), etc. The purpose of using this data set is to
build a model that predicts the average property price, which is an output variable, using information such as property and demographics as an input variable. There are 13 kinds of input variables in total, and the details are as follows.</p>
<ul class="simple">
<li>CRIM: Population1Per capita crime rate</li>
<li>ZN: 25,000Percentage of residential areas over square feet</li>
<li>INDUS: Percentage of area occupied by non-retail industry</li>
<li>CHAS: Dummy variables on the Charles River (1: Along the river, 0: otherwise)</li>
<li>NOX: concentration of nitrogen oxides</li>
<li>RM: Average number of rooms per residence</li>
<li>AGE: Percentage of properties built before 1940</li>
<li>DIS: Weighted distance from five Boston employment facilities</li>
<li>RAD: Access Index to Urban Main Roads</li>
<li>TAX: $ $10,000Property tax rate per</li>
<li>PTRATIO: Number of students per teacher</li>
<li>B: Index that represents the proportion of blacks</li>
<li>LSTAT: Percentage of low-income people</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">load_boston()</span></code> Letâ€™s execute the function and read the data set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Variables are <code class="docutils literal notranslate"><span class="pre">boston</span></code>stored in dictionary form, and while looking at the contents of variables, we will find the ones corresponding to the input data and the output data. This time is the <code class="docutils literal notranslate"><span class="pre">data</span></code> input, and <code class="docutils literal notranslate"><span class="pre">target</span></code>corresponds to the output.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]
 [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]
 [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]
 ...
 [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]
 [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]
 [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4
 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8
 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6
 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4
 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9
 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9
 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7
 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8
 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4
 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8
 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4
 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8
 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2
 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.
 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.
 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1
 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5
 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8
 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8
 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1
 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9
 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2
 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1
 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1
 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6
 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8
 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3
 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2
  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.
 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4
 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3
 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6
 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7
 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3
 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.
  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9
 22.  11.9]
</pre></div></div>
</div>
<p>Input data and teacher data are stored in the form of NumPy, <code class="docutils literal notranslate"><span class="pre">.shape</span></code> and you can check the number of rows and columns by using.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(506, 13)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">t</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(506,)
</pre></div>
</div>
</div>
<p>Array of input data <span class="math notranslate nohighlight">\(X\)</span> To <span class="math notranslate nohighlight">\(506\)</span> Data for the case is stored. Each sample is <span class="math notranslate nohighlight">\(13\)</span> Expressed as a dimensional vector, each of which is <span class="math notranslate nohighlight">\(13\)</span> Represents a kind of input variable. Teacher data <span class="math notranslate nohighlight">\(t\)</span> The scalar value of the average property price is stored as the output variable corresponding to the input variable in.</p>
</div>
<div class="section" id="2.4.2.2.-Of-the-data-set-division">
<h4>2.4.2.2. 2.4.2.2. Of the data set division<a class="headerlink" href="#2.4.2.2.-Of-the-data-set-division" title="Permalink to this headline">Â¶</a></h4>
<p>Next, I will introduce how to divide this learning data into <strong>training data</strong> and <strong>test data</strong> . If the performance of the model is evaluated using the data used at the time of learning, even if the performance of the learning data is high, the unknown data (taken from the same distribution) has not been seen during learning. There is a case. This <strong>over-learning</strong> is called. In order to prevent this, machine learning separates and evaluates test data for evaluating performance separately from
learning data. This separation and verification is called <strong>holdout method</strong>.</p>
<p>Scikit-learn provides functions to divide training and testing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(354, 13)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(152, 13)
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">train_test_split()</span></code> The argument <code class="docutils literal notranslate"><span class="pre">test_size</span></code> of the function is the ratio of data used for verification,<span class="math notranslate nohighlight">\(0.3\)</span> And the entire <span class="math notranslate nohighlight">\(30\)</span>% Is the test data. Also, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is a random number seed, and given a fixed seed value, you can ensure the repeatability of the division. Why do random numbers appear? <span class="math notranslate nohighlight">\(70\)</span>% Randomly selected from the whole, not for training and the rest for testing <span class="math notranslate nohighlight">\(70\)</span>% For training, the rest <span class="math notranslate nohighlight">\(30\)</span>% This is because% is selected
for testing.</p>
<p>Then, learning is performed using training data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</pre></div>
</div>
</div>
<p>If you do verification, it is better to check both training data and test data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># è¨“ç·´ãƒ‡ãƒ¼ã‚¿</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.7644563391821222
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.673528086534723
</pre></div>
</div>
</div>
<p>By examining not only test data but also training data, you can isolate problems when learning fails.</p>
<p><strong>Underfitting</strong> is a condition in which the model can not predict the training data with good accuracy . If underfitting is occurring, it is considered that the current machine learning algorithm does not capture the features of the data well, and change the algorithm or think of a transformation that can represent the features of the input data more appropriately I will try to improve it. Conversely, in the case of <strong>overfitting (overlearning)</strong> , it is confirmed that the features of the data
are captured to some extent by the algorithm, so we will take measures to prevent the model from overlearning. As a typical method, it can be solved by adjusting the parameter value used for parameter learning of each algorithm called <strong>hyper parameter</strong> . Thus, even if the desired results are not obtained, it is important to verify both the training data and the test data, because the measures to be taken next will change as the situation is grasped. I understand.</p>
<p>You can also do scaling with Scikit-learn. For example, the procedure to perform data normalization to convert to mean 0, standard deviation 1 is as follows.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Calculate mean and variance using training data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># å¹³å‡ã¨åˆ†æ•£ã‚’è¨ˆç®—</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>StandardScaler(copy=True, with_mean=True, with_std=True)
</pre></div>
</div>
</div>
<p>Scale training data and test data using the calculated mean and variance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># å¤‰æ›</span>
<span class="n">X_train_s</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_s</span>  <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note that we also use the mean and variance of training data when scaling test data. Since test data is an unknown data set for a model, using the average and variance of all the data combining training data and test data will give information to the model of test data that can not be originally known. I will. Therefore, scaling is performed using only training data for which models are available.</p>
<p>Since the mean and variance of training data and test data are different, the average of test data scaled by the mean and variance of training data is the average0, Variance1Please note that it does not necessarily become.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">X_train_s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[-0.20416267 -0.49997924  1.54801583 ...  1.2272573   0.42454294
   3.10807269]
 [-0.38584317  0.34677427 -0.58974728 ...  0.05696346  0.40185312
  -0.66643035]
 [-0.33266283 -0.49997924  1.54801583 ...  1.2272573   0.39846135
   0.63936662]
 ...
 [-0.38147768 -0.49997924 -0.15303077 ... -0.30312696  0.39659002
  -0.30284441]
 [-0.3720831  -0.49997924 -0.59690657 ... -0.25811566  0.37588849
   0.89967717]
 [-0.38289844 -0.49997924 -1.00641779 ... -0.84326258  0.42454294
   0.31822262]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="n">X_test_s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[-0.39152624 -0.49997924 -1.12239824 ... -0.70822867  0.17086147
  -0.72160487]
 [ 0.70825498 -0.49997924  1.00534187 ...  0.77714428  0.0648977
  -0.41177872]
 [-0.38588517 -0.49997924  0.4025299  ... -0.93328518  0.38758427
  -0.27454978]
 ...
 [ 1.6177735  -0.49997924  1.00534187 ...  0.77714428  0.42454294
   2.59876943]
 [-0.34043865 -0.49997924 -0.1687812  ... -0.03305915  0.42454294
  -1.11772962]
 [-0.39601293 -0.49997924 -1.27417512 ...  0.10197476  0.39202867
  -1.02294263]]
</pre></div></div>
</div>
<p>In addition, Scikit-learn supports various machine learning algorithms such as logistic regression, support vector machines, and random forests.</p>
<p>For these as well, as with multiple regression analysis, a model is instantiated, and learning data is used as an argument for .<code class="docutils literal notranslate"><span class="pre">.fit()</span></code> training with a <code class="docutils literal notranslate"><span class="pre">.score()</span></code> function, and can be evaluated using a function.</p>
<p>Please refer to <a class="reference external" href="https://scikit-learn.org/">Scikit-learn</a> site and commentary site etc. for more detailed information.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Introduction_to_Neural_Network.html" class="btn btn-neutral float-right" title="3. Basics of neural network" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Basic_Math_for_ML.html" class="btn btn-neutral" title="1. Basis of the mathematics required to machine learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Preferred Networks &amp; ã‚­ã‚«ã‚¬ã‚¯

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>