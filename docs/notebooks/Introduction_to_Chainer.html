

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4. Introduction to Deep Learning Framework &mdash; メディカルAI専門コース オンライン講義資料  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Practice: Segmentation of MRI" href="Image_Segmentation.html" />
    <link rel="prev" title="3. Basics of neural network" href="Introduction_to_Neural_Network.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-797798-11"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-797798-11');
  </script>

  <meta name="description" content="メディカルAI学会公認資格向けオンライン講義資料。機械学習に必要な数学の基礎の解説から深層学習（ディープラーニング）を用いた実践的な内容までGoogle Colaboratory上でGPUを用いて実際にコードを実行可能な形式にしオンライン資料として無料公開。">
  <meta property="og:title" content="メディカルAI専門コース オンライン講義資料">
  <meta property="og:description" content="メディカルAI学会公認資格向けオンライン講義資料。機械学習に必要な数学の基礎の解説から深層学習（ディープラーニング）を用いた実践的な内容までGoogle Colaboratory上でGPUを用いて実際にコードを実行可能な形式にしオンライン資料として無料公開。">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://japan-medical-ai.github.io/medical-ai-course-materials/">
  <meta property="og:image" content="https://raw.githubusercontent.com/japan-medical-ai/medical-ai-course-materials/master/notebooks/images/medical_ai.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@PreferredNetJP">
  <meta name="twitter:creator" content="@PreferredNetJP">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> メディカルAI専門コース オンライン講義資料
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Basic_Math_for_ML.html">1. Basis of the mathematics required to machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_ML_libs.html">2. Basics of machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Neural_Network.html">3. Basics of neural network</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. Introduction to Deep Learning Framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Preparing-Environment">4.1. Preparing Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Basic-Usage-of-Chainer">4.2. Basic Usage of Chainer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Preparing-Dataset">4.2.1. Preparing Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Create-a-Dataset-for-Validation">4.2.2. Create a Dataset for Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-Iterator">4.2.3. Creating Iterator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#About-SerialIterator">4.2.3.1. About SerialIterator</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Defining-Network">4.2.4. Defining Network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Link-and-Function">4.2.4.1. Link and Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Chain">4.2.4.2. Chain</a></li>
<li class="toctree-l4"><a class="reference internal" href="#To-guarantee-the-same-result">4.2.4.3. To guarantee the same result</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Defining-network-inherted-from-Chain">4.2.4.4. Defining network inherted from Chain</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Running-on-GPU">4.2.4.5. Running on GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Calculation-of-the-number-of-input-side-units">4.2.4.6. Calculation of the number of input side units</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Selection-of-Optimizers">4.2.5. Selection of Optimizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Learning-Rate">4.2.5.1. Learning Rate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Start-Training">4.2.6. Start Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Objective-Function">4.2.6.1. Objective Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#The-Code-of-the-Traning-Loop">4.2.6.2. The Code of the Traning Loop</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Note-on-Validation-and-Testing">4.2.6.3. Note on Validation and Testing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Saving-Trained-Model">4.2.7. Saving Trained Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Perform-inference-after-loading-the-saved-model">4.2.8. Perform inference after loading the saved model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#How-to-use-Trainer">4.3. How to use Trainer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Pareparing-Dataset,-Iterator-and-Network">4.3.1. Pareparing Dataset, Iterator and Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Preparation-of-Updater">4.3.2. Preparation of Updater</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Chain-for-the-loss-calculation">4.3.2.1. Chain for the loss calculation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Preparation-of-Trainer">4.3.3. Preparation of Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Add-Extension-to-Trainer">4.3.4. Add Extension to Trainer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#LogReport">4.3.4.1. <code class="docutils literal notranslate"><span class="pre">LogReport</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#snapshot">4.3.4.2. <code class="docutils literal notranslate"><span class="pre">snapshot</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dump_graph">4.3.4.3. <code class="docutils literal notranslate"><span class="pre">dump_graph</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#Evaluator">4.3.4.4. <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#PrintReport">4.3.4.5. <code class="docutils literal notranslate"><span class="pre">PrintReport</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#PlotReport">4.3.4.6. <code class="docutils literal notranslate"><span class="pre">PlotReport</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ParameterStatistics">4.3.4.7. <code class="docutils literal notranslate"><span class="pre">ParameterStatistics</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Start-of-Training-(using-Trainer)">4.3.5. Start of Training (using Trainer)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Test-data-evaluation">4.3.6. Test data evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Infer-with-trained-model">4.3.7. Infer with trained model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Use-of-new-network">4.4. Use of new network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Defining-new-network">4.4.1. Defining new network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training">4.4.2. Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Prediction-using-the-trained-network">4.4.3. Prediction using the trained network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Defining-deep-network">4.4.4. Defining deep network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Defining-the-components">4.4.4.1. Defining the components</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Defining-large-network">4.4.4.2. Defining large network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Tips-for-speeding-up">4.4.4.3. Tips for speeding up</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Using-Dataset-Class">4.5. Using Dataset Class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#CIFAR10-Dataset-Class">4.5.1. CIFAR10 Dataset Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training-using-created-dataset">4.5.2. Training using created dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Simple-way-to-use-Data-Augmentation">4.6. Simple way to use Data Augmentation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Conversion-Processing-utilizing-ChainerCV">4.6.1. Conversion Processing utilizing ChainerCV</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#References">4.7. References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Image_Segmentation.html">5. Practice: Segmentation of MRI</a></li>
<li class="toctree-l1"><a class="reference internal" href="Blood_Cell_Detection.html">6. Practice section: Detection of cells from microscope images of blood</a></li>
<li class="toctree-l1"><a class="reference internal" href="DNA_Sequence_Data_Analysis.html">7. Practical part: sequence analysis using deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html">8. Practical part: Time series analysis of monitoring data using the deep learning</a></li>
</ul>

            
          
          <div style="padding-right:20px; bottom:10px;">
            <a href="https://short-term.kikagaku.co.jp/dnn-seminar/">
              <img src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/img_handson.png" />
              <p style="padding:5px; font-size:small; line-height: 150%">ディープラーニングの詳しい解説や画像・自然言語の取り扱い、クラウド上のGPUを使った実践的な演習をご希望の方はこちらがおすすめです</p>
            </a>
          </div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">メディカルAI専門コース オンライン講義資料</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>4. Introduction to Deep Learning Framework</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Introduction_to_Chainer.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p><a class="reference external" href="https://colab.research.google.com/github/preferred-medicine/medical-ai-course-materials/blob/master/notebooks/Introduction_to_Chainer.ipynb"><img alt="colab-logo" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="Introduction-to-Deep-Learning-Framework">
<h1>4. Introduction to Deep Learning Framework<a class="headerlink" href="#Introduction-to-Deep-Learning-Framework" title="Permalink to this headline">¶</a></h1>
<p>Chainer is a deep learning framework which uses the methodology called <strong>Define-by-Run</strong> among popular deep learning frameworks for the first time. Preferred Networks, Inc. has been developing Chainer since 2015. Define-by-Run is a way to define structure of a neural network by using a code that performs calculations inside the neural network, which has been adopted widely by other popular deep learning frameworks, such as TensorFlow and PyTorch. The other way is to define the neural network
structure before the training which requires us to add a code to take data necessary for training as input. Such approach is known as Define-and-Run. Since Define-by-Run enables definition of the neural network structure at run-time, it makes it easy to write a dynamic neural network. Int this section, we will explain the fundamental usage of this framework called Chainer which is characterized by its <strong>flexibility</strong> and <strong>intuitiveness</strong>.</p>
<div class="section" id="Preparing-Environment">
<h2>4.1. Preparing Environment<a class="headerlink" href="#Preparing-Environment" title="Permalink to this headline">¶</a></h2>
<p>Let’s run the following cell on Colab and install the latest version of Chainer. Here we install a software called <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> at the same time, which will later be used to visualize the graph structure of neural network architecture.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>curl https://colab.chainer.org/install <span class="p">|</span> sh -
<span class="o">!</span>apt-get install -y graphviz
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1580  100  1580    0     0   6774      0 --:--:-- --:--:-- --:--:--  6752
sh: line 9: nvidia-smi: command not found
********************************************************************************
GPU is not enabled!
Open &#34;Runtime&#34; &gt; &#34;Change runtime type&#34; and set &#34;Hardware accelerator&#34; to &#34;GPU&#34;.
********************************************************************************
/bin/sh: apt-get: command not found
</pre></div></div>
</div>
<p>Now, run the following command in the terminal to check if a package called CuPy, which is necessary to use GPU with Chainer, has been installed correctly.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>python -c <span class="s1">&#39;import chainer; chainer.print_runtime_info()&#39;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
/Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages/chainer/_environment_check.py:37: UserWarning: Accelerate has been detected as a NumPy backend library.
vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.
We recommend using other BLAS libraries such as OpenBLAS.
For details of the issue, please see
https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.

Please be aware that Mac OS X is not an officially supported OS.

  &#39;&#39;&#39;)  # NOQA
Platform: Darwin-17.7.0-x86_64-i386-64bit
Chainer: 5.1.0
NumPy: 1.15.4
CuPy: Not Available
iDeep: Not Available
</pre></div></div>
</div>
<p>There are items such as Chainer, Numpy and CuPy, and also CUDA, cuDNN and NCCL under CuPy. If version numbers are displayed, it is successful. In the following tutorial, we will use matplotlib for visualizing the graph, so let’s install it at the same time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install matplotlib
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-yellow-fg">DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won&#39;t be maintained after that date. A future version of pip will drop support for Python 2.7.</span>
Requirement already satisfied: matplotlib in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (2.2.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (1.0.1)
Requirement already satisfied: cycler&gt;=0.10 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (0.10.0)
Requirement already satisfied: subprocess32 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (3.5.3)
Requirement already satisfied: pytz in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (2018.7)
Requirement already satisfied: six&gt;=1.10 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (1.11.0)
Requirement already satisfied: backports.functools-lru-cache in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (1.5)
Requirement already satisfied: numpy&gt;=1.7.1 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (1.15.4)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (2.3.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from matplotlib) (2.7.5)
Requirement already satisfied: setuptools in /Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib) (40.6.3)
<span class="ansi-yellow-fg">You are using pip version 19.0.3, however version 19.1 is available.
You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span>
</pre></div></div>
</div>
</div>
<div class="section" id="Basic-Usage-of-Chainer">
<h2>4.2. Basic Usage of Chainer<a class="headerlink" href="#Basic-Usage-of-Chainer" title="Permalink to this headline">¶</a></h2>
<p>First, we will explain the basic usage of Chainer by working on simple tasks. Let’s write a network that classifies images into one of 10 classes (0 - 9 of numbers) using the well-known handwritten numerical data set MNIST.</p>
<div class="section" id="Preparing-Dataset">
<h3>4.2.1. Preparing Dataset<a class="headerlink" href="#Preparing-Dataset" title="Permalink to this headline">¶</a></h3>
<p>First we prepare the dataset used for training . In supervised learning, the dataset must be an object that returns a pair of “input data” and “corresponding label data”. Chainer has a convenient method that automatically performs from data downloading to object creation for commonly used data sets such as MNIST and CIFAR 10/100. Let’s use this method for the moment.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>

<span class="c1"># If datasets have not been downloaded yet, dowonload them</span>
<span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">get_mnist</span><span class="p">(</span><span class="n">withlabel</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/sandeepayyar/Documents/.env/lib/python2.7/site-packages/chainer/_environment_check.py:37: UserWarning: Accelerate has been detected as a NumPy backend library.
vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.
We recommend using other BLAS libraries such as OpenBLAS.
For details of the issue, please see
https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.

Please be aware that Mac OS X is not an officially supported OS.

  &#39;&#39;&#39;)  # NOQA
</pre></div></div>
</div>
<p>The data set object is ready. When you specify this object like <code class="docutils literal notranslate"><span class="pre">train_val[i]</span></code>, think of it as a list that returns the i th (data, label) tuple . (In fact, just a Python list is also available as Chainer’s dataset object). Let’s retrieve the 0th data and label and display it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Configure it so that results using matplotlib will be rendered inside the notebook.</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># Illustration of data</span>
<span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">train_val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Extract (data, label) from 0&#39;th data point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;label:&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_11_0.png" src="../_images/notebooks_Introduction_to_Chainer_11_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;label:&#39;, 5)
</pre></div></div>
</div>
</div>
<div class="section" id="Create-a-Dataset-for-Validation">
<h3>4.2.2. Create a Dataset for Validation<a class="headerlink" href="#Create-a-Dataset-for-Validation" title="Permalink to this headline">¶</a></h3>
<p>Next, we divide the dataset <code class="docutils literal notranslate"><span class="pre">train_val</span></code> we created earlier into dataset for training and dataset for validation. Validation dataset is a dataset for verification, not used for training but used for checking the generalization performance of the model, and for adjusting hyper parameters such as learning rate. The split processing can also be performed using functions provided by Chainer for dividing datasets. Let’s split the dataset that originally contains 60,000 data points into two randomly
selected 50,000 data points as <code class="docutils literal notranslate"><span class="pre">train</span></code> and the remaining 10,000 data points as <code class="docutils literal notranslate"><span class="pre">valid</span></code>. To do this, we use the function named <code class="docutils literal notranslate"><span class="pre">split_dataset_random</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer.datasets</span> <span class="kn">import</span> <span class="n">split_dataset_random</span>

<span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

</pre></div>
</div>
</div>
<p>The first argument of the function is the target dataset object to be divided, the second argument is the number of elements of the first dataset, and the third argument is a random number seed used for random extraction (this can be omitted). If you specify the same value as the third argument <code class="docutils literal notranslate"><span class="pre">seed</span></code>, the dataset will be split in the same way when re-executed. Let’s check the number of data contained in each dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training dataset size:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation dataset size:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;Training dataset size:&#39;, 50000)
(&#39;Validation dataset size:&#39;, 10000)
</pre></div></div>
</div>
</div>
<div class="section" id="Creating-Iterator">
<h3>4.2.3. Creating Iterator<a class="headerlink" href="#Creating-Iterator" title="Permalink to this headline">¶</a></h3>
<p>Next, we will introduce the function called Iterator which bundles several data points(input and label pairs) from the dataset object prepared earlier and passes it one after another to the training model. The Iterator function is required especially during the optimization method, such as stochastic gradient descent method (SGD) which updates the parameters of the neural network, and for calculations using <strong>mini batches</strong> that bundle some data. (Mini batch calculations are common during mini
batch gradient descent by calculating the average of the gradient to stabilize the parameter updates, and it is easy to parallelize using GPU etc.)</p>
<p><code class="docutils literal notranslate"><span class="pre">Iterator</span></code> specifies the data set object we created earlier as an argument and calls the method <code class="docutils literal notranslate"><span class="pre">next()</span></code> to return a new mini batch. When we finish using all the data in the dataset once for training, we call it <strong>an epoch</strong>. Inside Iterator, information such as how many epochs have been learned during training, etc. are sequentially recorded, which makes it easy to write code that runs the training loop by using data in the dataset several times.</p>
<p>Here’s how to create an interator from a dataset object.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer</span> <span class="kn">import</span> <span class="n">iterators</span>

<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">train_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">valid_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span>
    <span class="n">valid</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span>
    <span class="n">test</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We have now created a total of three iterators, <code class="docutils literal notranslate"><span class="pre">train_iter</span></code> for the training data set, <code class="docutils literal notranslate"><span class="pre">valid_iter</span></code> for the validation dataset, and <code class="docutils literal notranslate"><span class="pre">test_iter</span></code> for the test dataset used to evaluate the trained network. Since we set <code class="docutils literal notranslate"><span class="pre">batchsize</span></code> to 128, if the method <code class="docutils literal notranslate"><span class="pre">next()</span></code> is called as <code class="docutils literal notranslate"><span class="pre">train_iter.next()</span></code>, the three iterators created will return <strong>128 numeric image data</strong> in bundle. Let’s examine the actual return value of <code class="docutils literal notranslate"><span class="pre">next()</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">minibatch</span> <span class="o">=</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">minibatch</span></code> variable is a list of 128 tuples of <code class="docutils literal notranslate"><span class="pre">(img,</span> <span class="pre">label)</span></code> (with the size of mini batch). Let’s check if the length of this list is actually 128.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;batchsize:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">minibatch</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;batchsize:&#39;, 128)
</pre></div></div>
</div>
<p>Next, let’s read the first element of this list named as <code class="docutils literal notranslate"><span class="pre">minibatch</span></code> (it should be a tuple with images and labels) as <code class="docutils literal notranslate"><span class="pre">minibatch[0]</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">minibatch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;x:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;t:&#39;</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;x:&#39;, (784,))
(&#39;t:&#39;, ())
</pre></div></div>
</div>
<p>You can examine shapes of the two arrays, <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">t</span></code>, representing the return values at that time. They are stored as vectors of length 784 respectively, and correct label as being a scalar value. 784 comes from a set of 28×28 pixel values of square image data flattend in a row.</p>
<div class="section" id="About-SerialIterator">
<h4>4.2.3.1. About SerialIterator<a class="headerlink" href="#About-SerialIterator" title="Permalink to this headline">¶</a></h4>
<p>One of the iterators that is provided by Chainer is the <code class="docutils literal notranslate"><span class="pre">SerialIterator</span></code>, the simplest iterator that fetches the data in the dataset in order. It takes dataset object and batch size as an argument of <code class="docutils literal notranslate"><span class="pre">SerialIterator</span></code> constructor (method called at the time of instantiating class). At this time, if data needs to be repeatedly read out from the passed dataset object, set <code class="docutils literal notranslate"><span class="pre">repeat</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, and if it does not want to retrieve more data after one lap, set it to <code class="docutils literal notranslate"><span class="pre">False</span></code>. This is mainly used
for datasets during validation. By default, this option is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>. Also, if you pass <code class="docutils literal notranslate"><span class="pre">True</span></code> in an <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> argument, it randomly changes the order of data retrieved from the dataset for each epoch. In addition to <code class="docutils literal notranslate"><span class="pre">SerialIterator</span></code>, multiple iterators, such as <code class="docutils literal notranslate"><span class="pre">MultiprocessIterator</span></code> and <code class="docutils literal notranslate"><span class="pre">MultithreadIterator</span></code> that allow data to be processed at high speed with multiple processes, are provided. See the following link for more details.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.chainer.org/en/stable/reference/iterators.html">Iterators provided by Chainer</a></p></li>
</ul>
</div>
</div>
<div class="section" id="Defining-Network">
<h3>4.2.4. Defining Network<a class="headerlink" href="#Defining-Network" title="Permalink to this headline">¶</a></h3>
<p>Let’s define a network to be trained. In this example, we will create a neural network (multilayer perceptron) consisting of fully-connected layers. Let the number of units in the hidden layer be 100. Since the MNIST dataset has 10 types of labels indicating numbers from 0 to 9, the number of output units is 10.</p>
<p>Here is a brief description of <code class="docutils literal notranslate"><span class="pre">Link</span></code>, <code class="docutils literal notranslate"><span class="pre">Function</span></code> and <code class="docutils literal notranslate"><span class="pre">Chain</span></code> that are necessary to define a neural network.</p>
<div class="section" id="Link-and-Function">
<h4>4.2.4.1. Link and Function<a class="headerlink" href="#Link-and-Function" title="Permalink to this headline">¶</a></h4>
<p>Chainer distinguishes each layer of the neural network into <code class="docutils literal notranslate"><span class="pre">Link</span></code> and <code class="docutils literal notranslate"><span class="pre">Function</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Link</span></code> is a function which <strong>has parameters</strong>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Function</span></code> is a function which <strong>does not have parameters</strong>.</p></li>
</ul>
<p>We will combine these to describe the network. Layers with parameters are provided in the module <code class="docutils literal notranslate"><span class="pre">chainer.link</span></code>. For example, <code class="docutils literal notranslate"><span class="pre">chainer.links.Linear</span></code> corresponds to the fully-connected layer described in the previous chapter, <code class="docutils literal notranslate"><span class="pre">W</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>, that are trainable parameters, are stored inside it. Layers without parameters are provided in the module, <code class="docutils literal notranslate"><span class="pre">chainer.functions</span></code>. We typically import these modules to make it easy to access them as;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">chainer.links</span> <span class="k">as</span> <span class="nn">L</span>
<span class="kn">import</span> <span class="nn">chainer.functions</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
<p>We can then access <code class="docutils literal notranslate"><span class="pre">L.Convolution2D(...)</span></code> or <code class="docutils literal notranslate"><span class="pre">F.relu(...)</span></code>, just as a convention.</p>
</div>
<div class="section" id="Chain">
<h4>4.2.4.2. Chain<a class="headerlink" href="#Chain" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Chain</span></code> is <strong>a class for grouping layers with parameters (Link)</strong>. Having parameters basically means that you need to update them when you train the network (you can also have parameters that are not updated). In Chainer, the function called <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> takes a role of updating the parameters of the model. We will put together in one place using <code class="docutils literal notranslate"><span class="pre">Chain</span></code> so that we can easily find all the parameters to be updated .</p>
</div>
<div class="section" id="To-guarantee-the-same-result">
<h4>4.2.4.3. To guarantee the same result<a class="headerlink" href="#To-guarantee-the-same-result" title="Permalink to this headline">¶</a></h4>
<p>Fixing the random number seed at the beginning of writing the network makes it possible to reproduce almost the same result as this article. (If you want to more precisely guarantee the reproducibility of the calculation results in environments where cuDNN is enabled, you need to know about the configuring option <code class="docutils literal notranslate"><span class="pre">chainer.config.cudnn_deterministic</span></code>. Please refer this document for more details:
<a class="reference external" href="https://docs.chainer.org/en/stable/reference/configuration.html?highlight=chainer.config.cudnn_deterministic">chainer.config.cudnn_deterministic</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">chainer</span>

<span class="k">def</span> <span class="nf">reset_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">chainer</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">available</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">cupy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Defining-network-inherted-from-Chain">
<h4>4.2.4.4. Defining network inherted from Chain<a class="headerlink" href="#Defining-network-inherted-from-Chain" title="Permalink to this headline">¶</a></h4>
<p>In Chainer, networks are generally defined as classes that inherit <code class="docutils literal notranslate"><span class="pre">Chain</span></code> class. By inheriting <code class="docutils literal notranslate"><span class="pre">Chain</span></code>, the three-layer multilayer perceptron, or MLP, with number of units in the hiddlen layer = 100 and number of output units = 10 can be written as follows.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">chainer</span>
<span class="kn">import</span> <span class="nn">chainer.links</span> <span class="kn">as</span> <span class="nn">L</span>
<span class="kn">import</span> <span class="nn">chainer.functions</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">Chain</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_mid_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Set up layers that have parameters</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_mid_units</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_mid_units</span><span class="p">,</span> <span class="n">n_mid_units</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l3</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_mid_units</span><span class="p">,</span> <span class="n">n_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Write forward calculation when data is received</span>
        <span class="n">h1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">h2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">h1</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l3</span><span class="p">(</span><span class="n">h2</span><span class="p">)</span>

<span class="n">gpu_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Set this value to -1 when using CPU</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>

<span class="k">if</span> <span class="n">gpu_id</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">gpu_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">self.init_scope()</span></code> is called in the constructor of the class inherited from <code class="docutils literal notranslate"><span class="pre">MLP</span></code>, and in that the <code class="docutils literal notranslate"><span class="pre">Link</span></code> (more specifically, the fully-connected layer, <code class="docutils literal notranslate"><span class="pre">L.Linear</span></code>) which appears in the network is defined. By describing the network in this way, <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> automatically interprets that these are layers with parameters to be optimized.</p>
<p>Also, as indicated by the name of the function <code class="docutils literal notranslate"><span class="pre">forward</span></code>, it describes the forward propagation of the network. By taking <code class="docutils literal notranslate"><span class="pre">x</span></code> as an argument for <code class="docutils literal notranslate"><span class="pre">forward</span></code>, and returning the result of forward propagation as output, it becomes possible to use an object created by instantiating the <code class="docutils literal notranslate"><span class="pre">MLP</span></code> class like a function. (Example: <code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">=</span> <span class="pre">net(data)</span></code>)</p>
<p>Chainer provides many kinds of <code class="docutils literal notranslate"><span class="pre">Function</span></code> and <code class="docutils literal notranslate"><span class="pre">Link</span></code>. Please take a look at the following links.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.chainer.org/en/stable/reference/functions.html">List of functions available in Chainer</a></p></li>
<li><p><a class="reference external" href="https://docs.chainer.org/en/stable/reference/links.html">List of layers (Link) available in Chainer</a></p></li>
</ul>
<p>In <code class="docutils literal notranslate"><span class="pre">Link</span></code>, Well-known network structures such as ResNet and VGG are provided in addition to fully-connected layer, convolution layer, LSTM etc. commonly used for neural networks. In <code class="docutils literal notranslate"><span class="pre">Function</span></code>, functions such as ReLU activation functions, functions to resize images, functions such as sine and cosine, and functions that can be used as elements of the network are provided. It is necessary to use those provided in <code class="docutils literal notranslate"><span class="pre">chainer.functions</span></code> even for functions with no parameters because, in
<code class="docutils literal notranslate"><span class="pre">Define-by-Run</span></code>, it acquires the path that calculates gradient with back propagation, by first performing forward propagation calculation with input data to the network, then tracing the history of the functions (with and without parameters) that were applied to the data.</p>
</div>
<div class="section" id="Running-on-GPU">
<h4>4.2.4.5. Running on GPU<a class="headerlink" href="#Running-on-GPU" title="Permalink to this headline">¶</a></h4>
<p>GPUs are routinely used for training networks with many parameters in deep learning. By using GPU, processing such as matrix operation can be done very fast compared with CPU. The way to do calculations with GPU with Chainer is simple. <code class="docutils literal notranslate"><span class="pre">Chain</span></code> class has a <code class="docutils literal notranslate"><span class="pre">to_gpu</span></code> method, and if you specify a GPU ID for this argument, all parameters of the network are transferred to the memory of the specified GPU ID. By doing this, forward propagation and parameter update at training etc are all done on the
GPU. If -1 is specified as the GPU ID, CPU is used instead.</p>
</div>
<div class="section" id="Calculation-of-the-number-of-input-side-units">
<h4>4.2.4.6. Calculation of the number of input side units<a class="headerlink" href="#Calculation-of-the-number-of-input-side-units" title="Permalink to this headline">¶</a></h4>
<p>In the above network definition, in the first Linear layer, <code class="docutils literal notranslate"><span class="pre">None</span></code> is passed to the first argument. By specifying the argument as <code class="docutils literal notranslate"><span class="pre">None</span></code>, the necessary number of units on the input side are automatically determined at the time when the data is first input to that layer, create a matrix of size of <code class="docutils literal notranslate"><span class="pre">n_input</span></code> <span class="math notranslate nohighlight">\(\times\)</span> <code class="docutils literal notranslate"><span class="pre">n_mid_units</span></code> and hold it as a parameter to be trained. Remember, this will be a useful function, for example, when placing the convolution layer in front of
fully-connected layers later.</p>
</div>
</div>
<div class="section" id="Selection-of-Optimizers">
<h3>4.2.5. Selection of Optimizers<a class="headerlink" href="#Selection-of-Optimizers" title="Permalink to this headline">¶</a></h3>
<p>Let’s train the network defined above with the MNIST dataset. Many methods of optimization of training have been proposed, Chainer offers them by the function <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> to make them avaiable with the same interface. <code class="docutils literal notranslate"><span class="pre">chainer.optimizers</span></code> module is defined below. Here is the list:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.chainer.org/en/stable/reference/optimizers.html">List of optimizers available in Chainer</a></p></li>
</ul>
<p>Here we use the simplest method of gradient descent method, <code class="docutils literal notranslate"><span class="pre">optimizers.SGD</span></code>. We will pass the model (<code class="docutils literal notranslate"><span class="pre">Chain</span></code> object) to the object of <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> using <code class="docutils literal notranslate"><span class="pre">setup</span></code> method. By doing this, you can let <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> know what it needs to optimize.</p>
<p>Please try out various optimization methods and see how the result would change. Within the <code class="docutils literal notranslate"><span class="pre">Optimizers</span></code> listed as <code class="docutils literal notranslate"><span class="pre">chainer.optimizers.SGD</span></code> for instance, you can simply replace <code class="docutils literal notranslate"><span class="pre">SGD</span></code> with <code class="docutils literal notranslate"><span class="pre">MomentumSGD</span></code>, <code class="docutils literal notranslate"><span class="pre">RMSprop</span></code>, <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, or any of the other optimizers and see how the learning curve (also known as loss curve - the plots of the value of the objective function) changes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer</span> <span class="kn">import</span> <span class="n">optimizers</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Learning-Rate">
<h4>4.2.5.1. Learning Rate<a class="headerlink" href="#Learning-Rate" title="Permalink to this headline">¶</a></h4>
<p>We passed <span class="math notranslate nohighlight">\(0.01\)</span> to the argument named <code class="docutils literal notranslate"><span class="pre">lr</span></code> in SGD this time. This value is known as the learning rate, also called a <strong>hyper parameter</strong>, an important parameter that is necessary to adjust in order to train the model well for obtaining high performance. Unlike parameters to be trained, hyperparameter refers to things related to training settings that have to be set separately to the structure of networks.</p>
</div>
</div>
<div class="section" id="Start-Training">
<h3>4.2.6. Start Training<a class="headerlink" href="#Start-Training" title="Permalink to this headline">¶</a></h3>
<p>Since it is a classification problem to distinguish between 0 to 9 numbers, we calculate the loss to be minimized using the loss function, <code class="docutils literal notranslate"><span class="pre">softmax_cross_entropy</span></code>. With softmax function, when <span class="math notranslate nohighlight">\(d\)</span> dimension of vector <span class="math notranslate nohighlight">\({\bf y} \in \mathbb{R}^d\)</span> is given, you can normalize it so that the sum of the values of the each dimension becomes 1. In other words, we can make output like probability distribution from arbitrary real vector. If you write the <span class="math notranslate nohighlight">\(i\)</span>th dimension of
<span class="math notranslate nohighlight">\({\bf y}\)</span> as <span class="math notranslate nohighlight">\(y_i\)</span>, softmax function can be expressed as</p>
<div class="math notranslate nohighlight">
\[p_i = \frac{\exp(y_i)}{\sum_{j=1}^d \exp(y_j)}\]</div>
<p>Thus, we consider that the normalized output vector is representing the probability of the input belonging to each class, and the one calculating the cross entropy described in the previous chapter with the correct 1-hot vector is <code class="docutils literal notranslate"><span class="pre">softmax_cross_entropy</span></code> function.</p>
<p>First, pass data to the network and calculate the predicted value by forward propagation. Then, pass the predicted value and the correct/true label corresponding to the input data to the loss function to calculate the loss (value to be minimized). The loss is obtained as an object of <code class="docutils literal notranslate"><span class="pre">chainer.Variable</span></code>. This <code class="docutils literal notranslate"><span class="pre">Variable</span></code> <strong>remembers the history of past calculations so that it is traceable</strong>. This mechanism plays a central role in the concept called Define-by-Run <a class="reference external" href="http://learningsys.org/papers/LearningSys_2015_paper_33.pdf">Tokui
2015</a>.</p>
<p>The process of computing the gradient for the calculated loss <strong>backwards in the network</strong> can be achieved in chainer, by simply calling the <code class="docutils literal notranslate"><span class="pre">backward</span></code> method on <code class="docutils literal notranslate"><span class="pre">Variable</span></code> output by the network. By calling this, it builds <strong>a calculation graph for error back propagation</strong>, and calculates the gradient of the parameter in the middle using the chain rate. (For details , see the tutorial materials in the <a class="reference external" href="https://www.slideshare.net/mitmul/chainer-79942361">Tutorial material from Japan society for Software Science and
Technology</a> (written in Japanese))</p>
<p>Finally, updating (= training) of network parameters is performed by <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code>, using the gradient for each parameter calculated.</p>
<p>In summary, the following four items are performed in the series of update processing.</p>
<ol class="arabic simple">
<li><p>Pass data to the network to calculate forward propagation and get output <code class="docutils literal notranslate"><span class="pre">y</span></code></p></li>
<li><p>Calculate the loss to be minimized with a function <code class="docutils literal notranslate"><span class="pre">softmax_cross_entropy</span></code> using the output <code class="docutils literal notranslate"><span class="pre">y</span></code> and the correct answer label <code class="docutils literal notranslate"><span class="pre">t</span></code></p></li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">backward</span></code> method of ouput (<code class="docutils literal notranslate"><span class="pre">Variable</span></code>) of function <code class="docutils literal notranslate"><span class="pre">softmax_cross_entropy</span></code> and calculate the gradient of all parameters of the network by error back propagation method</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">update</span></code> method of the Optimizer to update all the parameters using the gradient calculated in 3.</p></li>
</ol>
<p>Parameters are updated by repeating the above steps. The data used for one parameter update is only data entered into the network, bundled as mini batch. Training is done by using the whole data set by inputting new mini batches one after another and repeating the above steps. This process is called <strong>a training loop</strong>.</p>
<div class="section" id="Objective-Function">
<h4>4.2.6.1. Objective Function<a class="headerlink" href="#Objective-Function" title="Permalink to this headline">¶</a></h4>
<p>As an objective function, if you want to solve a regression problem rather than a classification problem, for example, you can use <code class="docutils literal notranslate"><span class="pre">F.mean_squared_error</span></code> instead of <code class="docutils literal notranslate"><span class="pre">F.softmax_cross_entropy</span></code>. In addition, Chainer provides various loss functions to deal with various problems. You can see the list here:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://docs.chainer.org/en/stable/reference/functions.html#loss-functions">List of objective (loss functions) functions available in Chainer</a></p></li>
</ul>
</div>
<div class="section" id="The-Code-of-the-Traning-Loop">
<h4>4.2.6.2. The Code of the Traning Loop<a class="headerlink" href="#The-Code-of-the-Traning-Loop" title="Permalink to this headline">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">chainer.dataset</span> <span class="kn">import</span> <span class="n">concat_examples</span>
<span class="kn">from</span> <span class="nn">chainer.cuda</span> <span class="kn">import</span> <span class="n">to_cpu</span>

<span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">while</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">max_epoch</span><span class="p">:</span>

    <span class="c1"># ---------- 1 itelation of training ----------</span>
    <span class="n">train_batch</span> <span class="o">=</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">concat_examples</span><span class="p">(</span><span class="n">train_batch</span><span class="p">,</span> <span class="n">gpu_id</span><span class="p">)</span>

    <span class="c1"># Calucation of predicted value</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Loss calculation</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

    <span class="c1"># Gradient calculation</span>
    <span class="n">net</span><span class="o">.</span><span class="n">cleargrads</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Update parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="c1"># --------------- end ----------------</span>

    <span class="c1"># Let&#39;s check if generalization performance of the model</span>
    <span class="c1"># has been improved by calculating the prediction accuracy</span>
    <span class="c1"># at the completion of each epoch</span>
    <span class="k">if</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">is_new_epoch</span><span class="p">:</span>  <span class="c1"># when the end of one epoch..</span>

        <span class="c1"># Print the loss</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;epoch:{:02d} train_loss:{:.4f} &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">train_iter</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">))),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

        <span class="n">valid_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">valid_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">valid_batch</span> <span class="o">=</span> <span class="n">valid_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
            <span class="n">x_valid</span><span class="p">,</span> <span class="n">t_valid</span> <span class="o">=</span> <span class="n">concat_examples</span><span class="p">(</span><span class="n">valid_batch</span><span class="p">,</span> <span class="n">gpu_id</span><span class="p">)</span>

            <span class="c1"># Forward the Validation data</span>
            <span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">),</span> \
                    <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;enable_backprop&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
                <span class="n">y_valid</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_valid</span><span class="p">)</span>

            <span class="c1"># Loss calculation</span>
            <span class="n">loss_valid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">t_valid</span><span class="p">)</span>
            <span class="n">valid_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">loss_valid</span><span class="o">.</span><span class="n">array</span><span class="p">))</span>

            <span class="c1"># Calculate accuracy</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">t_valid</span><span class="p">)</span>
            <span class="n">accuracy</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span>
            <span class="n">valid_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="o">.</span><span class="n">array</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">valid_iter</span><span class="o">.</span><span class="n">is_new_epoch</span><span class="p">:</span>
                <span class="n">valid_iter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                <span class="k">break</span>

        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;val_loss:{:.4f} val_accuracy:{:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">valid_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">valid_accuracies</span><span class="p">)))</span>

<span class="c1"># Evaluation with test data</span>
<span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">test_batch</span> <span class="o">=</span> <span class="n">test_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">concat_examples</span><span class="p">(</span><span class="n">test_batch</span><span class="p">,</span> <span class="n">gpu_id</span><span class="p">)</span>

    <span class="c1"># Forward test data</span>
    <span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">),</span> \
            <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;enable_backprop&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

    <span class="c1"># Calculate accuracy</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span>
    <span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="o">.</span><span class="n">array</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">test_iter</span><span class="o">.</span><span class="n">is_new_epoch</span><span class="p">:</span>
        <span class="n">test_iter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">break</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;test_accuracy:{:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_accuracies</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch:01 train_loss:0.9390 val_loss:0.9743 val_accuracy:0.7948
epoch:02 train_loss:0.5398 val_loss:0.5335 val_accuracy:0.8634
epoch:03 train_loss:0.4008 val_loss:0.4232 val_accuracy:0.8846
epoch:04 train_loss:0.3328 val_loss:0.3744 val_accuracy:0.8944
epoch:05 train_loss:0.4598 val_loss:0.3458 val_accuracy:0.9002
epoch:06 train_loss:0.2478 val_loss:0.3276 val_accuracy:0.9073
epoch:07 train_loss:0.3308 val_loss:0.3110 val_accuracy:0.9118
epoch:08 train_loss:0.3792 val_loss:0.2991 val_accuracy:0.9146
epoch:09 train_loss:0.2978 val_loss:0.2887 val_accuracy:0.9178
epoch:10 train_loss:0.3221 val_loss:0.2804 val_accuracy:0.9204
test_accuracy:0.9237
</pre></div></div>
</div>
<p>Focusing on <code class="docutils literal notranslate"><span class="pre">val_accuracy</span></code>, finally it became possible to classify handwritten numbers with about 92% accuracy. The accuracy referred to here is <span class="math notranslate nohighlight">\(M/N\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the number of data points in the Validation dataset, and <span class="math notranslate nohighlight">\(M\)</span> is the number of correct results. During training, the generalization performance of the model is checked by measuring accuracy at the end of each loop using the Validation dataset prepared earlier. After training, we use the test dataset to evaluate the
networks for which training has been completed. The evaluation result on the test data is about 92.37%.</p>
</div>
<div class="section" id="Note-on-Validation-and-Testing">
<h4>4.2.6.3. Note on Validation and Testing<a class="headerlink" href="#Note-on-Validation-and-Testing" title="Permalink to this headline">¶</a></h4>
<p>For final evaluation after training, we use another Test dataset that is different from the Validation dataset used for hyper parameter adjustment. Test dataset is prepared so that there is no duplication of data in Training dataset and Validation dataset.</p>
<p>Now, so far, we mainly explained the way of “training”, but there are some points to be careful when doing “evaluation”. This is because in some functions and calculation processes, the behavior could differ between training and evaluation. The following describes methods to control the differences in their behavior.</p>
<div class="section" id="chainer.using_config('train',-False)">
<h5>4.2.6.3.1. <code class="docutils literal notranslate"><span class="pre">chainer.using_config('train',</span> <span class="pre">False)</span></code><a class="headerlink" href="#chainer.using_config('train',-False)" title="Permalink to this headline">¶</a></h5>
<p>In the previous example, functions that differ in behavior during learning and inference were not included, but when inferring for Validation or a test, use <code class="docutils literal notranslate"><span class="pre">chainer.using_config('train',</span> <span class="pre">False)</span></code> with the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement, as shown below, so that <strong>the corresponding function will operate as inference mode</strong>. As a result, functions that differ in behavior during training and inference perform correctly for inference (for example,
<a class="reference external" href="https://en.wikipedia.org/wiki/Dropout_(neural_networks)">Dropout</a> etc.). Please read this <code class="docutils literal notranslate"><span class="pre">train</span></code> section for more information: <a class="reference external" href="https://docs.chainer.org/en/stable/reference/configuration.html#configuration-keys">Configuration Keys</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
    <span class="o">---</span> <span class="n">some</span> <span class="n">inference</span> <span class="n">processing</span> <span class="o">---</span>
</pre></div>
</div>
</div>
<div class="section" id="chainer.using_config('enable_backprop',-False)">
<h5>4.2.6.3.2. <code class="docutils literal notranslate"><span class="pre">chainer.using_config('enable_backprop',</span> <span class="pre">False)</span></code><a class="headerlink" href="#chainer.using_config('enable_backprop',-False)" title="Permalink to this headline">¶</a></h5>
<p>When considering only evaluation, it is not necessary to construct gradient information for each parameter of the loss function after output calculation, so that <strong>unnecessary calculation graph construction is not performed, and memory consumption is saved</strong>. Please read <code class="docutils literal notranslate"><span class="pre">enable_backprop</span></code> section of the following document for more information: <a class="reference external" href="https://docs.chainer.org/en/stable/reference/configuration.html#configuration-keys">Configuration Keys</a></p>
</div>
<div class="section" id="Chainer’s-Config">
<h5>4.2.6.3.3. Chainer’s Config<a class="headerlink" href="#Chainer’s-Config" title="Permalink to this headline">¶</a></h5>
<p>Chainer also has several other global configs. In addition, the user can place any setting values under <code class="docutils literal notranslate"><span class="pre">chainer.config</span></code>. For more information please read: <a class="reference external" href="https://docs.chainer.org/en/stable/reference/configuration.html">Configuring Chainer</a></p>
</div>
</div>
</div>
<div class="section" id="Saving-Trained-Model">
<h3>4.2.7. Saving Trained Model<a class="headerlink" href="#Saving-Trained-Model" title="Permalink to this headline">¶</a></h3>
<p>After training is complete, we need to save the result. Chainer has a function to save trained networks in files in two formats. One is the HDF5 format, the other is the NumPy NPZ format, which saves the network. Here we use the serialization function (<code class="docutils literal notranslate"><span class="pre">numpy.savez()</span></code>) provided by the NumPy, with which the model is saved in Numpy’s standard format, NPZ, instead of HDF5 that requires the installation of additional libraries.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer</span> <span class="kn">import</span> <span class="n">serializers</span>

<span class="n">serializers</span><span class="o">.</span><span class="n">save_npz</span><span class="p">(</span><span class="s1">&#39;my_mnist.model&#39;</span><span class="p">,</span> <span class="n">net</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Check if has been saved</span>
<span class="o">%</span><span class="k">ls</span> -la my_mnist.model

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-rw-r--r-- 1 root root 333955 Mar  1 04:58 my_mnist.model
</pre></div></div>
</div>
</div>
<div class="section" id="Perform-inference-after-loading-the-saved-model">
<h3>4.2.8. Perform inference after loading the saved model<a class="headerlink" href="#Perform-inference-after-loading-the-saved-model" title="Permalink to this headline">¶</a></h3>
<p>We will explain how to load model in a file saved after training. First, re-instantiate the network used for training, and load the NPZ file saved earlier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># First, create an object of the same network</span>
<span class="n">infer_net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>

<span class="c1"># Load parameters, saved in a file, into the object</span>
<span class="n">serializers</span><span class="o">.</span><span class="n">load_npz</span><span class="p">(</span><span class="s1">&#39;my_mnist.model&#39;</span><span class="p">,</span> <span class="n">infer_net</span><span class="p">)</span>

</pre></div>
</div>
</div>
<p>Now we are ready. Let’s take the first image out of the test data and try to classify it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">gpu_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># If you need to use CPU, set this variable to -1</span>

<span class="k">if</span> <span class="n">gpu_id</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">infer_net</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">gpu_id</span><span class="p">)</span>

<span class="c1"># Pick the first test data</span>
<span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1">#  t not used</span>

<span class="c1"># Show the image just to see how it looks like</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Conver to mini-batch form. (If you&#39;d like to bunle multiple images for</span>
<span class="c1"># inference, bundle them into a mini-batch of size n)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Original shape:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; -&gt; &#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;After coverted to mini-batch shape：&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Send data to the same device as the as the network</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">infer_net</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Pass to the model&#39;s forward function</span>
<span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">),</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;enable_backprop&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">infer_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># As it is in Variable form, take out the content</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">array</span>

<span class="c1"># Pass the result to CPU</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_cpu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># View the max value of prediction rate</span>
<span class="n">pred_label</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Prediction by network:&#39;</span><span class="p">,</span> <span class="n">pred_label</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-cyan-fg">  File </span><span class="ansi-green-fg">&#34;&lt;ipython-input-1-93fb5e4741a3&gt;&#34;</span><span class="ansi-cyan-fg">, line </span><span class="ansi-green-fg">15</span>
<span class="ansi-red-fg">    print(&#39;Original shape:&#39;, x.shape, end=&#39; -&gt; &#39;)</span>
                                         ^
<span class="ansi-red-fg">SyntaxError</span><span class="ansi-red-fg">:</span> invalid syntax

</pre></div></div>
</div>
<p>Prediction by the network is 7. As you can see with the image, it is predicted correctly.</p>
</div>
</div>
<div class="section" id="How-to-use-Trainer">
<h2>4.3. How to use Trainer<a class="headerlink" href="#How-to-use-Trainer" title="Permalink to this headline">¶</a></h2>
<p>Chainer provides a function called <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> to hide the training loop as written so far. By using this, you do not have to write the training loop yourself, and by using the convenient extension function (<code class="docutils literal notranslate"><span class="pre">Extention</span></code>), you can easily visualize the learning curve in the training process and save the log.</p>
<div class="section" id="Pareparing-Dataset,-Iterator-and-Network">
<h3>4.3.1. Pareparing Dataset, Iterator and Network<a class="headerlink" href="#Pareparing-Dataset,-Iterator-and-Network" title="Permalink to this headline">¶</a></h3>
<p>Dataset, iterator and the network need to be prepared when using Trainer as well.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">get_mnist</span><span class="p">()</span>
<span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">train_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">valid_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span><span class="n">valid</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">SerialIterator</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">gpu_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># To use CPU, set this variable to -1</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>

<span class="k">if</span> <span class="n">gpu_id</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">gpu_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Preparation-of-Updater">
<h3>4.3.2. Preparation of Updater<a class="headerlink" href="#Preparation-of-Updater" title="Permalink to this headline">¶</a></h3>
<p>To recap the training steps for writing the training loop by yourself, the series of steps including “create mini-batch from data set”, “input to network and output prediction”, “compare error with correct answer”, “running error backward propagation” and “update parameters by Optimizer” were written as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ---------- 1 iteration of training ----------</span>
<span class="n">train_batch</span> <span class="o">=</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">concat_examples</span><span class="p">(</span><span class="n">train_batch</span><span class="p">,</span> <span class="n">gpu_id</span><span class="p">)</span>

<span class="c1"># Calculation of prediction value</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Loss calculation</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

<span class="c1"># Slope calculation</span>
<span class="n">net</span><span class="o">.</span><span class="n">cleargrads</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Parameter update</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
<p>By using the <code class="docutils literal notranslate"><span class="pre">Updater</span></code> provided as a function of Chainer, it is possible to write the series of these processes easily. <code class="docutils literal notranslate"><span class="pre">Iterator</span></code> and <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> are passed to the <code class="docutils literal notranslate"><span class="pre">Updater</span></code>. Because <code class="docutils literal notranslate"><span class="pre">Iterator</span></code> has a dataset object, we will create a mini-batch from it. Since <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> has a network to be optimized, it can be used for forward propagation, error calculation and parameter updating. Therefore, by passing these two, all processing will be complete within the <code class="docutils literal notranslate"><span class="pre">Updater</span></code>. Let’s create
an <code class="docutils literal notranslate"><span class="pre">Updater</span></code> object.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer</span> <span class="kn">import</span> <span class="n">training</span>

<span class="n">gpu_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># If you need to use CPU, set this variable to -1</span>

<span class="c1"># Wrap the network with Classifier to include loss calculation etc to the model</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Classifier</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="c1"># Choose optimization method</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="c1"># Pass Iterator and Optimizer to the Updater</span>
<span class="n">updater</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">StandardUpdater</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="section" id="Chain-for-the-loss-calculation">
<h4>4.3.2.1. Chain for the loss calculation<a class="headerlink" href="#Chain-for-the-loss-calculation" title="Permalink to this headline">¶</a></h4>
<p>Here, we wrap the network with <code class="docutils literal notranslate"><span class="pre">L.Classifier</span></code>. <code class="docutils literal notranslate"><span class="pre">L.Classifier</span></code> has the network passed <code class="docutils literal notranslate"><span class="pre">predictor</span></code> as an attribute and <strong>adds a function to perform loss calculation</strong>. By doing this, <code class="docutils literal notranslate"><span class="pre">net()</span></code> will take not only the data <code class="docutils literal notranslate"><span class="pre">x</span></code> but also the labels <code class="docutils literal notranslate"><span class="pre">t</span></code>, calculate the predicted value by passing the received data to <code class="docutils literal notranslate"><span class="pre">predictor</span></code>, and <strong>return the Variable of loss</strong> by comparing with the correct label <code class="docutils literal notranslate"><span class="pre">t</span></code>. The loss function used as default is <code class="docutils literal notranslate"><span class="pre">F.softmax_cross_entropy</span></code>, but you can change
it by passing the function that performs the loss calculation to lossfunc argument of <code class="docutils literal notranslate"><span class="pre">L.Classifier</span></code>, and (despite the name being <code class="docutils literal notranslate"><span class="pre">Classfier</span></code>) you can use it to add other loss calculation functions, For example: such as for regression problem, one can do: <code class="docutils literal notranslate"><span class="pre">L.Classifier(net,</span> <span class="pre">lossfun=L.mean_squared_error,</span> <span class="pre">compute_accuracy=False)</span></code>)</p>
<p><code class="docutils literal notranslate"><span class="pre">StandardUpdater</span></code> is the simplest class to carry out the processing of the above mentioned <code class="docutils literal notranslate"><span class="pre">Updater</span></code>. Besides this, <code class="docutils literal notranslate"><span class="pre">ParallelUpdater</span></code> is provided to use multiple GPUs.</p>
</div>
</div>
<div class="section" id="Preparation-of-Trainer">
<h3>4.3.3. Preparation of Trainer<a class="headerlink" href="#Preparation-of-Trainer" title="Permalink to this headline">¶</a></h3>
<p>In addition to <code class="docutils literal notranslate"><span class="pre">Updater</span></code> which is hiding the part of the training loop, <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> provides a function that manages the entire training by receiving the <code class="docutils literal notranslate"><span class="pre">Updater</span></code>. For instance, it provides things that are required as settings for training or various useful features such as, <strong>how many iterations needs to be made before stopping the training (stop_trigger)</strong>, <strong>to which file you want to save snapshot of the loss values</strong>, and <strong>whether to save the image file visualizing the learning
curve</strong>.</p>
<p>One of the required features is <code class="docutils literal notranslate"><span class="pre">stop_trigger</span></code> that specifies the timing of the end of training. This is specified in the constructor when creating a <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object. The way to specify it is simple: It only needs to be given a tuple of the form <code class="docutils literal notranslate"><span class="pre">(length,</span> <span class="pre">unit)</span></code>. Specify a number for “Length” and a string that is either <code class="docutils literal notranslate"><span class="pre">'iteration'</span></code> or <code class="docutils literal notranslate"><span class="pre">'epoch'</span></code> for “Unit”. With these, you can achieve, for example, finishing training with 100 epoch (dataset 100 cycles), or with 1000 iterations
(updated 1000 times). If you do not specify it, when creating <code class="docutils literal notranslate"><span class="pre">Training</span></code>, training will not stop automatically.</p>
<p>Let’s actually create a <code class="docutils literal notranslate"><span class="pre">Training</span></code> object.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Pass Updater to Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">updater</span><span class="p">,</span> <span class="p">(</span><span class="n">max_epoch</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="s1">&#39;results/mnist_result&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>With the argument <code class="docutils literal notranslate"><span class="pre">out</span></code>, using <code class="docutils literal notranslate"><span class="pre">Extension</span></code> explained below, we specify the directory to save the log file and the image file of the graph drawing the process of change of loss etc.</p>
<p>The relationship between the Trainer and the various objects inside is as shown below. Remembering this image would be helpful when you want to partially modify it yourself.</p>
<p><img alt="Relationship between Trainer-related objects" src="https://qiita-image-store.s3.amazonaws.com/0/17934/a751df31-b999-f692-d839-488c26b1c48a.png" /></p>
</div>
<div class="section" id="Add-Extension-to-Trainer">
<h3>4.3.4. Add Extension to Trainer<a class="headerlink" href="#Add-Extension-to-Trainer" title="Permalink to this headline">¶</a></h3>
<p>Advantages of using <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>:</p>
<ul class="simple">
<li><p>Automatically save logs to file（<code class="docutils literal notranslate"><span class="pre">LogReport</span></code>)</p></li>
<li><p>Display information such as loss regularly on the terminal（<code class="docutils literal notranslate"><span class="pre">PrintReport</span></code>）</p></li>
<li><p>Visualize the loss regularly as a graph and save it as an image（<code class="docutils literal notranslate"><span class="pre">PlotReport</span></code>)</p></li>
<li><p>Automatic serialization of model and Optimizer status regularly（<code class="docutils literal notranslate"><span class="pre">snapshot</span></code>）</p></li>
<li><p>Display a progress bar indicating the progress of learning（<code class="docutils literal notranslate"><span class="pre">ProgressBar</span></code>）</p></li>
<li><p>Save network structure in Graphviz dot format（<code class="docutils literal notranslate"><span class="pre">dump_graph</span></code>）</p></li>
<li><p>Output statistical information such as average and variance of network parameters（<code class="docutils literal notranslate"><span class="pre">ParameterStatistics</span></code>）</p></li>
</ul>
<p>These are easily achieved with the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. You would ony need to pass <code class="docutils literal notranslate"><span class="pre">Extension</span></code> you want to add, using <code class="docutils literal notranslate"><span class="pre">extend</span></code> method, to <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object. Let’s actually add some.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer.training</span> <span class="kn">import</span> <span class="n">extensions</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">LogReport</span><span class="p">())</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">snapshot</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;snapshot_epoch-{.updater.epoch}&#39;</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">Evaluator</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PrintReport</span><span class="p">([</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;l1/W/data/std&#39;</span><span class="p">,</span> <span class="s1">&#39;elapsed_time&#39;</span><span class="p">]))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">ParameterStatistics</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">predictor</span><span class="o">.</span><span class="n">l1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">}))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PlotReport</span><span class="p">([</span><span class="s1">&#39;l1/W/data/std&#39;</span><span class="p">],</span> <span class="n">x_key</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;std.png&#39;</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PlotReport</span><span class="p">([</span><span class="s1">&#39;main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/loss&#39;</span><span class="p">],</span> <span class="n">x_key</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;loss.png&#39;</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PlotReport</span><span class="p">([</span><span class="s1">&#39;main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/accuracy&#39;</span><span class="p">],</span> <span class="n">x_key</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;accuracy.png&#39;</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">dump_graph</span><span class="p">(</span><span class="s1">&#39;main/loss&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ModuleNotFoundError</span>                       Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-5ae25fc16f2b&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> chainer<span class="ansi-blue-fg">.</span>training <span class="ansi-green-fg">import</span> extensions
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> trainer<span class="ansi-blue-fg">.</span>extend<span class="ansi-blue-fg">(</span>extensions<span class="ansi-blue-fg">.</span>LogReport<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> trainer<span class="ansi-blue-fg">.</span>extend<span class="ansi-blue-fg">(</span>extensions<span class="ansi-blue-fg">.</span>snapshot<span class="ansi-blue-fg">(</span>filename<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;snapshot_epoch-{.updater.epoch}&#39;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> trainer<span class="ansi-blue-fg">.</span>extend<span class="ansi-blue-fg">(</span>extensions<span class="ansi-blue-fg">.</span>Evaluator<span class="ansi-blue-fg">(</span>valid_iter<span class="ansi-blue-fg">,</span> net<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>gpu_id<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;val&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">ModuleNotFoundError</span>: No module named &#39;chainer&#39;
</pre></div></div>
</div>
<div class="section" id="LogReport">
<h4>4.3.4.1. <code class="docutils literal notranslate"><span class="pre">LogReport</span></code><a class="headerlink" href="#LogReport" title="Permalink to this headline">¶</a></h4>
<p>Automatically aggregate <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> per <code class="docutils literal notranslate"><span class="pre">epoch</span></code> or <code class="docutils literal notranslate"><span class="pre">iteration</span></code>, then save them to a file named as <code class="docutils literal notranslate"><span class="pre">log</span></code>.</p>
</div>
<div class="section" id="snapshot">
<h4>4.3.4.2. <code class="docutils literal notranslate"><span class="pre">snapshot</span></code><a class="headerlink" href="#snapshot" title="Permalink to this headline">¶</a></h4>
<p>Save the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object at the specified timing (every 1 epoch by default). <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object, as described above has an <code class="docutils literal notranslate"><span class="pre">Updater</span></code> in which <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> and model are held, by taking a snapshot with <code class="docutils literal notranslate"><span class="pre">Extension</span></code>, you can resume training from that point, or to perform inference using the trained model.</p>
</div>
<div class="section" id="dump_graph">
<h4>4.3.4.3. <code class="docutils literal notranslate"><span class="pre">dump_graph</span></code><a class="headerlink" href="#dump_graph" title="Permalink to this headline">¶</a></h4>
<p>Saves the computation graph that can be traced from the specified <code class="docutils literal notranslate"><span class="pre">Variable</span></code> object in Graphviz dot format.</p>
</div>
<div class="section" id="Evaluator">
<h4>4.3.4.4. <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code><a class="headerlink" href="#Evaluator" title="Permalink to this headline">¶</a></h4>
<p>By passing the dataset <code class="docutils literal notranslate"><span class="pre">Iterator</span></code> for evaluation and the object of the model used for training, the model under training is evaluated using the dataset for evaluation at a specified timing. Internally, <code class="docutils literal notranslate"><span class="pre">chainer.config.using_config('train',</span> <span class="pre">False)</span></code> is done automatically. The memory usage efficiency is not the optimal by default because <code class="docutils literal notranslate"><span class="pre">backprop_enable</span></code> is not set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, however, if <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> is used, it wouldn’t be a problem in terms of the evaluation.</p>
</div>
<div class="section" id="PrintReport">
<h4>4.3.4.5. <code class="docutils literal notranslate"><span class="pre">PrintReport</span></code><a class="headerlink" href="#PrintReport" title="Permalink to this headline">¶</a></h4>
<p>Output the aggregated values to the standard output in the same way as <code class="docutils literal notranslate"><span class="pre">LogReport</span></code>. At that time, it gives which value to output in the form of a list.</p>
</div>
<div class="section" id="PlotReport">
<h4>4.3.4.6. <code class="docutils literal notranslate"><span class="pre">PlotReport</span></code><a class="headerlink" href="#PlotReport" title="Permalink to this headline">¶</a></h4>
<p>Draw the transition of the value specified in the argument list using the <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> library, and save it as an image in the output directory with the file name specified with the <code class="docutils literal notranslate"><span class="pre">file_name</span></code> argument.</p>
</div>
<div class="section" id="ParameterStatistics">
<h4>4.3.4.7. <code class="docutils literal notranslate"><span class="pre">ParameterStatistics</span></code><a class="headerlink" href="#ParameterStatistics" title="Permalink to this headline">¶</a></h4>
<p>Calculates statistical information such as the average, variance, minimum value, maximum value, etc. of the parameters of the specified layer (Link), and saves it in a log. It is useful to check whether parameters are diverging etc.</p>
<hr class="docutils" />
<p>The <code class="docutils literal notranslate"><span class="pre">Extension</span></code> object, in addition to ones introduced here, has several other options, such as the ability to specify the timing to operate individually by the <code class="docutils literal notranslate"><span class="pre">trigger</span></code>, and the options can be flexibly combined. See the official documentation for details.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://docs.chainer.org/en/stable/reference/extensions.html">List of Trainer extensions in Chainer</a></p></li>
</ul>
</div>
</div>
<div class="section" id="Start-of-Training-(using-Trainer)">
<h3>4.3.5. Start of Training (using Trainer)<a class="headerlink" href="#Start-of-Training-(using-Trainer)" title="Permalink to this headline">¶</a></h3>
<p>Execute Trainer object method <code class="docutils literal notranslate"><span class="pre">run</span></code> to start training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  l1/W/data/std  elapsed_time
1           1.66917     0.599884       0.93892        0.806764           0.0359232      5.61012
2           0.673347    0.843211       0.519291       0.86699            0.0366054      9.98746
3           0.459921    0.878686       0.414858       0.887658           0.037035       14.3671
4           0.389535    0.893262       0.370489       0.896855           0.037301       18.7945
5           0.353169    0.901255       0.342332       0.904569           0.03749        23.344
6           0.330151    0.90609        0.32213        0.909711           0.037639       27.7571
7           0.312338    0.910846       0.306804       0.91337            0.0377671      32.1619
8           0.298136    0.914663       0.295119       0.915843           0.0378811      36.614
9           0.285837    0.917559       0.284161       0.918513           0.0379865      41.0422
10          0.275229    0.921116       0.27476        0.921776           0.0380852      45.5019
</pre></div></div>
</div>
<p>The same result was achieved far more easily than writing the training loop manually. In addition, visualization of various scores and learning curves are automatically outputed by using the function of <code class="docutils literal notranslate"><span class="pre">Extension</span></code>.</p>
<p>Let’s check the loss graph.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/mnist_result/loss.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_78_0.png" src="../_images/notebooks_Introduction_to_Chainer_78_0.png" />
</div>
</div>
<p>Let’s also look at the graph of accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/mnist_result/accuracy.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_80_0.png" src="../_images/notebooks_Introduction_to_Chainer_80_0.png" />
</div>
</div>
<p>It appears that if you continue training a little more, further improvement in accuracy can be achieved.</p>
<p>Finally, let’s visualize the calculation graph in the file output by <code class="docutils literal notranslate"><span class="pre">Extension</span></code> <code class="docutils literal notranslate"><span class="pre">dump_graph</span></code>, using <code class="docutils literal notranslate"><span class="pre">Graphviz</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>dot -Tpng results/mnist_result/cg.dot -o results/mnist_result/cg.png

</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/mnist_result/cg.png&#39;</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_83_0.png" src="../_images/notebooks_Introduction_to_Chainer_83_0.png" />
</div>
</div>
<p>Data and parameters are passed to the function one after another, and a series of calculations are performed until loss as output can be confirmed.</p>
</div>
<div class="section" id="Test-data-evaluation">
<h3>4.3.6. Test data evaluation<a class="headerlink" href="#Test-data-evaluation" title="Permalink to this headline">¶</a></h3>
<p>The Evaluator, which is used to evaluate validation data during training, can also be used independently of the Trainer. As shown below, simply pass <code class="docutils literal notranslate"><span class="pre">Iterator</span></code>, network objects (<code class="docutils literal notranslate"><span class="pre">net</span></code>) and the device ID to the Evaluator constructor, to create the Evaluator object, then execute it as a function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_evaluator</span> <span class="o">=</span> <span class="n">extensions</span><span class="o">.</span><span class="n">Evaluator</span><span class="p">(</span><span class="n">test_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">test_evaluator</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;main/accuracy&#39;</span><span class="p">])</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Test accuracy: 0.92494065
</pre></div></div>
</div>
</div>
<div class="section" id="Infer-with-trained-model">
<h3>4.3.7. Infer with trained model<a class="headerlink" href="#Infer-with-trained-model" title="Permalink to this headline">¶</a></h3>
<p>Let’s load the trained parameters saved by the Trainer Extension snapshot, and perform an inference using the first test data as before.</p>
<p>One point to note here is that the npz file saved by snapshot is a snapshot of the entire Trainer, and the extension’s internal parameters etc. that are necessary for restarting learning are also saved together. However, since reading only the parameters of the network is fine this time, specify the path to the network part in the <code class="docutils literal notranslate"><span class="pre">path</span></code> argument of <code class="docutils literal notranslate"><span class="pre">serializers.load_npz()</span></code>. This allows objects in the network to read only the parameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">infer_net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">serializers</span><span class="o">.</span><span class="n">load_npz</span><span class="p">(</span>
    <span class="s1">&#39;results/mnist_result/snapshot_epoch-10&#39;</span><span class="p">,</span>
    <span class="n">infer_net</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s1">&#39;updater/model:main/predictor/&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">gpu_id</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">infer_net</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">gpu_id</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">infer_net</span><span class="o">.</span><span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
<span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">),</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;enable_backprop&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">infer_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_cpu</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">array</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Predicted label:&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-2-e24a2ad25092&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>reset_seed<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> infer_net <span class="ansi-blue-fg">=</span> MLP<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> serializers.load_npz(
<span class="ansi-green-intense-fg ansi-bold">      5</span>     <span class="ansi-blue-fg">&#39;results/mnist_result/snapshot_epoch-10&#39;</span><span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">NameError</span>: name &#39;reset_seed&#39; is not defined
</pre></div></div>
</div>
<p>We can see it predicted it correctly</p>
</div>
</div>
<div class="section" id="Use-of-new-network">
<h2>4.4. Use of new network<a class="headerlink" href="#Use-of-new-network" title="Permalink to this headline">¶</a></h2>
<p>Here, instead of using the MNIST data set, we will try to write various models ourselves and experience a trial-and-error flow, using a data set with one of 10 classes labeled with a small 32x32 color image called CIFAR10.</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 14%" />
<col style="width: 17%" />
<col style="width: 9%" />
<col style="width: 7%" />
<col style="width: 9%" />
<col style="width: 7%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 9%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>airplane</p></th>
<th class="head"><p>automobile</p></th>
<th class="head"><p>bird</p></th>
<th class="head"><p>cat</p></th>
<th class="head"><p>deer</p></th>
<th class="head"><p>dog</p></th>
<th class="head"><p>frog</p></th>
<th class="head"><p>horse</p></th>
<th class="head"><p>ship</p></th>
<th class="head"><p>truck</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="Airplane" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane4.png" /></p></td>
<td><p><img alt="Automobile" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile4.png" /></p></td>
<td><p><img alt="Bird" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird4.png" /></p></td>
<td><p><img alt="Cat" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat4.png" /></p></td>
<td><p><img alt="Deer" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer4.png" /></p></td>
<td><p><img alt="Dog" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog4.png" /></p></td>
<td><p><img alt="Frog" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog4.png" /></p></td>
<td><p><img alt="Horse" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse4.png" /></p></td>
<td><p><img alt="Ship" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship4.png" /></p></td>
<td><p><img alt="Truck" src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck4.png" /></p></td>
</tr>
</tbody>
</table>
<div class="section" id="Defining-new-network">
<h3>4.4.1. Defining new network<a class="headerlink" href="#Defining-new-network" title="Permalink to this headline">¶</a></h3>
<p>Here, let’s define the network with convolution layer introduced in the previous chapter, not the network consisting of only fully-connected layers we did earlier. It has three convolutional layers, followed by two fully coupled layers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">MyNet</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">Chain</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training">
<h3>4.4.2. Training<a class="headerlink" href="#Training" title="Permalink to this headline">¶</a></h3>
<p>Here, we will create a function <code class="docutils literal notranslate"><span class="pre">train</span></code> so that you can easily train other networks later with the same settings . It is a function, created with the following settings, that trains the network using the passed dataset internally using <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, and returns the network in the state where the training is complete.</p>
<ul class="simple">
<li><p>Network object</p></li>
<li><p>Batch size</p></li>
<li><p>GPU ID used</p></li>
<li><p>Number of epochs to complete</p></li>
<li><p>Dataset object</p></li>
<li><p>Initial learning rate</p></li>
<li><p>Timing of learning rate decay</p></li>
</ul>
<p>After completion of <code class="docutils literal notranslate"><span class="pre">Trainer.run()</span></code>, it will use the test dataset for evaluation. Unlike the example in the previous dataset MNIST, it uses the MomentumSGD as the optimization technique, <code class="docutils literal notranslate"><span class="pre">Extension</span></code> called <code class="docutils literal notranslate"><span class="pre">ExponentialShift</span></code> to attenuate the learning rate for each specified timing.</p>
<p>Also, in this case, 90% of the training data set returned by <code class="docutils literal notranslate"><span class="pre">cifar.get_cifar10()</span></code> is used for <code class="docutils literal notranslate"><span class="pre">train</span></code>, remaining 10% for <code class="docutils literal notranslate"><span class="pre">valid</span></code>.</p>
<p>Use this <code class="docutils literal notranslate"><span class="pre">train</span></code> function to train the model <code class="docutils literal notranslate"><span class="pre">MyModel</span></code> defined above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer.datasets</span> <span class="kn">import</span> <span class="n">cifar</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">network_object</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">gpu_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">test_dataset</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">postfix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">snapshot</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

    <span class="c1"># 1. Dataset</span>
    <span class="k">if</span> <span class="n">train_dataset</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">valid_dataset</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">test_dataset</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">cifar</span><span class="o">.</span><span class="n">get_cifar10</span><span class="p">()</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_val</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
        <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>

    <span class="c1"># 2. Iterator</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MultiprocessIterator</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
    <span class="n">valid_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MultiprocessIterator</span><span class="p">(</span><span class="n">valid</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

    <span class="c1"># 3. Model</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Classifier</span><span class="p">(</span><span class="n">network_object</span><span class="p">)</span>

    <span class="c1"># 4. Optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">MomentumSGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">base_lr</span><span class="p">)</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">add_hook</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">WeightDecay</span><span class="p">(</span><span class="mf">0.0005</span><span class="p">))</span>

    <span class="c1"># 5. Updater</span>
    <span class="n">updater</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">StandardUpdater</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">)</span>

    <span class="c1"># 6. Trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">updater</span><span class="p">,</span> <span class="p">(</span><span class="n">max_epoch</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="s1">&#39;results/{}_cifar10_{}result&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">network_object</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">postfix</span><span class="p">))</span>

    <span class="c1"># 7. Trainer extensions</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">LogReport</span><span class="p">())</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">observe_lr</span><span class="p">())</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">snapshot</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;snapshot_epoch_{.updater.epoch}&#39;</span><span class="p">),</span> <span class="n">trigger</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">Evaluator</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PrintReport</span><span class="p">([</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;elapsed_time&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">]))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PlotReport</span><span class="p">([</span><span class="s1">&#39;main/loss&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/loss&#39;</span><span class="p">],</span> <span class="n">x_key</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;loss.png&#39;</span><span class="p">))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">PlotReport</span><span class="p">([</span><span class="s1">&#39;main/accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;val/main/accuracy&#39;</span><span class="p">],</span> <span class="n">x_key</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;accuracy.png&#39;</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">lr_decay</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">extensions</span><span class="o">.</span><span class="n">ExponentialShift</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">trigger</span><span class="o">=</span><span class="n">lr_decay</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">snapshot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">chainer</span><span class="o">.</span><span class="n">serializers</span><span class="o">.</span><span class="n">load_npz</span><span class="p">(</span><span class="n">snapshot</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="k">del</span> <span class="n">trainer</span>

    <span class="c1"># 8. Evaluation</span>
    <span class="n">test_iter</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MultiprocessIterator</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="n">test_evaluator</span> <span class="o">=</span> <span class="n">extensions</span><span class="o">.</span><span class="n">Evaluator</span><span class="p">(</span><span class="n">test_iter</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu_id</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">test_evaluator</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;main/accuracy&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">net</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">net</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">MyNet</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">gpu_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Downloading from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz...
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr
1           1.92585     0.305797       1.72163        0.396484           7.3936        0.01
2           1.60847     0.422763       1.5302         0.460547           14.2303       0.01
3           1.47251     0.469529       1.4811         0.477148           21.6122       0.01
4           1.39214     0.500067       1.38733        0.501562           28.7671       0.01
5           1.32752     0.526019       1.37848        0.508789           35.8871       0.01
6           1.26747     0.548118       1.35386        0.518555           42.9225       0.01
7           1.21334     0.568176       1.25658        0.563281           49.9933       0.01
8           1.16389     0.584029       1.2344         0.566406           57.0437       0.01
9           1.12069     0.601873       1.23561        0.566016           63.9649       0.01
10          1.07164     0.618122       1.22468        0.558008           71.202        0.01
11          1.02903     0.636319       1.18382        0.579883           78.7195       0.01
12          0.981194    0.651821       1.19487        0.583398           85.8101       0.01
13          0.9353      0.668879       1.15842        0.599609           92.8278       0.01
14          0.901667    0.680533       1.20374        0.583203           99.7852       0.01
15          0.853855    0.697621       1.19961        0.59082            106.747       0.01
16          0.809625    0.713987       1.1916         0.594141           113.789       0.01
17          0.765904    0.73109        1.20508        0.598047           120.85        0.01
18          0.722185    0.744074       1.23998        0.579883           127.871       0.01
19          0.669985    0.764579       1.22414        0.597461           135           0.01
20          0.620186    0.782338       1.2336         0.597461           141.864       0.01
Test accuracy: 0.610265
</pre></div></div>
</div>
<p>The learning is over to 20 epochs. Let’s look at the plot of loss and accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/MyNet_cifar10_result/loss.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_97_0.png" src="../_images/notebooks_Introduction_to_Chainer_97_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/MyNet_cifar10_result/accuracy.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_98_0.png" src="../_images/notebooks_Introduction_to_Chainer_98_0.png" />
</div>
</div>
<p>The accuracy (<code class="docutils literal notranslate"><span class="pre">main/accuracy</span></code>) with the training data has reached about 77%, but the loss (<code class="docutils literal notranslate"><span class="pre">val/main/loss</span></code>) with the test data has stopped descending midway, and the accuracy (<code class="docutils literal notranslate"><span class="pre">val/main/accuracy</span></code>) has also plateaued at around 60%. If you check the last line of the displayed log, the accuracy with the test data is also about 60%. If the training data is accurate, but the test data is not accurate, it is considered that <strong>the model is overfitting to the training data</strong>.</p>
</div>
<div class="section" id="Prediction-using-the-trained-network">
<h3>4.4.3. Prediction using the trained network<a class="headerlink" href="#Prediction-using-the-trained-network" title="Permalink to this headline">¶</a></h3>
<p>Although the test accuracy was about 60%, let’s classify some test images using this learned network as a test. We create a <code class="docutils literal notranslate"><span class="pre">predict</span></code> function to be reused later.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cls_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span>
             <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">image_id</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">cifar</span><span class="o">.</span><span class="n">get_cifar10</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">),</span> <span class="n">chainer</span><span class="o">.</span><span class="n">using_config</span><span class="p">(</span><span class="s1">&#39;enable_backprop&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;predicted_label:&#39;</span><span class="p">,</span> <span class="n">cls_names</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;answer:&#39;</span><span class="p">,</span> <span class="n">cls_names</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="n">predict</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_101_0.png" src="../_images/notebooks_Introduction_to_Chainer_101_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted_label: airplane
answer: airplane
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_101_2.png" src="../_images/notebooks_Introduction_to_Chainer_101_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted_label: truck
answer: truck
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_101_4.png" src="../_images/notebooks_Introduction_to_Chainer_101_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted_label: dog
answer: dog
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_101_6.png" src="../_images/notebooks_Introduction_to_Chainer_101_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted_label: horse
answer: horse
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_101_8.png" src="../_images/notebooks_Introduction_to_Chainer_101_8.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
predicted_label: truck
answer: truck
</pre></div></div>
</div>
<p>Some were well classified and others were not. Although it is able to classify images 100% correctly with the data set used to learn the network, it is meaningless unless accurate prediction can be made on the unseen data, whhich is the images of the test dataset. Accuracy in test data is said to be related to the <strong>generalization performance of the model</strong>.</p>
<p>How can we design and traing a network with high generalization performance? This is a very difficult question, but it is one of the most important questions when considering applications using machine learning.</p>
</div>
<div class="section" id="Defining-deep-network">
<h3>4.4.4. Defining deep network<a class="headerlink" href="#Defining-deep-network" title="Permalink to this headline">¶</a></h3>
<p>Now let’s define a network with more layers than the previous one. Here, we define <code class="docutils literal notranslate"><span class="pre">ConvBlockwe</span></code> as a one-layer convolutional network, <code class="docutils literal notranslate"><span class="pre">LinearBlock</span></code> as a one-layer fully-connected network, and try to define a large network by stacking many of them.</p>
<div class="section" id="Defining-the-components">
<h4>4.4.4.1. Defining the components<a class="headerlink" href="#Defining-the-components" title="Permalink to this headline">¶</a></h4>
<p>First of all, let’s define the components of the network, <code class="docutils literal notranslate"><span class="pre">ConvBlock</span></code> and <code class="docutils literal notranslate"><span class="pre">LinearBlock</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">ConvBlock</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">Chain</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_ch</span><span class="p">,</span> <span class="n">pool_drop</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">chainer</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">HeNormal</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nobias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">initialW</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">n_ch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool_drop</span> <span class="o">=</span> <span class="n">pool_drop</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_drop</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pooling_2d</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>

<span class="k">class</span> <span class="nc">LinearBlock</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">Chain</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">chainer</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">HeNormal</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">initialW</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">drop</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ConvBlock</span></code> is defined as a small network that inherits from <code class="docutils literal notranslate"><span class="pre">Chain</span></code> and consists of one convolutional layer and Batch Normalization layer. The Batch Normalization layer is one of the widely used methods to stabilize the training process of the network, and is used by inserting it immediately after the convolution layer, as in this example. In the method <code class="docutils literal notranslate"><span class="pre">forward</span></code>, while passing data, apply the activation function ReLU, and in addition, if <code class="docutils literal notranslate"><span class="pre">pool_drop</span></code> argument is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>,
calculation of ordered propagation such as application of Max Pooling and Dropout is performed. Dropout is one of the methods used to improve the generalization performance by avoiding over-fitting of the network, and training is performed while randomly invalidating at fixed ratio (called dropout ratio) of nodes in the layer. (To disable, <code class="docutils literal notranslate"><span class="pre">ratio</span></code> argument can be used. 50% will be disabled if nothing is specified). For inference, if you set dropout ratio to <span class="math notranslate nohighlight">\(p\)</span>, layer works as a layer
that only multiply input by <span class="math notranslate nohighlight">\(p\)</span> and outputs it. This is said to have the effect of averaging training results of multiple networks in an artificial manner (see: <a class="reference external" href="https://en.wikipedia.org/wiki/Ensemble_averaging_(machine_learning)">Ensemble averaging</a>), and generalization performance may be improved. A technique to improve the generalization performance by giving some constraints to the model parameters during optimization is called regularization, and weight decay prevents this Dropout
and the absolute value of the parameters from becoming too large.</p>
<p>In Chainer, the code for forward calculation written using Python itself represents the structure of the network. That is, the network itself is defined by which layer the data passed at runtime. This property makes it possible to easily describe networks including the above branches, etc., and enables flexible, simple and highly readable network definition. This is a major feature of <strong>Define-by-Run</strong>.</p>
</div>
<div class="section" id="Defining-large-network">
<h4>4.4.4.2. Defining large network<a class="headerlink" href="#Defining-large-network" title="Permalink to this headline">¶</a></h4>
<p>Next, let’s build up these small networks as components and define a large network.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">DeepCNN</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">ChainList</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DeepCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="bp">True</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="bp">True</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="bp">True</span><span class="p">),</span>
            <span class="n">LinearBlock</span><span class="p">(),</span>
            <span class="n">LinearBlock</span><span class="p">(),</span>
            <span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_output</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>Here, the class <code class="docutils literal notranslate"><span class="pre">ChainList</span></code> is used. This class is a class that inherits from <code class="docutils literal notranslate"><span class="pre">Chain</span></code>, is useful when defining a network that calls a number of <code class="docutils literal notranslate"><span class="pre">Link</span></code> and/or <code class="docutils literal notranslate"><span class="pre">Chain</span></code> one after another. A model defined by inheriting from <code class="docutils literal notranslate"><span class="pre">ChainList</span></code> can be passed as an ordinary argument <code class="docutils literal notranslate"><span class="pre">Link</span></code> or a <code class="docutils literal notranslate"><span class="pre">Chain</span></code> object instead of a keyword argument when calling the constructor of the parent class, and can be extracted <strong>in the order registration</strong> by the <code class="docutils literal notranslate"><span class="pre">self.children()</span></code> method. Using this feature,
forward calculations can be easily described as above.</p>
<p>Let’s run the training. Since the number of parameters is large this time, the number of epochs to stop training is set to 100. Also, we set the learning rate to start from 0.1 and to be reduced to 1/10 every 30 epochs.</p>
</div>
<div class="section" id="Tips-for-speeding-up">
<h4>4.4.4.3. Tips for speeding up<a class="headerlink" href="#Tips-for-speeding-up" title="Permalink to this headline">¶</a></h4>
<p>This time, we will use a large network with many convolution layers, so let’s activate the autotune feature of cuDNN, which is provided by Chainer. The way is simple, just execute the following two lines in advance. When enabled, cuDNN will automatically make runtime adjustments, such as selecting a fast convolution algorithm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">chainer</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_max_workspace_size</span><span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
<span class="n">chainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">autotune</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</div>
<p>Let’s start learning. Basically, you can fix the random seed by executing the following two lines, and you can train the model represented by the class <code class="docutils literal notranslate"><span class="pre">DeepCNN</span></code> that you defined on 100 epochs, but this takes 40 minutes or more, so this time we will load the weights previously trained up to 90 epochs, resume learning from the point at the 90th epoch, and will actually run the training here for the last 10 epochs.</p>
<p><strong>When learning from scratch:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">DeepCNN</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">max_epoch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_snapshot_epoch_90.npz

<span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">DeepCNN</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">max_epoch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">snapshot</span><span class="o">=</span><span class="s1">&#39;DeepCNN_cifar10_snapshot_epoch_90.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2019-03-01 05:02:34--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_snapshot_epoch_90.npz
Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112
Connecting to github.com (github.com)|192.30.253.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/4fcc1200-eeb7-11e8-8ca0-9095e5bca078?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T050234Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=fb98973babee987108b54426e32251b5541de0666a6c1a7ba3bc4a476ab0a852&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream [following]
--2019-03-01 05:02:34--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/4fcc1200-eeb7-11e8-8ca0-9095e5bca078?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T050234Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=fb98973babee987108b54426e32251b5541de0666a6c1a7ba3bc4a476ab0a852&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.97.131
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.97.131|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 56889445 (54M) [application/octet-stream]
Saving to: ‘DeepCNN_cifar10_snapshot_epoch_90.npz’

DeepCNN_cifar10_sna 100%[===================&gt;]  54.25M  75.9MB/s    in 0.7s

2019-03-01 05:02:35 (75.9 MB/s) - ‘DeepCNN_cifar10_snapshot_epoch_90.npz’ saved [56889445/56889445]

epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr
1           2.62849     0.144931       2.22525        0.15625            27.9748       0.1
2           2.11316     0.210804       1.97533        0.266406           54.5483       0.1
3           1.87483     0.289396       1.8026         0.320508           81.0827       0.1
4           1.74066     0.340443       1.74728        0.358203           107.7         0.1
5           1.58789     0.409411       1.63916        0.40332            134.235       0.1
6           1.38757     0.492831       1.22399        0.561719           161.093       0.1
7           1.2036      0.566128       1.32939        0.553906           187.55        0.1
8           1.07527     0.617077       1.17079        0.589648           214.184       0.1
9           0.964984    0.660711       0.950063       0.67207            240.817       0.1
10          0.895905    0.688056       0.972697       0.657031           267.372       0.1
11          0.828796    0.715043       0.944733       0.686914           297.779       0.1
12          0.784123    0.731793       0.960205       0.687305           324.312       0.1
13          0.742033    0.748291       0.858308       0.719727           351.032       0.1
14          0.692516    0.76627        0.811853       0.725195           377.591       0.1
15          0.65644     0.776256       0.692374       0.767578           404.23        0.1
16          0.650682    0.780738       0.796731       0.733008           430.797       0.1
17          0.610249    0.793435       0.632162       0.791406           457.467       0.1
18          0.591896    0.803667       0.791757       0.739453           484.04        0.1
19          0.578718    0.804465       1.04659        0.671484           510.602       0.1
20          0.554954    0.814431       0.8127         0.733594           537.247       0.1
21          0.549188    0.814236       0.654926       0.787109           567.567       0.1
22          0.535866    0.820446       0.640323       0.788672           594.214       0.1
23          0.527765    0.823028       0.958373       0.70957            620.761       0.1
24          0.512286    0.830056       0.793664       0.748633           647.363       0.1
25          0.497195    0.833141       0.717548       0.759961           673.951       0.1
26          0.495153    0.835759       1.7557         0.511328           700.494       0.1
27          0.486062    0.837069       0.732518       0.775391           727.13        0.1
28          0.47963     0.839387       0.669157       0.786328           753.692       0.1
29          0.475502    0.838312       0.915904       0.718555           780.308       0.1
30          0.460236    0.844841       0.877713       0.72793            806.806       0.1
31          0.298483    0.897239       0.381921       0.879687           837.16        0.01
32          0.211182    0.92784        0.364046       0.882617           863.898       0.01
33          0.180429    0.937478       0.374651       0.883984           890.554       0.01
34          0.164156    0.943692       0.361041       0.888867           917.199       0.01
35          0.144584    0.950387       0.375391       0.889258           943.774       0.01
36          0.132288    0.954235       0.377427       0.890625           970.4         0.01
37          0.12103     0.957376       0.390434       0.892578           996.96        0.01
38          0.111974    0.961204       0.400307       0.886133           1023.62       0.01
39          0.102573    0.964476       0.399275       0.892773           1050.2        0.01
40          0.0972647   0.965931       0.432854       0.887109           1076.83       0.01
41          0.0928545   0.966597       0.418165       0.887305           1107.19       0.01
42          0.08498     0.96964        0.432462       0.884961           1133.75       0.01
43          0.0845448   0.970792       0.4365         0.880273           1160.37       0.01
44          0.0770674   0.973914       0.441935       0.883789           1187.02       0.01
45          0.0732439   0.974565       0.469901       0.881836           1213.62       0.01
46          0.070491    0.975962       0.453856       0.8875             1240.16       0.01
47          0.068846    0.97583        0.461264       0.881055           1266.75       0.01
48          0.0694101   0.976941       0.435111       0.885742           1293.25       0.01
49          0.0653772   0.977117       0.461284       0.882617           1319.87       0.01
50          0.0633419   0.97836        0.464232       0.889648           1346.47       0.01
51          0.0584663   0.979834       0.464193       0.885547           1376.6        0.01
52          0.0607617   0.979714       0.466352       0.881445           1403.21       0.01
53          0.0615791   0.978632       0.451807       0.889453           1429.69       0.01
54          0.0588031   0.979914       0.489054       0.881836           1456.28       0.01
55          0.0582368   0.979367       0.4719         0.882617           1482.83       0.01
56          0.0558719   0.981379       0.495846       0.878125           1509.45       0.01
57          0.0579962   0.979936       0.472415       0.875781           1536.06       0.01
58          0.0592009   0.9793         0.454762       0.88418            1562.6        0.01
59          0.0568546   0.980735       0.487556       0.876172           1589.17       0.01
60          0.0579785   0.980079       0.472908       0.883398           1615.93       0.01
61          0.0318918   0.98968        0.416953       0.895703           1646.15       0.001
62          0.0220127   0.993612       0.416859       0.899609           1672.69       0.001
63          0.0186169   0.99434        0.417849       0.898242           1699.29       0.001
64          0.0159041   0.995526       0.41804        0.900781           1725.78       0.001
65          0.0147089   0.995916       0.429896       0.899609           1752.39       0.001
66          0.0129457   0.996404       0.433748       0.898828           1779.01       0.001
67          0.0131643   0.996283       0.433923       0.898828           1805.54       0.001
68          0.0112659   0.996893       0.437222       0.901758           1832.17       0.001
69          0.0106502   0.997151       0.443475       0.901758           1858.73       0.001
70          0.0107926   0.997203       0.445066       0.900391           1885.34       0.001
71          0.0105973   0.997062       0.44159        0.898633           1915.8        0.001
72          0.00934292  0.99767        0.450084       0.897266           1942.45       0.001
73          0.0104884   0.997092       0.451691       0.899023           1969.06       0.001
74          0.00849317  0.997707       0.450391       0.9                1995.61       0.001
75          0.00846932  0.997891       0.451362       0.902148           2022.21       0.001
76          0.00826699  0.997841       0.448779       0.900781           2048.69       0.001
77          0.00875069  0.997492       0.45095        0.900391           2075.31       0.001
78          0.00823296  0.998019       0.449194       0.898438           2102.1        0.001
79          0.00701245  0.998113       0.454196       0.899609           2128.74       0.001
80          0.00846517  0.997596       0.455877       0.901172           2155.29       0.001
81          0.00677115  0.99818        0.459518       0.899805           2185.54       0.001
82          0.00717393  0.998047       0.465337       0.899805           2212.13       0.001
83          0.00709802  0.997908       0.464472       0.898828           2238.69       0.001
84          0.00699702  0.998091       0.470595       0.899219           2265.27       0.001
85          0.00746627  0.997975       0.470063       0.901172           2291.78       0.001
86          0.00666763  0.998069       0.466201       0.899414           2318.38       0.001
87          0.00616266  0.998531       0.462948       0.9                2344.86       0.001
88          0.00719447  0.997847       0.463587       0.899609           2371.48       0.001
89          0.00638493  0.998335       0.465655       0.901367           2398.08       0.001
90          0.0061445   0.998286       0.464918       0.900586           2424.59       0.001
91          0.00582547  0.99838        0.46484        0.900977           2453.48       0.0001
92          0.00602775  0.998331       0.461773       0.901367           2480.1        0.0001
93          0.00597373  0.998491       0.464172       0.900195           2506.88       0.0001
94          0.00619669  0.99813        0.464461       0.900391           2533.49       0.0001
95          0.0054557   0.998557       0.466652       0.900977           2560.12       0.0001
96          0.0061331   0.998308       0.465332       0.900781           2586.61       0.0001
97          0.00541795  0.998624       0.465642       0.900586           2613.27       0.0001
98          0.00512301  0.998801       0.467119       0.900781           2639.95       0.0001
99          0.00562213  0.998576       0.464967       0.901367           2666.67       0.0001
100         0.00551732  0.998624       0.462727       0.901367           2693.44       0.0001
Test accuracy: 0.8966574
</pre></div></div>
</div>
<p>Training is finished. Let’s look at the graphis of learning curve and the accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/DeepCNN_cifar10_result/loss.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_116_0.png" src="../_images/notebooks_Introduction_to_Chainer_116_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/DeepCNN_cifar10_result/accuracy.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_117_0.png" src="../_images/notebooks_Introduction_to_Chainer_117_0.png" />
</div>
</div>
<p>The accuracy of the Validation data, which was around 60% using the shallow (low number of layers) CNN, increased to around 90%. Also, the accuracy using test data is about 90% (comapared to ~60% previously). The training accuracy results are also 97% (compared to ~77% previously). In order to further improve the accuracy, one can not only improve the network structure itself but also artificially increase training data (Data augmentation) and/or combine the outputs of multiple models into one
output such as (Ensemble).</p>
</div>
</div>
</div>
<div class="section" id="Using-Dataset-Class">
<h2>4.5. Using Dataset Class<a class="headerlink" href="#Using-Dataset-Class" title="Permalink to this headline">¶</a></h2>
<p>Here, let’s write the data set class by using the function to acquire CIFAR10 data already provided by Chainer. In Chainer, a class representing a dataset needs to have the following functions.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__len__</span></code> that returns the number of data points in the dataset</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_example</span></code> method that returns data or data / label pairs corresponding to <code class="docutils literal notranslate"><span class="pre">i</span></code> passed as an argument.</p></li>
</ul>
<p>The functions required for other datasets can be prepared by inheriting <code class="docutils literal notranslate"><span class="pre">chainer.dataset.DatasetMixin</span></code> class. Here, let’s create a dataset class, by inheriting the class <code class="docutils literal notranslate"><span class="pre">DatasetMixin</span></code>, that has a Data augmentation function which converts the training data during the training to increase the variation of data which are received by the model.</p>
<div class="section" id="CIFAR10-Dataset-Class">
<h3>4.5.1. CIFAR10 Dataset Class<a class="headerlink" href="#CIFAR10-Dataset-Class" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">CIFAR10Augmented</span><span class="p">(</span><span class="n">chainer</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">DatasetMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">train_ratio</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="n">train_val</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cifar</span><span class="o">.</span><span class="n">get_cifar10</span><span class="p">()</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_val</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)</span>
        <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="k">elif</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;valid&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">valid_data</span>
        <span class="k">elif</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">test_data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;split&#39; argument should be either &#39;train&#39;, &#39;valid&#39;, or &#39;test&#39;. But {} was given.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">split</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_crop</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_example</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">x_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_crop</span><span class="p">)</span>
            <span class="n">y_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_crop</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">y_offset</span><span class="p">:</span><span class="n">y_offset</span> <span class="o">+</span> <span class="n">h</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_crop</span><span class="p">,</span>
                  <span class="n">x_offset</span><span class="p">:</span><span class="n">x_offset</span> <span class="o">+</span> <span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_crop</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-2-2250fe68d370&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">class</span> CIFAR10Augmented<span class="ansi-blue-fg">(</span>chainer<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">.</span>DatasetMixin<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>     <span class="ansi-green-fg">def</span> __init__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> split<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;train&#39;</span><span class="ansi-blue-fg">,</span> train_ratio<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.9</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>         train_val<span class="ansi-blue-fg">,</span> test_data <span class="ansi-blue-fg">=</span> cifar<span class="ansi-blue-fg">.</span>get_cifar10<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>         train_size <span class="ansi-blue-fg">=</span> int<span class="ansi-blue-fg">(</span>len<span class="ansi-blue-fg">(</span>train_val<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">*</span> train_ratio<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;chainer&#39; is not defined
</pre></div></div>
</div>
<p>This class does the following conversion for each of the CIFAR10 data.</p>
<ul class="simple">
<li><p>Crop 28x28 area randomly from 32x32 size</p></li>
<li><p>Flip the image horizontally at a probability of 1/2</p></li>
</ul>
<p>It is known that adding such operations and artificially increasing the variation of training data contributes to the reduction of overfitting. Besides these operations, various ideas have been proposed to artificially increase the number of training data such as conversion that changes the color of an image, random rotation, and affine conversion.</p>
</div>
<div class="section" id="Training-using-created-dataset">
<h3>4.5.2. Training using created dataset<a class="headerlink" href="#Training-using-created-dataset" title="Permalink to this headline">¶</a></h3>
<p>Let’s use this <code class="docutils literal notranslate"><span class="pre">CIFAR10</span></code> class for traing now. Let’s use the same network as before and find out how effective the data augmentation is. Except for the dataset class, including <code class="docutils literal notranslate"><span class="pre">train</span></code> functions, everything is the same as before.</p>
<p>Again, it would take about 40 minutes, so let’s download and load the snapshot that has been trained with up to 90 epochs as above, and let’s actually train the model only for the last 10 epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_augmented_snapshot_epoch_90.npz

<span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">DeepCNN</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">max_epoch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">CIFAR10Augmented</span><span class="p">(),</span> <span class="n">valid_dataset</span><span class="o">=</span><span class="n">CIFAR10Augmented</span><span class="p">(</span><span class="s1">&#39;valid&#39;</span><span class="p">),</span> <span class="n">test_dataset</span><span class="o">=</span><span class="n">CIFAR10Augmented</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">postfix</span><span class="o">=</span><span class="s1">&#39;augmented_&#39;</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">snapshot</span><span class="o">=</span><span class="s1">&#39;DeepCNN_cifar10_augmented_snapshot_epoch_90.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2019-03-01 05:07:14--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_augmented_snapshot_epoch_90.npz
Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113
Connecting to github.com (github.com)|192.30.253.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/5064a880-eeb7-11e8-95bf-80b5d9533256?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T050714Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=744aa53cbf9b34edc8a35fd65be24578b4cc00399a3382452d09082d34504194&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_augmented_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream [following]
--2019-03-01 05:07:14--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/5064a880-eeb7-11e8-95bf-80b5d9533256?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T050714Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=744aa53cbf9b34edc8a35fd65be24578b4cc00399a3382452d09082d34504194&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_augmented_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.237.155
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.237.155|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 56730280 (54M) [application/octet-stream]
Saving to: ‘DeepCNN_cifar10_augmented_snapshot_epoch_90.npz’

DeepCNN_cifar10_aug 100%[===================&gt;]  54.10M  21.5MB/s    in 2.5s

2019-03-01 05:07:17 (21.5 MB/s) - ‘DeepCNN_cifar10_augmented_snapshot_epoch_90.npz’ saved [56730280/56730280]

epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr
1           2.5875      0.156405       2.11656        0.203125           24.1767       0.1
2           1.99359     0.233842       1.84577        0.304492           47.9466       0.1
3           1.76968     0.325365       1.98983        0.26543            71.6864       0.1
4           1.61662     0.389537       2.07369        0.26875            95.5072       0.1
5           1.41259     0.478989       1.52089        0.446484           119.236       0.1
6           1.23382     0.555487       1.48775        0.480664           143.06        0.1
7           1.09323     0.613404       1.11949        0.590234           166.813       0.1
8           0.99303     0.650857       1.33017        0.566992           190.624       0.1
9           0.926848    0.678755       1.0075         0.665234           214.446       0.1
10          0.863165    0.702769       0.858035       0.717383           238.218       0.1
11          0.807948    0.727162       0.9556         0.679297           265.757       0.1
12          0.769224    0.739116       0.857765       0.711328           289.507       0.1
13          0.739977    0.752952       0.91583        0.711133           313.339       0.1
14          0.72064     0.759393       1.20587        0.61875            337.097       0.1
15          0.690136    0.77093        0.837919       0.726562           360.905       0.1
16          0.673935    0.774706       1.03539        0.678711           384.67        0.1
17          0.662879    0.778742       0.730712       0.758789           408.47        0.1
18          0.639202    0.78742        0.758566       0.765625           432.298       0.1
19          0.625988    0.792713       1.24791        0.664062           456.061       0.1
20          0.616269    0.795277       0.963706       0.70625            479.882       0.1
21          0.611734    0.795962       0.887129       0.723437           507.312       0.1
22          0.600444    0.800582       0.889526       0.710352           531.173       0.1
23          0.605317    0.800414       0.715702       0.756445           554.926       0.1
24          0.584194    0.805731       0.984225       0.694336           578.687       0.1
25          0.584041    0.805464       0.956576       0.685156           602.49        0.1
26          0.57384     0.80954        0.977559       0.712695           627.031       0.1
27          0.560405    0.814298       0.894127       0.718945           650.845       0.1
28          0.559933    0.816195       0.729981       0.752734           674.584       0.1
29          0.555933    0.814387       0.841304       0.727344           698.4         0.1
30          0.558057    0.814971       0.753542       0.757227           722.119       0.1
31          0.397613    0.866455       0.337977       0.888867           749.619       0.01
32          0.320024    0.890202       0.322082       0.894336           773.368       0.01
33          0.293655    0.900479       0.323365       0.888867           797.169       0.01
34          0.279553    0.904874       0.308263       0.897656           820.951       0.01
35          0.26519     0.909945       0.301763       0.897852           844.682       0.01
36          0.259166    0.909846       0.286909       0.904688           868.482       0.01
37          0.246168    0.915064       0.289997       0.904688           892.324       0.01
38          0.24097     0.91697        0.280986       0.903906           916.139       0.01
39          0.233951    0.918892       0.291962       0.904102           939.884       0.01
40          0.220939    0.923628       0.299502       0.902539           963.666       0.01
41          0.216055    0.924272       0.2946         0.905664           991.125       0.01
42          0.215143    0.926972       0.308637       0.897266           1014.88       0.01
43          0.213903    0.926625       0.291742       0.907812           1038.64       0.01
44          0.203283    0.929198       0.296043       0.905469           1062.33       0.01
45          0.19772     0.931041       0.327708       0.89375            1086.11       0.01
46          0.194907    0.932893       0.312555       0.901563           1109.82       0.01
47          0.190354    0.934326       0.336271       0.895703           1133.58       0.01
48          0.190431    0.932915       0.326305       0.902539           1157.3        0.01
49          0.18926     0.934326       0.312767       0.901172           1181.05       0.01
50          0.184469    0.936035       0.296937       0.907812           1204.93       0.01
51          0.181691    0.936521       0.324149       0.901172           1232.22       0.01
52          0.17546     0.939675       0.347524       0.893945           1256          0.01
53          0.175786    0.937723       0.335627       0.893164           1279.74       0.01
54          0.173612    0.940274       0.317897       0.902344           1303.52       0.01
55          0.171849    0.939548       0.306998       0.90625            1327.23       0.01
56          0.168304    0.94165        0.31145        0.902148           1351.04       0.01
57          0.170139    0.941495       0.301311       0.910156           1374.82       0.01
58          0.165011    0.942708       0.359516       0.892773           1398.52       0.01
59          0.163968    0.94256        0.365818       0.886133           1422.3        0.01
60          0.16541     0.942575       0.357          0.890234           1446.01       0.01
61          0.129435    0.955988       0.277052       0.915234           1473.42       0.001
62          0.101981    0.965434       0.284798       0.916406           1497.13       0.001
63          0.0953637   0.967285       0.279956       0.919727           1520.93       0.001
64          0.0911066   0.968171       0.28204        0.918359           1544.63       0.001
65          0.0853851   0.97037        0.28504        0.918945           1568.41       0.001
66          0.0800331   0.972101       0.287688       0.917969           1592.21       0.001
67          0.0761374   0.973202       0.29148        0.920117           1616.19       0.001
68          0.0756613   0.973699       0.299635       0.918945           1639.98       0.001
69          0.075577    0.97407        0.293845       0.918359           1663.68       0.001
70          0.0730666   0.974676       0.29563        0.920508           1687.47       0.001
71          0.070825    0.975516       0.295581       0.920313           1714.73       0.001
72          0.0710753   0.975697       0.29838        0.919336           1738.52       0.001
73          0.0705982   0.975142       0.298369       0.920508           1762.3        0.001
74          0.0667571   0.976562       0.299809       0.920508           1786.01       0.001
75          0.0642319   0.978427       0.300881       0.920898           1809.77       0.001
76          0.0640179   0.977742       0.304647       0.918359           1833.51       0.001
77          0.0629752   0.977761       0.299763       0.919336           1857.31       0.001
78          0.0586612   0.979523       0.306034       0.922461           1881.03       0.001
79          0.059752    0.979869       0.311227       0.921289           1904.82       0.001
80          0.0571715   0.980213       0.304607       0.920703           1928.51       0.001
81          0.0573339   0.980136       0.315108       0.92168            1956.06       0.001
82          0.0560348   0.979847       0.321934       0.916992           1979.87       0.001
83          0.0553193   0.980613       0.315378       0.914648           2003.58       0.001
84          0.0531816   0.98129        0.318977       0.919531           2027.34       0.001
85          0.0560367   0.98097        0.310993       0.919141           2051.02       0.001
86          0.0535048   0.981534       0.317829       0.920117           2075.04       0.001
87          0.0522188   0.981571       0.31144        0.920313           2098.73       0.001
88          0.0526632   0.982156       0.318594       0.920703           2122.46       0.001
89          0.0528096   0.981445       0.309017       0.92207            2146.21       0.001
90          0.0499371   0.982928       0.313269       0.920508           2169.92       0.001
91          0.0454926   0.984797       0.313569       0.919141           2195.11       0.0001
92          0.0448548   0.984375       0.308275       0.921289           2218.89       0.0001
93          0.0444652   0.98473        0.309395       0.921094           2242.73       0.0001
94          0.0438955   0.984687       0.310709       0.92168            2266.55       0.0001
95          0.0448537   0.984486       0.310669       0.920313           2290.63       0.0001
96          0.0446187   0.984731       0.311206       0.921289           2314.31       0.0001
97          0.0454414   0.984553       0.311353       0.921484           2338.06       0.0001
98          0.0435442   0.985019       0.309628       0.920117           2361.82       0.0001
99          0.0427361   0.985777       0.309663       0.921875           2385.53       0.0001
100         0.0407838   0.986084       0.314156       0.920313           2409.44       0.0001
Test accuracy: 0.91702926
</pre></div></div>
</div>
<p>We found that the test accuracy, which was about 90% without the data augmentation, has been improved by about 1.8% using augmenting the training data.</p>
<p>Let’s look at the loss and accuracy graphs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/DeepCNN_cifar10_augmented_result/loss.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_126_0.png" src="../_images/notebooks_Introduction_to_Chainer_126_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;results/DeepCNN_cifar10_augmented_result/accuracy.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_Chainer_127_0.png" src="../_images/notebooks_Introduction_to_Chainer_127_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Simple-way-to-use-Data-Augmentation">
<h2>4.6. Simple way to use Data Augmentation<a class="headerlink" href="#Simple-way-to-use-Data-Augmentation" title="Permalink to this headline">¶</a></h2>
<p>An operation that performs various transformations on each image in a dataset as described above to artificially increase the number of data points is called Data Augmentation. In the above section, we implemented transformation operations written inside <code class="docutils literal notranslate"><span class="pre">get_example()</span></code> in order to show how to create the original dataset class, but there is actually a way to perform various transformations on data more easily.</p>
<p>That is to use <code class="docutils literal notranslate"><span class="pre">TransformDataset</span></code> class. <code class="docutils literal notranslate"><span class="pre">TransformDataset</span></code> is a useful class that takes a source dataset object and a function that does what you want to perform on each data point sampled from the source dataset, and returns transformed data. A simple usage is shown below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">chainer.datasets</span> <span class="kn">import</span> <span class="n">TransformDataset</span>

<span class="n">train_val</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">cifar</span><span class="o">.</span><span class="n">get_cifar10</span><span class="p">()</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_val</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># Write how you want to transform data in the form of function</span>
<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">x_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">y_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">y_offset</span><span class="p">:</span><span class="n">y_offset</span> <span class="o">+</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">4</span><span class="p">,</span>
          <span class="n">x_offset</span><span class="p">:</span><span class="n">x_offset</span> <span class="o">+</span> <span class="n">w</span> <span class="o">-</span> <span class="mi">4</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span>


<span class="c1"># Dataset object that returns data processed with transform function</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TransformDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The new <code class="docutils literal notranslate"><span class="pre">train_dataset</span></code> obtained in this way is a dataset object that returns data after conversion processing similar to that of a custom-made dataset class.</p>
<div class="section" id="Conversion-Processing-utilizing-ChainerCV">
<h3>4.6.1. Conversion Processing utilizing ChainerCV<a class="headerlink" href="#Conversion-Processing-utilizing-ChainerCV" title="Permalink to this headline">¶</a></h3>
<p>Now, in the code introduced earlier, we implemented the process of random cropping and random flipping on the image. In order to carry out more transformations, we can add processing to the above <code class="docutils literal notranslate"><span class="pre">transform</span></code> function, but it is time-consuming to implement commonly used transformation processing each time. In this section, we will introduce <a class="reference external" href="http://chainercv.readthedocs.io/en/stable">Chainer CV</a> [<a class="reference external" href="https://arxiv.org/abs/1708.08169">Niitani 2017</a>]. ChainerCV is an open source software that
plays a role as an auxiliary package of Chainer, with a wealth of specialized functions in Computer Vision.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install chainercv
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Collecting chainercv
  Downloading https://files.pythonhosted.org/packages/e0/b9/02d9eb0ff60db1b9e5ffb1d89f8ee26764784a0f9f37a7342cb665e8de38/chainercv-0.12.0.tar.gz (239kB)
    100% |████████████████████████████████| 245kB 8.0MB/s
Requirement already satisfied: chainer&gt;=5.0 in /usr/local/lib/python3.6/dist-packages (from chainercv) (5.0.0)
Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from chainercv) (4.0.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer&gt;=5.0-&gt;chainercv) (3.0.10)
Requirement already satisfied: numpy&gt;=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer&gt;=5.0-&gt;chainercv) (1.14.6)
Requirement already satisfied: protobuf&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer&gt;=5.0-&gt;chainercv) (3.6.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer&gt;=5.0-&gt;chainercv) (1.11.0)
Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow-&gt;chainercv) (0.46)
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.0.0-&gt;chainer&gt;=5.0-&gt;chainercv) (40.8.0)
Building wheels for collected packages: chainercv
  Building wheel for chainercv (setup.py) ... done
  Stored in directory: /root/.cache/pip/wheels/48/34/47/ace83b5217d8cd49bd017951c776588fd4a7d8a1bf8817141a
Successfully built chainercv
Installing collected packages: chainercv
Successfully installed chainercv-0.12.0
</pre></div></div>
</div>
<p><a class="reference external" href="http://chainercv.readthedocs.io/en/stable">ChainerCV</a> comes with various transformations for images．</p>
<ul class="simple">
<li><p><a class="reference external" href="http://chainercv.readthedocs.io/en/stable/reference/transforms.html#image">List of image conversions available in ChainerCV</a></p></li>
</ul>
<p>For example, random cropping and random left / right flipping, which were written using NumPy above, can be written in one line as follows using modules <code class="docutils literal notranslate"><span class="pre">chainercv.transforms</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>  <span class="c1"># Random crop</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">chainercv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">random_flip</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Random flip</span>
</pre></div>
</div>
<p>Lets update <code class="docutils literal notranslate"><span class="pre">transform</span></code> function using <code class="docutils literal notranslate"><span class="pre">chainercv.transforms</span></code>. By the way, in the dataset obtained by <code class="docutils literal notranslate"><span class="pre">get_cifar10()</span></code>, the range of pixel values of the image is scaled to <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code> by default. We can keep the same range as <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">255]</span></code> by passing <code class="docutils literal notranslate"><span class="pre">scale=255.</span></code> to <code class="docutils literal notranslate"><span class="pre">get_cifar10()</span></code>. The following five processes are performed here:</p>
<ol class="arabic simple">
<li><p>PCA lighting: Performs conversion processing to change colors in the method used for training in the previous research (AlexNet).</p></li>
<li><p>Standardization: Standardizes the mean and standard deviation of pixel values per channel from the entire training data set</p></li>
<li><p>Random flip: Randomly flip image horizontally</p></li>
<li><p>Random expand: Create a black canvas of a randomly determined size from <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1.5]</span></code> and place the image at a random location within it</p></li>
<li><p>Random crop: Randomuly crop the area with the size of <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28)</span></code></p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">chainercv</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">train_val</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">cifar</span><span class="o">.</span><span class="n">get_cifar10</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">255.</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_val</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">split_dataset_random</span><span class="p">(</span><span class="n">train_val</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># Color augmentation</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">pca_lighting</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mf">76.5</span><span class="p">)</span>

    <span class="c1"># Standardization</span>
    <span class="n">img</span> <span class="o">-=</span> <span class="n">mean</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">img</span> <span class="o">/=</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>

    <span class="c1"># Random flip &amp; crop</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">random_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">x_random</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">random_expand</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">max_ratio</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TransformDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">TransformDataset</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">TransformDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Let’s train the model using standardization and <code class="docutils literal notranslate"><span class="pre">TransformDataset</span></code> with PCA Lighting by Chainer CV.</p>
<p>As before, using the snapshot that has been trained up to 90 epochs, only the last 10 epochs are trained.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython2 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_augmented2_snapshot_epoch_90.npz

<span class="n">reset_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">DeepCNN</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">max_epoch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="o">=</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">postfix</span><span class="o">=</span><span class="s1">&#39;augmented2_&#39;</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">snapshot</span><span class="o">=</span><span class="s1">&#39;DeepCNN_cifar10_augmented2_snapshot_epoch_90.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2019-03-01 05:11:46--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/DeepCNN_cifar10_augmented2_snapshot_epoch_90.npz
Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113
Connecting to github.com (github.com)|192.30.253.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/5064a880-eeb7-11e8-8e8b-fddbe76ecd56?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T051146Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=4b1a98d2f1ff9902c4f33dd783aa737871f83399dafac87402f8f6cde804c803&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_augmented2_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream [following]
--2019-03-01 05:11:46--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/5064a880-eeb7-11e8-8e8b-fddbe76ecd56?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190301%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20190301T051146Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=4b1a98d2f1ff9902c4f33dd783aa737871f83399dafac87402f8f6cde804c803&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3DDeepCNN_cifar10_augmented2_snapshot_epoch_90.npz&amp;response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 54.231.41.19
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|54.231.41.19|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 56734002 (54M) [application/octet-stream]
Saving to: ‘DeepCNN_cifar10_augmented2_snapshot_epoch_90.npz’

DeepCNN_cifar10_aug 100%[===================&gt;]  54.11M  59.2MB/s    in 0.9s

2019-03-01 05:11:47 (59.2 MB/s) - ‘DeepCNN_cifar10_augmented2_snapshot_epoch_90.npz’ saved [56734002/56734002]

epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr
1           2.64248     0.137296       2.15132        0.175              23.5716       0.1
2           2.09025     0.202814       1.90949        0.248633           47.2547       0.1
3           1.92989     0.251647       1.80744        0.313867           70.8962       0.1
4           1.82033     0.296742       1.75358        0.319727           94.6262       0.1
5           1.70069     0.350717       1.59837        0.397266           118.252       0.1
6           1.56064     0.418435       1.6835         0.418359           141.967       0.1
7           1.45132     0.473691       1.30451        0.528711           165.613       0.1
8           1.33843     0.523815       2.81471        0.372656           189.382       0.1
9           1.27017     0.556019       1.61386        0.499023           213.846       0.1
10          1.20204     0.579972       1.46257        0.519141           237.532       0.1
11          1.14896     0.601252       1.1028         0.623633           265.125       0.1
12          1.10957     0.614428       1.17823        0.594141           288.775       0.1
13          1.07055     0.635387       1.00013        0.670898           312.476       0.1
14          1.04187     0.647058       1.07628        0.642383           336.226       0.1
15          1.00359     0.661066       1.00439        0.655859           360.038       0.1
16          0.971513    0.675503       0.8598         0.723828           383.802       0.1
17          0.941225    0.686301       1.09454        0.661328           407.665       0.1
18          0.917967    0.694869       0.998599       0.681055           431.468       0.1
19          0.905397    0.699586       0.811614       0.738281           455.224       0.1
20          0.874732    0.706188       0.714926       0.762695           479.061       0.1
21          0.86753     0.712607       0.850176       0.738477           506.629       0.1
22          0.858491    0.714844       0.95919        0.692187           530.459       0.1
23          0.845307    0.717637       1.12914        0.668164           554.185       0.1
24          0.827677    0.72785        0.827821       0.746484           577.974       0.1
25          0.821103    0.728715       0.7663         0.741602           601.76        0.1
26          0.816583    0.728321       0.763894       0.757812           625.472       0.1
27          0.805109    0.735596       0.74157        0.754492           649.375       0.1
28          0.809963    0.734152       0.742951       0.7625             673.099       0.1
29          0.792127    0.737149       0.692472       0.773633           696.895       0.1
30          0.783124    0.741965       1.02244        0.702734           720.621       0.1
31          0.604456    0.795898       0.394226       0.868359           748.179       0.01
32          0.523254    0.822227       0.379255       0.873242           771.92        0.01
33          0.502693    0.830078       0.360393       0.877734           795.747       0.01
34          0.484705    0.835627       0.351212       0.884766           819.578       0.01
35          0.465001    0.842192       0.348862       0.882031           843.291       0.01
36          0.45372     0.846613       0.339081       0.885742           867.053       0.01
37          0.450468    0.846043       0.335244       0.887695           890.763       0.01
38          0.439256    0.848411       0.331884       0.889453           914.524       0.01
39          0.430965    0.852475       0.324836       0.895312           938.351       0.01
40          0.424651    0.855447       0.370822       0.881641           962.135       0.01
41          0.418223    0.857          0.328078       0.89082            989.723       0.01
42          0.409156    0.860332       0.334291       0.888672           1013.41       0.01
43          0.410969    0.860574       0.338266       0.888281           1037.14       0.01
44          0.397083    0.862469       0.337938       0.889258           1060.81       0.01
45          0.390805    0.8661         0.31488        0.900586           1084.56       0.01
46          0.39124     0.866008       0.324671       0.893945           1108.24       0.01
47          0.390007    0.865101       0.320954       0.895117           1131.96       0.01
48          0.383439    0.868367       0.355809       0.890625           1155.62       0.01
49          0.380758    0.87065        0.314927       0.899805           1179.36       0.01
50          0.379198    0.870716       0.302073       0.903125           1203.09       0.01
51          0.371325    0.873019       0.317537       0.899805           1230.61       0.01
52          0.368561    0.874578       0.338393       0.891016           1254.34       0.01
53          0.366614    0.872975       0.318233       0.89707            1278.2        0.01
54          0.366082    0.874667       0.328654       0.892187           1301.94       0.01
55          0.365454    0.873331       0.311355       0.902148           1325.61       0.01
56          0.357191    0.876509       0.330824       0.895898           1349.36       0.01
57          0.361274    0.874667       0.320739       0.897461           1373.1        0.01
58          0.354885    0.878339       0.308104       0.901172           1396.78       0.01
59          0.359033    0.876931       0.316534       0.900586           1420.55       0.01
60          0.356422    0.876291       0.366406       0.888281           1444.25       0.01
61          0.314513    0.891513       0.261128       0.914062           1471.67       0.001
62          0.275813    0.905159       0.257487       0.916406           1495.37       0.001
63          0.268649    0.907804       0.253204       0.918164           1519.12       0.001
64          0.264412    0.908298       0.256485       0.918555           1542.84       0.001
65          0.261826    0.910511       0.253851       0.917773           1566.66       0.001
66          0.255704    0.911998       0.257955       0.916602           1590.48       0.001
67          0.25836     0.909566       0.256463       0.919141           1614.22       0.001
68          0.251792    0.912753       0.254393       0.920117           1638.04       0.001
69          0.251154    0.914508       0.25251        0.920508           1661.81       0.001
70          0.24735     0.91464        0.255754       0.91875            1685.83       0.001
71          0.241314    0.917268       0.253207       0.921094           1713.35       0.001
72          0.246059    0.914617       0.257668       0.920508           1737.18       0.001
73          0.238097    0.918213       0.257092       0.919727           1761.02       0.001
74          0.235832    0.918981       0.251519       0.919922           1784.77       0.001
75          0.236254    0.918857       0.253711       0.919531           1808.58       0.001
76          0.235273    0.917646       0.249922       0.920117           1832.36       0.001
77          0.233553    0.918635       0.251188       0.921094           1856.13       0.001
78          0.229216    0.920829       0.256883       0.921484           1879.92       0.001
79          0.231176    0.919877       0.254759       0.92207            1903.75       0.001
80          0.227571    0.921007       0.251693       0.920508           1927.51       0.001
81          0.229313    0.92041        0.257421       0.920508           1955.13       0.001
82          0.225018    0.922896       0.255896       0.919922           1978.98       0.001
83          0.223251    0.923478       0.25848        0.918555           2002.75       0.001
84          0.221238    0.924294       0.259179       0.920703           2026.56       0.001
85          0.222084    0.923411       0.251648       0.920313           2050.3        0.001
86          0.221973    0.924339       0.252463       0.920898           2074.11       0.001
87          0.217851    0.925147       0.252802       0.920898           2097.85       0.001
88          0.215969    0.925138       0.255438       0.921094           2121.65       0.001
89          0.217307    0.92294        0.253423       0.920313           2145.48       0.001
90          0.217241    0.925058       0.254931       0.919922           2169.54       0.001
91          0.211696    0.926869       0.250793       0.922852           2194.26       0.0001
92          0.202627    0.929688       0.248774       0.923242           2218          0.0001
93          0.210399    0.927046       0.249476       0.923242           2241.84       0.0001
94          0.204141    0.929754       0.248579       0.923633           2265.62       0.0001
95          0.197843    0.931596       0.249407       0.924805           2289.48       0.0001
96          0.200821    0.930889       0.2483         0.922656           2313.26       0.0001
97          0.204194    0.9284         0.248897       0.923633           2337.15       0.0001
98          0.204944    0.928644       0.250977       0.922852           2360.91       0.0001
99          0.201082    0.931001       0.249237       0.923633           2384.56       0.0001
100         0.202857    0.930353       0.253938       0.923047           2408.31       0.0001
Test accuracy: 0.9244462
</pre></div></div>
</div>
<p>We observe slightly improved accuracy. There are several other improvement methods that can be easily tested, such as training using a well-known network structure called ResNet [He 2016].</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="References">
<h2>4.7. References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[Tokui 2015] Tokui, S., Oono, K., Hido, S. and Clayton, J., Chainer: a Next-Generation Open Source Framework for Deep Learning, Proceedings of Workshop on Machine Learning Systems(LearningSys) in The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS), (2015)</p>
<p>[Niitani 2017] Yusuke Niitani, Toru Ogawa, Shunta Saito, Masaki Saito, “ChainerCV: a Library for Deep Learning in Computer Vision”, ACM Multimedia (ACMMM), Open Source Software Competition, 2017</p>
<p>[Hidaka 2017] Masatoshi Hidaka, Yuichiro Kikura, Yoshitaka Ushiku, Tatsuya Harada. WebDNN: Fastest DNN Execution Framework on Web Browser. ACM International Conference on Multimedia (ACMMM), Open Source Software Competition, pp.1213-1216, 2017.</p>
<p>[He 2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, “Deep Residual Learning for Image Recognition”, CVPR 2016</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Image_Segmentation.html" class="btn btn-neutral float-right" title="5. Practice: Segmentation of MRI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Introduction_to_Neural_Network.html" class="btn btn-neutral" title="3. Basics of neural network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Preferred Networks &amp; キカガク

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>